{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2.csv')\n",
    "df.dropna(subset=['price'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "target = 'price'\n",
    "features.remove(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target].str.strip(\"$\").str.replace(\",\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "class Data_Transformer(object):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        self.mean_weight = new_df[\"Weight\"].mean() # obtain mean weight\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase weekday\n",
    "        self.majority_month = new_df[\"Month\"].mode()[0] # obtain majority purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        self.majority_weekday = new_df[\"Weekday\"].mode()[0] # obtain majority purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df[\"Ingredient Number\"] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        self.mean_ingredient_number = new_df[\"Ingredient Number\"].mean() # obtain mean ingredient number\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with median ingredient number\n",
    "        self.pl_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Level\"] = pd.Series(self.pl_le.fit_transform(X[\"product_level\"])) # fit and transform product level with label-encoder\n",
    "        self.majority_product_level = new_df[\"Product Level\"].mode()[0] # obtain majority product level code\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        self.pt_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Type\"] = pd.Series(self.pt_le.fit_transform(X[\"product_type\"])) # fit and transform product type with label-encoder\n",
    "        self.majority_product_type = new_df[\"Product Type\"].mode()[0] # obtain majority product type code\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        self.cost_imputer = XGBRegressor() # create a XGBoost imputer for cost\n",
    "        df_for_imputing_cost = new_df.dropna() # create training data for cost imputer by dropping missing data\n",
    "        self.cost_imputer.fit(df_for_imputing_cost[[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]], df_for_imputing_cost[\"Cost\"]) # fit cost imputer\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df['Ingredient Number'] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with mean ingredient number\n",
    "        new_df[\"Product Level\"] = self.pl_le.transform(X[\"product_level\"]) # transform product level with label-encoder\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        new_df[\"Product Type\"] = self.pt_le.transform(X[\"product_type\"]) # transform product type with label-encoder\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        imputed_cost = pd.Series(self.cost_imputer.predict(new_df[new_df[\"Cost\"].isnull()][[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]])) # obtain imputed cost\n",
    "        imputed_cost.index = new_df[new_df[\"Cost\"].isnull()][\"Cost\"].index # set index of imputed cost\n",
    "        new_df[\"Cost\"].fillna(imputed_cost,inplace=True) # fill in missing cost with imputed cost\n",
    "        return new_df # return new_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def weight2num(self, x): # function to convert weight to number\n",
    "        if type(x) == str:\n",
    "            x = x.strip('Kg').split(' Ton ')\n",
    "            return float(x[0])*1000+float(x[1])\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def get_numbers(self, x): # function to get number of ingredients in recipe\n",
    "        if type(x) == str:\n",
    "            return len(x.split(','))\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('dtf', Data_Transformer()),\n",
    "        ('scaler', MinMaxScaler())]\n",
    "preproc = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc.fit_transform(X_train)\n",
    "X_test = preproc.transform(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = nn.Sequential(nn.Linear(7, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "batch_size = 200\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSELoss(reduction='mean')\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train_loss 80905895936.0, Validation_loss 85585108992.0, Seconds 0.032996416091918945\n",
      "Epoch 1: Train_loss 80801480704.0, Validation_loss 85473722368.0, Seconds 0.02851271629333496\n",
      "Epoch 2: Train_loss 80148258816.0, Validation_loss 84776722432.0, Seconds 0.1055138111114502\n",
      "Epoch 3: Train_loss 77610319872.0, Validation_loss 82065661952.0, Seconds 0.027004718780517578\n",
      "Epoch 4: Train_loss 70725246976.0, Validation_loss 74681548800.0, Seconds 0.027997970581054688\n",
      "Epoch 5: Train_loss 58227744768.0, Validation_loss 61091160064.0, Seconds 0.0240020751953125\n",
      "Epoch 6: Train_loss 48409956352.0, Validation_loss 49643986944.0, Seconds 0.023511648178100586\n",
      "Epoch 7: Train_loss 48095453184.0, Validation_loss 48595722240.0, Seconds 0.02499985694885254\n",
      "Epoch 8: Train_loss 46901157888.0, Validation_loss 47685218304.0, Seconds 0.026000022888183594\n",
      "Epoch 9: Train_loss 46264692736.0, Validation_loss 46972395520.0, Seconds 0.024006366729736328\n",
      "Epoch 10: Train_loss 45533773824.0, Validation_loss 45970739200.0, Seconds 0.027510881423950195\n",
      "Epoch 11: Train_loss 44825899008.0, Validation_loss 45116866560.0, Seconds 0.02399730682373047\n",
      "Epoch 12: Train_loss 44086951936.0, Validation_loss 44252299264.0, Seconds 0.02400660514831543\n",
      "Epoch 13: Train_loss 43294724096.0, Validation_loss 43280134144.0, Seconds 0.029006242752075195\n",
      "Epoch 14: Train_loss 42439553024.0, Validation_loss 42232557568.0, Seconds 0.025519132614135742\n",
      "Epoch 15: Train_loss 41507753984.0, Validation_loss 41099452416.0, Seconds 0.027997970581054688\n",
      "Epoch 16: Train_loss 40484237312.0, Validation_loss 39846805504.0, Seconds 0.025002002716064453\n",
      "Epoch 17: Train_loss 39360671744.0, Validation_loss 38464565248.0, Seconds 0.02400350570678711\n",
      "Epoch 18: Train_loss 38141829120.0, Validation_loss 36957057024.0, Seconds 0.024505615234375\n",
      "Epoch 19: Train_loss 36856406016.0, Validation_loss 35350204416.0, Seconds 0.025000333786010742\n",
      "Epoch 20: Train_loss 35570233344.0, Validation_loss 33715118080.0, Seconds 0.026999711990356445\n",
      "Epoch 21: Train_loss 34383204352.0, Validation_loss 32168400896.0, Seconds 0.026012182235717773\n",
      "Epoch 22: Train_loss 33384222720.0, Validation_loss 30829748224.0, Seconds 0.02352738380432129\n",
      "Epoch 23: Train_loss 32595134464.0, Validation_loss 29755777024.0, Seconds 0.025999069213867188\n",
      "Epoch 24: Train_loss 31965906944.0, Validation_loss 28913537024.0, Seconds 0.023999691009521484\n",
      "Epoch 25: Train_loss 31429257216.0, Validation_loss 28233238528.0, Seconds 0.023007869720458984\n",
      "Epoch 26: Train_loss 30949558272.0, Validation_loss 27657033728.0, Seconds 0.023510456085205078\n",
      "Epoch 27: Train_loss 30517987328.0, Validation_loss 27154776064.0, Seconds 0.026004314422607422\n",
      "Epoch 28: Train_loss 30148769792.0, Validation_loss 26723182592.0, Seconds 0.022997379302978516\n",
      "Epoch 29: Train_loss 29851424768.0, Validation_loss 26364350464.0, Seconds 0.027001380920410156\n",
      "Epoch 30: Train_loss 29611450368.0, Validation_loss 26074167296.0, Seconds 0.024507761001586914\n",
      "Epoch 31: Train_loss 29416738816.0, Validation_loss 25836193792.0, Seconds 0.02499985694885254\n",
      "Epoch 32: Train_loss 29255938048.0, Validation_loss 25641656320.0, Seconds 0.027005910873413086\n",
      "Epoch 33: Train_loss 29118734336.0, Validation_loss 25481619456.0, Seconds 0.024996280670166016\n",
      "Epoch 34: Train_loss 28999303168.0, Validation_loss 25351106560.0, Seconds 0.023505449295043945\n",
      "Epoch 35: Train_loss 28897095680.0, Validation_loss 25242836992.0, Seconds 0.026000022888183594\n",
      "Epoch 36: Train_loss 28811503616.0, Validation_loss 25152012288.0, Seconds 0.025006771087646484\n",
      "Epoch 37: Train_loss 28739803136.0, Validation_loss 25080107008.0, Seconds 0.02499866485595703\n",
      "Epoch 38: Train_loss 28683126784.0, Validation_loss 25024991232.0, Seconds 0.024504661560058594\n",
      "Epoch 39: Train_loss 28638892032.0, Validation_loss 24984725504.0, Seconds 0.025000572204589844\n",
      "Epoch 40: Train_loss 28601565184.0, Validation_loss 24955641856.0, Seconds 0.021999835968017578\n",
      "Epoch 41: Train_loss 28568223744.0, Validation_loss 24933060608.0, Seconds 0.028005123138427734\n",
      "Epoch 42: Train_loss 28539056128.0, Validation_loss 24914460672.0, Seconds 0.024507761001586914\n",
      "Epoch 43: Train_loss 28510851072.0, Validation_loss 24902223872.0, Seconds 0.02799844741821289\n",
      "Epoch 44: Train_loss 28483815424.0, Validation_loss 24892325888.0, Seconds 0.027006149291992188\n",
      "Epoch 45: Train_loss 28457414656.0, Validation_loss 24883818496.0, Seconds 0.027504682540893555\n",
      "Epoch 46: Train_loss 28433414144.0, Validation_loss 24875311104.0, Seconds 0.024999618530273438\n",
      "Epoch 47: Train_loss 28411824128.0, Validation_loss 24870803456.0, Seconds 0.023000478744506836\n",
      "Epoch 48: Train_loss 28392290304.0, Validation_loss 24869634048.0, Seconds 0.026999950408935547\n",
      "Epoch 49: Train_loss 28375443456.0, Validation_loss 24869120000.0, Seconds 0.02451634407043457\n",
      "Epoch 50: Train_loss 28359688192.0, Validation_loss 24869775360.0, Seconds 0.0279996395111084\n",
      "Epoch 51: Train_loss 28345090048.0, Validation_loss 24869693440.0, Seconds 0.026000022888183594\n",
      "Epoch 52: Train_loss 28330991616.0, Validation_loss 24870037504.0, Seconds 0.026998519897460938\n",
      "Epoch 53: Train_loss 28317198336.0, Validation_loss 24870588416.0, Seconds 0.024510622024536133\n",
      "Epoch 54: Train_loss 28303552512.0, Validation_loss 24871602176.0, Seconds 0.024000167846679688\n",
      "Epoch 55: Train_loss 28290701312.0, Validation_loss 24872409088.0, Seconds 0.023001432418823242\n",
      "Epoch 56: Train_loss 28278605824.0, Validation_loss 24872751104.0, Seconds 0.02500009536743164\n",
      "Epoch 57: Train_loss 28266610688.0, Validation_loss 24875198464.0, Seconds 0.02250838279724121\n",
      "Epoch 58: Train_loss 28255703040.0, Validation_loss 24877318144.0, Seconds 0.024998903274536133\n",
      "Epoch 59: Train_loss 28246075392.0, Validation_loss 24880007168.0, Seconds 0.025000333786010742\n",
      "Epoch 60: Train_loss 28237191168.0, Validation_loss 24882034688.0, Seconds 0.024999141693115234\n",
      "Epoch 61: Train_loss 28228083712.0, Validation_loss 24885268480.0, Seconds 0.02451038360595703\n",
      "Epoch 62: Train_loss 28219011072.0, Validation_loss 24886935552.0, Seconds 0.0279996395111084\n",
      "Epoch 63: Train_loss 28210915328.0, Validation_loss 24889804800.0, Seconds 0.02899932861328125\n",
      "Epoch 64: Train_loss 28203270144.0, Validation_loss 24893597696.0, Seconds 0.028007030487060547\n",
      "Epoch 65: Train_loss 28196096000.0, Validation_loss 24897189888.0, Seconds 0.02850818634033203\n",
      "Epoch 66: Train_loss 28189544448.0, Validation_loss 24899969024.0, Seconds 0.026998519897460938\n",
      "Epoch 67: Train_loss 28183646208.0, Validation_loss 24902608896.0, Seconds 0.026001691818237305\n",
      "Epoch 68: Train_loss 28178010112.0, Validation_loss 24904708096.0, Seconds 0.02701401710510254\n",
      "Epoch 69: Train_loss 28172539904.0, Validation_loss 24906870784.0, Seconds 0.02753305435180664\n",
      "Epoch 70: Train_loss 28167223296.0, Validation_loss 24908810240.0, Seconds 0.0279998779296875\n",
      "Epoch 71: Train_loss 28162088960.0, Validation_loss 24910675968.0, Seconds 0.028996944427490234\n",
      "Epoch 72: Train_loss 28157155328.0, Validation_loss 24912873472.0, Seconds 0.026525020599365234\n",
      "Epoch 73: Train_loss 28152178688.0, Validation_loss 24915247104.0, Seconds 0.026001691818237305\n",
      "Epoch 74: Train_loss 28147302400.0, Validation_loss 24917291008.0, Seconds 0.026999711990356445\n",
      "Epoch 75: Train_loss 28142694400.0, Validation_loss 24919531520.0, Seconds 0.028002262115478516\n",
      "Epoch 76: Train_loss 28137912320.0, Validation_loss 24921571328.0, Seconds 0.023504972457885742\n",
      "Epoch 77: Train_loss 28133130240.0, Validation_loss 24924047360.0, Seconds 0.02600693702697754\n",
      "Epoch 78: Train_loss 28128714752.0, Validation_loss 24926738432.0, Seconds 0.024992942810058594\n",
      "Epoch 79: Train_loss 28124213248.0, Validation_loss 24928493568.0, Seconds 0.025007247924804688\n",
      "Epoch 80: Train_loss 28119914496.0, Validation_loss 24930357248.0, Seconds 0.02452826499938965\n",
      "Epoch 81: Train_loss 28115531776.0, Validation_loss 24932433920.0, Seconds 0.027009248733520508\n",
      "Epoch 82: Train_loss 28111249408.0, Validation_loss 24934653952.0, Seconds 0.028989553451538086\n",
      "Epoch 83: Train_loss 28106932224.0, Validation_loss 24936312832.0, Seconds 0.03000640869140625\n",
      "Epoch 84: Train_loss 28102666240.0, Validation_loss 24937846784.0, Seconds 0.02810382843017578\n",
      "Epoch 85: Train_loss 28098422784.0, Validation_loss 24939216896.0, Seconds 0.02600264549255371\n",
      "Epoch 86: Train_loss 28094132224.0, Validation_loss 24940705792.0, Seconds 0.023995637893676758\n",
      "Epoch 87: Train_loss 28089862144.0, Validation_loss 24942225408.0, Seconds 0.02648186683654785\n",
      "Epoch 88: Train_loss 28085850112.0, Validation_loss 24943646720.0, Seconds 0.028998851776123047\n",
      "Epoch 89: Train_loss 28081809408.0, Validation_loss 24944920576.0, Seconds 0.027004003524780273\n",
      "Epoch 90: Train_loss 28077740032.0, Validation_loss 24946800640.0, Seconds 0.02400040626525879\n",
      "Epoch 91: Train_loss 28073674752.0, Validation_loss 24948256768.0, Seconds 0.029510021209716797\n",
      "Epoch 92: Train_loss 28069697536.0, Validation_loss 24949911552.0, Seconds 0.02499985694885254\n",
      "Epoch 93: Train_loss 28065763328.0, Validation_loss 24951234560.0, Seconds 0.02299976348876953\n",
      "Epoch 94: Train_loss 28061786112.0, Validation_loss 24952729600.0, Seconds 0.026009559631347656\n",
      "Epoch 95: Train_loss 28057954304.0, Validation_loss 24953827328.0, Seconds 0.02850794792175293\n",
      "Epoch 96: Train_loss 28054126592.0, Validation_loss 24954234880.0, Seconds 0.02599930763244629\n",
      "Epoch 97: Train_loss 28050251776.0, Validation_loss 24954648576.0, Seconds 0.028000831604003906\n",
      "Epoch 98: Train_loss 28046282752.0, Validation_loss 24955500544.0, Seconds 0.02500629425048828\n",
      "Epoch 99: Train_loss 28042586112.0, Validation_loss 24956717056.0, Seconds 0.02650737762451172\n",
      "Epoch 100: Train_loss 28038856704.0, Validation_loss 24957423616.0, Seconds 0.027007341384887695\n",
      "Epoch 101: Train_loss 28035119104.0, Validation_loss 24957988864.0, Seconds 0.027994155883789062\n",
      "Epoch 102: Train_loss 28031193088.0, Validation_loss 24959416320.0, Seconds 0.02750873565673828\n",
      "Epoch 103: Train_loss 28027240448.0, Validation_loss 24961048576.0, Seconds 0.02900099754333496\n",
      "Epoch 104: Train_loss 28023347200.0, Validation_loss 24961536000.0, Seconds 0.025000810623168945\n",
      "Epoch 105: Train_loss 28019574784.0, Validation_loss 24961736704.0, Seconds 0.02700066566467285\n",
      "Epoch 106: Train_loss 28015675392.0, Validation_loss 24962295808.0, Seconds 0.0265195369720459\n",
      "Epoch 107: Train_loss 28011567104.0, Validation_loss 24963014656.0, Seconds 0.02700042724609375\n",
      "Epoch 108: Train_loss 28007524352.0, Validation_loss 24964542464.0, Seconds 0.02399921417236328\n",
      "Epoch 109: Train_loss 28003467264.0, Validation_loss 24965898240.0, Seconds 0.02600574493408203\n",
      "Epoch 110: Train_loss 27999488000.0, Validation_loss 24967225344.0, Seconds 0.025508880615234375\n",
      "Epoch 111: Train_loss 27995332608.0, Validation_loss 24968380416.0, Seconds 0.024998903274536133\n",
      "Epoch 112: Train_loss 27991273472.0, Validation_loss 24969650176.0, Seconds 0.02499985694885254\n",
      "Epoch 113: Train_loss 27987181568.0, Validation_loss 24970684416.0, Seconds 0.023005247116088867\n",
      "Epoch 114: Train_loss 27983226880.0, Validation_loss 24970895360.0, Seconds 0.10051274299621582\n",
      "Epoch 115: Train_loss 27979368448.0, Validation_loss 24971067392.0, Seconds 0.024457931518554688\n",
      "Epoch 116: Train_loss 27975290880.0, Validation_loss 24971198464.0, Seconds 0.023997783660888672\n",
      "Epoch 117: Train_loss 27971016704.0, Validation_loss 24970559488.0, Seconds 0.023009777069091797\n",
      "Epoch 118: Train_loss 27966183424.0, Validation_loss 24970467328.0, Seconds 0.029993057250976562\n",
      "Epoch 119: Train_loss 27961534464.0, Validation_loss 24969725952.0, Seconds 0.024504661560058594\n",
      "Epoch 120: Train_loss 27956817920.0, Validation_loss 24968577024.0, Seconds 0.02500009536743164\n",
      "Epoch 121: Train_loss 27951974400.0, Validation_loss 24968392704.0, Seconds 0.024002552032470703\n",
      "Epoch 122: Train_loss 27947177984.0, Validation_loss 24967227392.0, Seconds 0.02701258659362793\n",
      "Epoch 123: Train_loss 27942500352.0, Validation_loss 24966316032.0, Seconds 0.02350592613220215\n",
      "Epoch 124: Train_loss 27937722368.0, Validation_loss 24965574656.0, Seconds 0.027993202209472656\n",
      "Epoch 125: Train_loss 27933093888.0, Validation_loss 24964409344.0, Seconds 0.023000478744506836\n",
      "Epoch 126: Train_loss 27928414208.0, Validation_loss 24962666496.0, Seconds 0.023003101348876953\n",
      "Epoch 127: Train_loss 27923599360.0, Validation_loss 24960722944.0, Seconds 0.02250504493713379\n",
      "Epoch 128: Train_loss 27918735360.0, Validation_loss 24958654464.0, Seconds 0.024000883102416992\n",
      "Epoch 129: Train_loss 27913787392.0, Validation_loss 24956928000.0, Seconds 0.02599954605102539\n",
      "Epoch 130: Train_loss 27908628480.0, Validation_loss 24954998784.0, Seconds 0.028007984161376953\n",
      "Epoch 131: Train_loss 27903315968.0, Validation_loss 24952461312.0, Seconds 0.024505138397216797\n",
      "Epoch 132: Train_loss 27897903104.0, Validation_loss 24949936128.0, Seconds 0.02800273895263672\n",
      "Epoch 133: Train_loss 27892670464.0, Validation_loss 24948439040.0, Seconds 0.02899765968322754\n",
      "Epoch 134: Train_loss 27887261696.0, Validation_loss 24946606080.0, Seconds 0.02701258659362793\n",
      "Epoch 135: Train_loss 27881891840.0, Validation_loss 24944728064.0, Seconds 0.02652144432067871\n",
      "Epoch 136: Train_loss 27876184064.0, Validation_loss 24942063616.0, Seconds 0.027001619338989258\n",
      "Epoch 137: Train_loss 27870408704.0, Validation_loss 24939278336.0, Seconds 0.02699875831604004\n",
      "Epoch 138: Train_loss 27864776704.0, Validation_loss 24936523776.0, Seconds 0.02951788902282715\n",
      "Epoch 139: Train_loss 27859324928.0, Validation_loss 24934219776.0, Seconds 0.024995803833007812\n",
      "Epoch 140: Train_loss 27853912064.0, Validation_loss 24932036608.0, Seconds 0.02799820899963379\n",
      "Epoch 141: Train_loss 27848294400.0, Validation_loss 24930213888.0, Seconds 0.02499985694885254\n",
      "Epoch 142: Train_loss 27842263040.0, Validation_loss 24927838208.0, Seconds 0.026517152786254883\n",
      "Epoch 143: Train_loss 27836291072.0, Validation_loss 24925771776.0, Seconds 0.03199148178100586\n",
      "Epoch 144: Train_loss 27830360064.0, Validation_loss 24924499968.0, Seconds 0.026003122329711914\n",
      "Epoch 145: Train_loss 27824093184.0, Validation_loss 24923166720.0, Seconds 0.02700042724609375\n",
      "Epoch 146: Train_loss 27817617408.0, Validation_loss 24922523648.0, Seconds 0.030505895614624023\n",
      "Epoch 147: Train_loss 27810973696.0, Validation_loss 24920766464.0, Seconds 0.02400040626525879\n",
      "Epoch 148: Train_loss 27804393472.0, Validation_loss 24917833728.0, Seconds 0.030000925064086914\n",
      "Epoch 149: Train_loss 27797786624.0, Validation_loss 24913876992.0, Seconds 0.024516582489013672\n",
      "Epoch 150: Train_loss 27791286272.0, Validation_loss 24910063616.0, Seconds 0.02399158477783203\n",
      "Epoch 151: Train_loss 27784695808.0, Validation_loss 24906711040.0, Seconds 0.03300762176513672\n",
      "Epoch 152: Train_loss 27778095104.0, Validation_loss 24902643712.0, Seconds 0.029994964599609375\n",
      "Epoch 153: Train_loss 27771414528.0, Validation_loss 24898725888.0, Seconds 0.025505542755126953\n",
      "Epoch 154: Train_loss 27764846592.0, Validation_loss 24894898176.0, Seconds 0.023006677627563477\n",
      "Epoch 155: Train_loss 27758358528.0, Validation_loss 24891549696.0, Seconds 0.029992103576660156\n",
      "Epoch 156: Train_loss 27751731200.0, Validation_loss 24888555520.0, Seconds 0.030511140823364258\n",
      "Epoch 157: Train_loss 27745064960.0, Validation_loss 24885071872.0, Seconds 0.024999618530273438\n",
      "Epoch 158: Train_loss 27738558464.0, Validation_loss 24881545216.0, Seconds 0.023000240325927734\n",
      "Epoch 159: Train_loss 27732115456.0, Validation_loss 24878358528.0, Seconds 0.02500009536743164\n",
      "Epoch 160: Train_loss 27725705216.0, Validation_loss 24875753472.0, Seconds 0.025507450103759766\n",
      "Epoch 161: Train_loss 27719108608.0, Validation_loss 24872622080.0, Seconds 0.02700352668762207\n",
      "Epoch 162: Train_loss 27712458752.0, Validation_loss 24868868096.0, Seconds 0.023999929428100586\n",
      "Epoch 163: Train_loss 27705892864.0, Validation_loss 24864346112.0, Seconds 0.023999691009521484\n",
      "Epoch 164: Train_loss 27699367936.0, Validation_loss 24859918336.0, Seconds 0.025515079498291016\n",
      "Epoch 165: Train_loss 27692941312.0, Validation_loss 24855146496.0, Seconds 0.029005050659179688\n",
      "Epoch 166: Train_loss 27686547456.0, Validation_loss 24850657280.0, Seconds 0.028992891311645508\n",
      "Epoch 167: Train_loss 27680229376.0, Validation_loss 24845596672.0, Seconds 0.028005123138427734\n",
      "Epoch 168: Train_loss 27673968640.0, Validation_loss 24839512064.0, Seconds 0.028505802154541016\n",
      "Epoch 169: Train_loss 27667752960.0, Validation_loss 24834080768.0, Seconds 0.033000946044921875\n",
      "Epoch 170: Train_loss 27661631488.0, Validation_loss 24829691904.0, Seconds 0.028998613357543945\n",
      "Epoch 171: Train_loss 27655153664.0, Validation_loss 24824365056.0, Seconds 0.023511409759521484\n",
      "Epoch 172: Train_loss 27648700416.0, Validation_loss 24819181568.0, Seconds 0.024997234344482422\n",
      "Epoch 173: Train_loss 27642220544.0, Validation_loss 24815296512.0, Seconds 0.03000044822692871\n",
      "Epoch 174: Train_loss 27635742720.0, Validation_loss 24811909120.0, Seconds 0.02300715446472168\n",
      "Epoch 175: Train_loss 27629391872.0, Validation_loss 24807395328.0, Seconds 0.023506879806518555\n",
      "Epoch 176: Train_loss 27623149568.0, Validation_loss 24802945024.0, Seconds 0.02800583839416504\n",
      "Epoch 177: Train_loss 27616935936.0, Validation_loss 24799100928.0, Seconds 0.02799248695373535\n",
      "Epoch 178: Train_loss 27610804224.0, Validation_loss 24795258880.0, Seconds 0.03201484680175781\n",
      "Epoch 179: Train_loss 27604504576.0, Validation_loss 24791128064.0, Seconds 0.031523942947387695\n",
      "Epoch 180: Train_loss 27597819904.0, Validation_loss 24787204096.0, Seconds 0.03200030326843262\n",
      "Epoch 181: Train_loss 27591163904.0, Validation_loss 24783255552.0, Seconds 0.027008533477783203\n",
      "Epoch 182: Train_loss 27584327680.0, Validation_loss 24779511808.0, Seconds 0.0325312614440918\n",
      "Epoch 183: Train_loss 27577645056.0, Validation_loss 24774934528.0, Seconds 0.0279996395111084\n",
      "Epoch 184: Train_loss 27571079168.0, Validation_loss 24770789376.0, Seconds 0.02600407600402832\n",
      "Epoch 185: Train_loss 27564533760.0, Validation_loss 24767674368.0, Seconds 0.02800297737121582\n",
      "Epoch 186: Train_loss 27557941248.0, Validation_loss 24764522496.0, Seconds 0.02950572967529297\n",
      "Epoch 187: Train_loss 27550457856.0, Validation_loss 24757972992.0, Seconds 0.031001806259155273\n",
      "Epoch 188: Train_loss 27543504896.0, Validation_loss 24752089088.0, Seconds 0.030022144317626953\n",
      "Epoch 189: Train_loss 27536730112.0, Validation_loss 24748201984.0, Seconds 0.026501893997192383\n",
      "Epoch 190: Train_loss 27529986048.0, Validation_loss 24744390656.0, Seconds 0.0269930362701416\n",
      "Epoch 191: Train_loss 27523158016.0, Validation_loss 24741165056.0, Seconds 0.029001951217651367\n",
      "Epoch 192: Train_loss 27516540928.0, Validation_loss 24737370112.0, Seconds 0.030004024505615234\n",
      "Epoch 193: Train_loss 27509956608.0, Validation_loss 24735109120.0, Seconds 0.028513669967651367\n",
      "Epoch 194: Train_loss 27503546368.0, Validation_loss 24731992064.0, Seconds 0.025995492935180664\n",
      "Epoch 195: Train_loss 27497103360.0, Validation_loss 24728307712.0, Seconds 0.023000478744506836\n",
      "Epoch 196: Train_loss 27490947072.0, Validation_loss 24726054912.0, Seconds 0.024681806564331055\n",
      "Epoch 197: Train_loss 27484788736.0, Validation_loss 24723171328.0, Seconds 0.028011322021484375\n",
      "Epoch 198: Train_loss 27478675456.0, Validation_loss 24719566848.0, Seconds 0.024993419647216797\n",
      "Epoch 199: Train_loss 27472484352.0, Validation_loss 24716281856.0, Seconds 0.025998592376708984\n",
      "Epoch 200: Train_loss 27466141696.0, Validation_loss 24713838592.0, Seconds 0.02451181411743164\n",
      "Epoch 201: Train_loss 27459760128.0, Validation_loss 24711843840.0, Seconds 0.027999162673950195\n",
      "Epoch 202: Train_loss 27453493248.0, Validation_loss 24710045696.0, Seconds 0.02700018882751465\n",
      "Epoch 203: Train_loss 27447220224.0, Validation_loss 24707336192.0, Seconds 0.025000333786010742\n",
      "Epoch 204: Train_loss 27440769024.0, Validation_loss 24707000320.0, Seconds 0.029509782791137695\n",
      "Epoch 205: Train_loss 27434485760.0, Validation_loss 24706084864.0, Seconds 0.027999401092529297\n",
      "Epoch 206: Train_loss 27428212736.0, Validation_loss 24703121408.0, Seconds 0.02300095558166504\n",
      "Epoch 207: Train_loss 27421775872.0, Validation_loss 24699650048.0, Seconds 0.02900552749633789\n",
      "Epoch 208: Train_loss 27413649408.0, Validation_loss 24692377600.0, Seconds 0.027507305145263672\n",
      "Epoch 209: Train_loss 27405322240.0, Validation_loss 24686403584.0, Seconds 0.023000240325927734\n",
      "Epoch 210: Train_loss 27397193728.0, Validation_loss 24682571776.0, Seconds 0.024000883102416992\n",
      "Epoch 211: Train_loss 27389464576.0, Validation_loss 24680304640.0, Seconds 0.02300262451171875\n",
      "Epoch 212: Train_loss 27382249472.0, Validation_loss 24678946816.0, Seconds 0.026509523391723633\n",
      "Epoch 213: Train_loss 27374829568.0, Validation_loss 24676210688.0, Seconds 0.027999162673950195\n",
      "Epoch 214: Train_loss 27368130560.0, Validation_loss 24674080768.0, Seconds 0.028072595596313477\n",
      "Epoch 215: Train_loss 27361724416.0, Validation_loss 24673771520.0, Seconds 0.024931669235229492\n",
      "Epoch 216: Train_loss 27355527168.0, Validation_loss 24673972224.0, Seconds 0.025514841079711914\n",
      "Epoch 217: Train_loss 27349360640.0, Validation_loss 24672905216.0, Seconds 0.029994487762451172\n",
      "Epoch 218: Train_loss 27343171584.0, Validation_loss 24672124928.0, Seconds 0.03000020980834961\n",
      "Epoch 219: Train_loss 27337201664.0, Validation_loss 24670855168.0, Seconds 0.025511741638183594\n",
      "Epoch 220: Train_loss 27331368960.0, Validation_loss 24669515776.0, Seconds 0.028999805450439453\n",
      "Epoch 221: Train_loss 27325444096.0, Validation_loss 24666791936.0, Seconds 0.031002521514892578\n",
      "Epoch 222: Train_loss 27319750656.0, Validation_loss 24665114624.0, Seconds 0.024010896682739258\n",
      "Epoch 223: Train_loss 27313983488.0, Validation_loss 24664170496.0, Seconds 0.022501468658447266\n",
      "Epoch 224: Train_loss 27308183552.0, Validation_loss 24663701504.0, Seconds 0.027002573013305664\n",
      "Epoch 225: Train_loss 27302512640.0, Validation_loss 24661733376.0, Seconds 0.09452104568481445\n",
      "Epoch 226: Train_loss 27296837632.0, Validation_loss 24660191232.0, Seconds 0.025002002716064453\n",
      "Epoch 227: Train_loss 27291291648.0, Validation_loss 24658341888.0, Seconds 0.02900409698486328\n",
      "Epoch 228: Train_loss 27285831680.0, Validation_loss 24656652288.0, Seconds 0.02651238441467285\n",
      "Epoch 229: Train_loss 27280384000.0, Validation_loss 24655595520.0, Seconds 0.02499699592590332\n",
      "Epoch 230: Train_loss 27274991616.0, Validation_loss 24654819328.0, Seconds 0.028000831604003906\n",
      "Epoch 231: Train_loss 27269640192.0, Validation_loss 24653473792.0, Seconds 0.028083324432373047\n",
      "Epoch 232: Train_loss 27264172032.0, Validation_loss 24651819008.0, Seconds 0.02951192855834961\n",
      "Epoch 233: Train_loss 27258458112.0, Validation_loss 24650532864.0, Seconds 0.02899956703186035\n",
      "Epoch 234: Train_loss 27252822016.0, Validation_loss 24650752000.0, Seconds 0.025999784469604492\n",
      "Epoch 235: Train_loss 27247464448.0, Validation_loss 24650158080.0, Seconds 0.027516841888427734\n",
      "Epoch 236: Train_loss 27242211328.0, Validation_loss 24648581120.0, Seconds 0.025999784469604492\n",
      "Epoch 237: Train_loss 27237076992.0, Validation_loss 24648169472.0, Seconds 0.023000240325927734\n",
      "Epoch 238: Train_loss 27231674368.0, Validation_loss 24647653376.0, Seconds 0.02300095558166504\n",
      "Epoch 239: Train_loss 27226488832.0, Validation_loss 24647831552.0, Seconds 0.024518489837646484\n",
      "Epoch 240: Train_loss 27221317632.0, Validation_loss 24647983104.0, Seconds 0.02300095558166504\n",
      "Epoch 241: Train_loss 27216214016.0, Validation_loss 24648663040.0, Seconds 0.02599191665649414\n",
      "Epoch 242: Train_loss 27211112448.0, Validation_loss 24648206336.0, Seconds 0.02300119400024414\n",
      "Epoch 243: Train_loss 27205984256.0, Validation_loss 24648075264.0, Seconds 0.026528596878051758\n",
      "Epoch 244: Train_loss 27201005568.0, Validation_loss 24646660096.0, Seconds 0.03000473976135254\n",
      "Epoch 245: Train_loss 27196053504.0, Validation_loss 24647761920.0, Seconds 0.026996850967407227\n",
      "Epoch 246: Train_loss 27191189504.0, Validation_loss 24647675904.0, Seconds 0.029004335403442383\n",
      "Epoch 247: Train_loss 27186341888.0, Validation_loss 24647761920.0, Seconds 0.030514001846313477\n",
      "Epoch 248: Train_loss 27181627392.0, Validation_loss 24649515008.0, Seconds 0.025993824005126953\n",
      "Epoch 249: Train_loss 27176972288.0, Validation_loss 24650455040.0, Seconds 0.029000282287597656\n",
      "Epoch 250: Train_loss 27172472832.0, Validation_loss 24649893888.0, Seconds 0.028517723083496094\n",
      "Epoch 251: Train_loss 27167784960.0, Validation_loss 24651851776.0, Seconds 0.026000499725341797\n",
      "Epoch 252: Train_loss 27163015168.0, Validation_loss 24653942784.0, Seconds 0.023999929428100586\n",
      "Epoch 253: Train_loss 27158394880.0, Validation_loss 24652746752.0, Seconds 0.024007797241210938\n",
      "Epoch 254: Train_loss 27153844224.0, Validation_loss 24653881344.0, Seconds 0.03850579261779785\n",
      "Epoch 255: Train_loss 27149518848.0, Validation_loss 24653324288.0, Seconds 0.023998737335205078\n",
      "Epoch 256: Train_loss 27145185280.0, Validation_loss 24654372864.0, Seconds 0.027001380920410156\n",
      "Epoch 257: Train_loss 27141005312.0, Validation_loss 24653248512.0, Seconds 0.026001691818237305\n",
      "Epoch 258: Train_loss 27136813056.0, Validation_loss 24652980224.0, Seconds 0.029437541961669922\n",
      "Epoch 259: Train_loss 27132680192.0, Validation_loss 24651470848.0, Seconds 0.029998779296875\n",
      "Epoch 260: Train_loss 27128680448.0, Validation_loss 24652996608.0, Seconds 0.03301429748535156\n",
      "Epoch 261: Train_loss 27124783104.0, Validation_loss 24652658688.0, Seconds 0.02451014518737793\n",
      "Epoch 262: Train_loss 27120932864.0, Validation_loss 24651706368.0, Seconds 0.0260007381439209\n",
      "Epoch 263: Train_loss 27116816384.0, Validation_loss 24652574720.0, Seconds 0.02500009536743164\n",
      "Epoch 264: Train_loss 27112837120.0, Validation_loss 24652283904.0, Seconds 0.026002883911132812\n",
      "Epoch 265: Train_loss 27108732928.0, Validation_loss 24650559488.0, Seconds 0.023505687713623047\n",
      "Epoch 266: Train_loss 27104200704.0, Validation_loss 24652199936.0, Seconds 0.02700042724609375\n",
      "Epoch 267: Train_loss 27099574272.0, Validation_loss 24650356736.0, Seconds 0.028999805450439453\n",
      "Epoch 268: Train_loss 27094900736.0, Validation_loss 24649095168.0, Seconds 0.026004791259765625\n",
      "Epoch 269: Train_loss 27090393088.0, Validation_loss 24649385984.0, Seconds 0.029511451721191406\n",
      "Epoch 270: Train_loss 27086006272.0, Validation_loss 24651034624.0, Seconds 0.029996156692504883\n",
      "Epoch 271: Train_loss 27081867264.0, Validation_loss 24651902976.0, Seconds 0.031000614166259766\n",
      "Epoch 272: Train_loss 27077582848.0, Validation_loss 24650516480.0, Seconds 0.030509471893310547\n",
      "Epoch 273: Train_loss 27073732608.0, Validation_loss 24651786240.0, Seconds 0.029996871948242188\n",
      "Epoch 274: Train_loss 27070081024.0, Validation_loss 24652369920.0, Seconds 0.03200221061706543\n",
      "Epoch 275: Train_loss 27066503168.0, Validation_loss 24655337472.0, Seconds 0.029515743255615234\n",
      "Epoch 276: Train_loss 27062745088.0, Validation_loss 24655992832.0, Seconds 0.026997804641723633\n",
      "Epoch 277: Train_loss 27059281920.0, Validation_loss 24655294464.0, Seconds 0.025010108947753906\n",
      "Epoch 278: Train_loss 27055958016.0, Validation_loss 24655441920.0, Seconds 0.023997783660888672\n",
      "Epoch 279: Train_loss 27052464128.0, Validation_loss 24656883712.0, Seconds 0.02751755714416504\n",
      "Epoch 280: Train_loss 27049349120.0, Validation_loss 24657455104.0, Seconds 0.030004501342773438\n",
      "Epoch 281: Train_loss 27046330368.0, Validation_loss 24658384896.0, Seconds 0.02999424934387207\n",
      "Epoch 282: Train_loss 27043266560.0, Validation_loss 24659730432.0, Seconds 0.031514883041381836\n",
      "Epoch 283: Train_loss 27040272384.0, Validation_loss 24661213184.0, Seconds 0.025001049041748047\n",
      "Epoch 284: Train_loss 27037333504.0, Validation_loss 24662474752.0, Seconds 0.030999422073364258\n",
      "Epoch 285: Train_loss 27034634240.0, Validation_loss 24660432896.0, Seconds 0.027002573013305664\n",
      "Epoch 286: Train_loss 27031875584.0, Validation_loss 24662681600.0, Seconds 0.027510643005371094\n",
      "Epoch 287: Train_loss 27029129216.0, Validation_loss 24667097088.0, Seconds 0.029005050659179688\n",
      "Epoch 288: Train_loss 27026409472.0, Validation_loss 24664672256.0, Seconds 0.025996923446655273\n",
      "Epoch 289: Train_loss 27023806464.0, Validation_loss 24665604096.0, Seconds 0.029506683349609375\n",
      "Epoch 290: Train_loss 27021099008.0, Validation_loss 24667817984.0, Seconds 0.026005983352661133\n",
      "Epoch 291: Train_loss 27018461184.0, Validation_loss 24669896704.0, Seconds 0.02500009536743164\n",
      "Epoch 292: Train_loss 27015782400.0, Validation_loss 24671232000.0, Seconds 0.025997638702392578\n",
      "Epoch 293: Train_loss 27013203968.0, Validation_loss 24673372160.0, Seconds 0.023509979248046875\n",
      "Epoch 294: Train_loss 27010615296.0, Validation_loss 24673282048.0, Seconds 0.029001235961914062\n",
      "Epoch 295: Train_loss 27008141312.0, Validation_loss 24676718592.0, Seconds 0.031008243560791016\n",
      "Epoch 296: Train_loss 27005552640.0, Validation_loss 24678014976.0, Seconds 0.030997753143310547\n",
      "Epoch 297: Train_loss 27003324416.0, Validation_loss 24680343552.0, Seconds 0.028507471084594727\n",
      "Epoch 298: Train_loss 27000963072.0, Validation_loss 24679092224.0, Seconds 0.030002832412719727\n",
      "Epoch 299: Train_loss 26998325248.0, Validation_loss 24682043392.0, Seconds 0.024998188018798828\n",
      "Epoch 300: Train_loss 26995972096.0, Validation_loss 24682833920.0, Seconds 0.024506330490112305\n",
      "Epoch 301: Train_loss 26993704960.0, Validation_loss 24685287424.0, Seconds 0.02801060676574707\n",
      "Epoch 302: Train_loss 26991392768.0, Validation_loss 24686397440.0, Seconds 0.025995731353759766\n",
      "Epoch 303: Train_loss 26989172736.0, Validation_loss 24686002176.0, Seconds 0.028999805450439453\n",
      "Epoch 304: Train_loss 26987026432.0, Validation_loss 24688025600.0, Seconds 0.02651071548461914\n",
      "Epoch 305: Train_loss 26984771584.0, Validation_loss 24688134144.0, Seconds 0.026999711990356445\n",
      "Epoch 306: Train_loss 26982592512.0, Validation_loss 24689770496.0, Seconds 0.028998613357543945\n",
      "Epoch 307: Train_loss 26980505600.0, Validation_loss 24691034112.0, Seconds 0.028006553649902344\n",
      "Epoch 308: Train_loss 26978365440.0, Validation_loss 24694005760.0, Seconds 0.027515649795532227\n",
      "Epoch 309: Train_loss 26976415744.0, Validation_loss 24692168704.0, Seconds 0.027996063232421875\n",
      "Epoch 310: Train_loss 26974093312.0, Validation_loss 24693235712.0, Seconds 0.028001070022583008\n",
      "Epoch 311: Train_loss 26972119040.0, Validation_loss 24695648256.0, Seconds 0.030515432357788086\n",
      "Epoch 312: Train_loss 26970306560.0, Validation_loss 24695453696.0, Seconds 0.02900099754333496\n",
      "Epoch 313: Train_loss 26968322048.0, Validation_loss 24698804224.0, Seconds 0.024999618530273438\n",
      "Epoch 314: Train_loss 26966325248.0, Validation_loss 24700160000.0, Seconds 0.0310060977935791\n",
      "Epoch 315: Train_loss 26964387840.0, Validation_loss 24699414528.0, Seconds 0.02551412582397461\n",
      "Epoch 316: Train_loss 26962182144.0, Validation_loss 24701460480.0, Seconds 0.025996923446655273\n",
      "Epoch 317: Train_loss 26960302080.0, Validation_loss 24701566976.0, Seconds 0.0240020751953125\n",
      "Epoch 318: Train_loss 26958551040.0, Validation_loss 24703588352.0, Seconds 0.025004148483276367\n",
      "Epoch 319: Train_loss 26957004800.0, Validation_loss 24702597120.0, Seconds 0.02450871467590332\n",
      "Epoch 320: Train_loss 26955243520.0, Validation_loss 24700962816.0, Seconds 0.028000831604003906\n",
      "Epoch 321: Train_loss 26953562112.0, Validation_loss 24700741632.0, Seconds 0.025001049041748047\n",
      "Epoch 322: Train_loss 26951905280.0, Validation_loss 24702683136.0, Seconds 0.029512405395507812\n",
      "Epoch 323: Train_loss 26950277120.0, Validation_loss 24702402560.0, Seconds 0.02800130844116211\n",
      "Epoch 324: Train_loss 26948507648.0, Validation_loss 24704471040.0, Seconds 0.028006792068481445\n",
      "Epoch 325: Train_loss 26947002368.0, Validation_loss 24703793152.0, Seconds 0.027999162673950195\n",
      "Epoch 326: Train_loss 26945269760.0, Validation_loss 24704636928.0, Seconds 0.029508590698242188\n",
      "Epoch 327: Train_loss 26943897600.0, Validation_loss 24702558208.0, Seconds 0.026001453399658203\n",
      "Epoch 328: Train_loss 26942154752.0, Validation_loss 24705476608.0, Seconds 0.02400040626525879\n",
      "Epoch 329: Train_loss 26940739584.0, Validation_loss 24706285568.0, Seconds 0.026006460189819336\n",
      "Epoch 330: Train_loss 26939238400.0, Validation_loss 24707794944.0, Seconds 0.02951192855834961\n",
      "Epoch 331: Train_loss 26937552896.0, Validation_loss 24709509120.0, Seconds 0.026999711990356445\n",
      "Epoch 332: Train_loss 26935941120.0, Validation_loss 24711665664.0, Seconds 0.029000043869018555\n",
      "Epoch 333: Train_loss 26934308864.0, Validation_loss 24713285632.0, Seconds 0.027514934539794922\n",
      "Epoch 334: Train_loss 26932889600.0, Validation_loss 24713883648.0, Seconds 0.02700328826904297\n",
      "Epoch 335: Train_loss 26931277824.0, Validation_loss 24716670976.0, Seconds 0.029997825622558594\n",
      "Epoch 336: Train_loss 26929936384.0, Validation_loss 24717723648.0, Seconds 0.0882411003112793\n",
      "Epoch 337: Train_loss 26928420864.0, Validation_loss 24718585856.0, Seconds 0.02799224853515625\n",
      "Epoch 338: Train_loss 26927218688.0, Validation_loss 24720545792.0, Seconds 0.02513909339904785\n",
      "Epoch 339: Train_loss 26925690880.0, Validation_loss 24722862080.0, Seconds 0.02598881721496582\n",
      "Epoch 340: Train_loss 26924242944.0, Validation_loss 24724822016.0, Seconds 0.028992652893066406\n",
      "Epoch 341: Train_loss 26923257856.0, Validation_loss 24723576832.0, Seconds 0.0240018367767334\n",
      "Epoch 342: Train_loss 26921736192.0, Validation_loss 24725653504.0, Seconds 0.025512218475341797\n",
      "Epoch 343: Train_loss 26920468480.0, Validation_loss 24728987648.0, Seconds 0.026002168655395508\n",
      "Epoch 344: Train_loss 26919389184.0, Validation_loss 24728823808.0, Seconds 0.02400803565979004\n",
      "Epoch 345: Train_loss 26918195200.0, Validation_loss 24729399296.0, Seconds 0.027991294860839844\n",
      "Epoch 346: Train_loss 26917210112.0, Validation_loss 24730413056.0, Seconds 0.0255129337310791\n",
      "Epoch 347: Train_loss 26915651584.0, Validation_loss 24733974528.0, Seconds 0.03000617027282715\n",
      "Epoch 348: Train_loss 26914727936.0, Validation_loss 24734793728.0, Seconds 0.025995254516601562\n",
      "Epoch 349: Train_loss 26913351680.0, Validation_loss 24736413696.0, Seconds 0.029009103775024414\n",
      "Epoch 350: Train_loss 26912382976.0, Validation_loss 24736485376.0, Seconds 0.024501562118530273\n",
      "Epoch 351: Train_loss 26911430656.0, Validation_loss 24735000576.0, Seconds 0.027000904083251953\n",
      "Epoch 352: Train_loss 26910261248.0, Validation_loss 24737466368.0, Seconds 0.02900075912475586\n",
      "Epoch 353: Train_loss 26909124608.0, Validation_loss 24740890624.0, Seconds 0.029522418975830078\n",
      "Epoch 354: Train_loss 26907965440.0, Validation_loss 24741648384.0, Seconds 0.026999711990356445\n",
      "Epoch 355: Train_loss 26906863616.0, Validation_loss 24740794368.0, Seconds 0.029003381729125977\n",
      "Epoch 356: Train_loss 26905858048.0, Validation_loss 24743800832.0, Seconds 0.025002479553222656\n",
      "Epoch 357: Train_loss 26904879104.0, Validation_loss 24745783296.0, Seconds 0.025101184844970703\n",
      "Epoch 358: Train_loss 26904180736.0, Validation_loss 24745553920.0, Seconds 0.02500152587890625\n",
      "Epoch 359: Train_loss 26903273472.0, Validation_loss 24746547200.0, Seconds 0.023999929428100586\n",
      "Epoch 360: Train_loss 26902401024.0, Validation_loss 24747442176.0, Seconds 0.03000497817993164\n",
      "Epoch 361: Train_loss 26901532672.0, Validation_loss 24747556864.0, Seconds 0.02850627899169922\n",
      "Epoch 362: Train_loss 26900946944.0, Validation_loss 24749965312.0, Seconds 0.026999711990356445\n",
      "Epoch 363: Train_loss 26899519488.0, Validation_loss 24754569216.0, Seconds 0.03000497817993164\n",
      "Epoch 364: Train_loss 26898743296.0, Validation_loss 24756019200.0, Seconds 0.027512311935424805\n",
      "Epoch 365: Train_loss 26897979392.0, Validation_loss 24754690048.0, Seconds 0.023006439208984375\n",
      "Epoch 366: Train_loss 26896834560.0, Validation_loss 24754864128.0, Seconds 0.024991989135742188\n",
      "Epoch 367: Train_loss 26895802368.0, Validation_loss 24757438464.0, Seconds 0.030004262924194336\n",
      "Epoch 368: Train_loss 26895194112.0, Validation_loss 24757233664.0, Seconds 0.027171850204467773\n",
      "Epoch 369: Train_loss 26894381056.0, Validation_loss 24756779008.0, Seconds 0.024999618530273438\n",
      "Epoch 370: Train_loss 26893383680.0, Validation_loss 24758171648.0, Seconds 0.024000883102416992\n",
      "Epoch 371: Train_loss 26892847104.0, Validation_loss 24758290432.0, Seconds 0.0240018367767334\n",
      "Epoch 372: Train_loss 26891708416.0, Validation_loss 24758124544.0, Seconds 0.029289960861206055\n",
      "Epoch 373: Train_loss 26891147264.0, Validation_loss 24761225216.0, Seconds 0.029000043869018555\n",
      "Epoch 374: Train_loss 26890094592.0, Validation_loss 24762001408.0, Seconds 0.029000520706176758\n",
      "Epoch 375: Train_loss 26889461760.0, Validation_loss 24765026304.0, Seconds 0.02300262451171875\n",
      "Epoch 376: Train_loss 26888695808.0, Validation_loss 24763271168.0, Seconds 0.023508071899414062\n",
      "Epoch 377: Train_loss 26888130560.0, Validation_loss 24762884096.0, Seconds 0.02499842643737793\n",
      "Epoch 378: Train_loss 26887026688.0, Validation_loss 24763437056.0, Seconds 0.02500128746032715\n",
      "Epoch 379: Train_loss 26886676480.0, Validation_loss 24764889088.0, Seconds 0.0260012149810791\n",
      "Epoch 380: Train_loss 26885681152.0, Validation_loss 24766353408.0, Seconds 0.026511192321777344\n",
      "Epoch 381: Train_loss 26885187584.0, Validation_loss 24767543296.0, Seconds 0.02800130844116211\n",
      "Epoch 382: Train_loss 26884546560.0, Validation_loss 24768190464.0, Seconds 0.027001142501831055\n",
      "Epoch 383: Train_loss 26883819520.0, Validation_loss 24766588928.0, Seconds 0.02651190757751465\n",
      "Epoch 384: Train_loss 26883035136.0, Validation_loss 24768608256.0, Seconds 0.025005817413330078\n",
      "Epoch 385: Train_loss 26882482176.0, Validation_loss 24772022272.0, Seconds 0.028999805450439453\n",
      "Epoch 386: Train_loss 26881847296.0, Validation_loss 24772579328.0, Seconds 0.02199840545654297\n",
      "Epoch 387: Train_loss 26880974848.0, Validation_loss 24772902912.0, Seconds 0.027533531188964844\n",
      "Epoch 388: Train_loss 26880577536.0, Validation_loss 24770772992.0, Seconds 0.028003454208374023\n",
      "Epoch 389: Train_loss 26879973376.0, Validation_loss 24773183488.0, Seconds 0.024993181228637695\n",
      "Epoch 390: Train_loss 26879168512.0, Validation_loss 24775030784.0, Seconds 0.027002811431884766\n",
      "Epoch 391: Train_loss 26878736384.0, Validation_loss 24774291456.0, Seconds 0.02350759506225586\n",
      "Epoch 392: Train_loss 26878152704.0, Validation_loss 24776611840.0, Seconds 0.02800154685974121\n",
      "Epoch 393: Train_loss 26877700096.0, Validation_loss 24772745216.0, Seconds 0.025998592376708984\n",
      "Epoch 394: Train_loss 26876940288.0, Validation_loss 24775948288.0, Seconds 0.025004863739013672\n",
      "Epoch 395: Train_loss 26876573696.0, Validation_loss 24773144576.0, Seconds 0.022505998611450195\n",
      "Epoch 396: Train_loss 26875875328.0, Validation_loss 24776286208.0, Seconds 0.025000810623168945\n",
      "Epoch 397: Train_loss 26875314176.0, Validation_loss 24775499776.0, Seconds 0.02200031280517578\n",
      "Epoch 398: Train_loss 26874748928.0, Validation_loss 24775700480.0, Seconds 0.023000001907348633\n",
      "Epoch 399: Train_loss 26874488832.0, Validation_loss 24773836800.0, Seconds 0.02751612663269043\n",
      "Epoch 400: Train_loss 26873653248.0, Validation_loss 24777519104.0, Seconds 0.025000333786010742\n",
      "Epoch 401: Train_loss 26873225216.0, Validation_loss 24777834496.0, Seconds 0.025998353958129883\n",
      "Epoch 402: Train_loss 26872721408.0, Validation_loss 24774543360.0, Seconds 0.02900218963623047\n",
      "Epoch 403: Train_loss 26872131584.0, Validation_loss 24777764864.0, Seconds 0.026515960693359375\n",
      "Epoch 404: Train_loss 26871547904.0, Validation_loss 24781223936.0, Seconds 0.023000001907348633\n",
      "Epoch 405: Train_loss 26871056384.0, Validation_loss 24780021760.0, Seconds 0.023999452590942383\n",
      "Epoch 406: Train_loss 26870374400.0, Validation_loss 24780232704.0, Seconds 0.023000478744506836\n",
      "Epoch 407: Train_loss 26870163456.0, Validation_loss 24782219264.0, Seconds 0.027513504028320312\n",
      "Epoch 408: Train_loss 26869479424.0, Validation_loss 24780894208.0, Seconds 0.02900075912475586\n",
      "Epoch 409: Train_loss 26869112832.0, Validation_loss 24779808768.0, Seconds 0.03099989891052246\n",
      "Epoch 410: Train_loss 26868516864.0, Validation_loss 24781815808.0, Seconds 0.025002479553222656\n",
      "Epoch 411: Train_loss 26868170752.0, Validation_loss 24781826048.0, Seconds 0.02351069450378418\n",
      "Epoch 412: Train_loss 26867324928.0, Validation_loss 24783165440.0, Seconds 0.02600407600402832\n",
      "Epoch 413: Train_loss 26866960384.0, Validation_loss 24781774848.0, Seconds 0.029997587203979492\n",
      "Epoch 414: Train_loss 26866376704.0, Validation_loss 24781449216.0, Seconds 0.03050827980041504\n",
      "Epoch 415: Train_loss 26865584128.0, Validation_loss 24782430208.0, Seconds 0.03000044822692871\n",
      "Epoch 416: Train_loss 26865211392.0, Validation_loss 24783034368.0, Seconds 0.026001691818237305\n",
      "Epoch 417: Train_loss 26864939008.0, Validation_loss 24779313152.0, Seconds 0.026002883911132812\n",
      "Epoch 418: Train_loss 26864353280.0, Validation_loss 24784529408.0, Seconds 0.024514198303222656\n",
      "Epoch 419: Train_loss 26864011264.0, Validation_loss 24783130624.0, Seconds 0.024993896484375\n",
      "Epoch 420: Train_loss 26863464448.0, Validation_loss 24781983744.0, Seconds 0.025999069213867188\n",
      "Epoch 421: Train_loss 26863493120.0, Validation_loss 24785139712.0, Seconds 0.02800464630126953\n",
      "Epoch 422: Train_loss 26862659584.0, Validation_loss 24783495168.0, Seconds 0.028510570526123047\n",
      "Epoch 423: Train_loss 26862608384.0, Validation_loss 24785743872.0, Seconds 0.030001401901245117\n",
      "Epoch 424: Train_loss 26862256128.0, Validation_loss 24777553920.0, Seconds 0.028998851776123047\n",
      "Epoch 425: Train_loss 26861828096.0, Validation_loss 24786679808.0, Seconds 0.025512218475341797\n",
      "Epoch 426: Train_loss 26861381632.0, Validation_loss 24782141440.0, Seconds 0.025998830795288086\n",
      "Epoch 427: Train_loss 26861142016.0, Validation_loss 24780615680.0, Seconds 0.026999711990356445\n",
      "Epoch 428: Train_loss 26860687360.0, Validation_loss 24784453632.0, Seconds 0.024000167846679688\n",
      "Epoch 429: Train_loss 26860384256.0, Validation_loss 24780156928.0, Seconds 0.024508237838745117\n",
      "Epoch 430: Train_loss 26860066816.0, Validation_loss 24784549888.0, Seconds 0.02900242805480957\n",
      "Epoch 431: Train_loss 26859878400.0, Validation_loss 24783230976.0, Seconds 0.027997970581054688\n",
      "Epoch 432: Train_loss 26859446272.0, Validation_loss 24779880448.0, Seconds 0.02900385856628418\n",
      "Epoch 433: Train_loss 26859259904.0, Validation_loss 24780351488.0, Seconds 0.027508974075317383\n",
      "Epoch 434: Train_loss 26858813440.0, Validation_loss 24781203456.0, Seconds 0.026001691818237305\n",
      "Epoch 435: Train_loss 26858706944.0, Validation_loss 24784367616.0, Seconds 0.031004667282104492\n",
      "Epoch 436: Train_loss 26858106880.0, Validation_loss 24779063296.0, Seconds 0.028501033782958984\n",
      "Epoch 437: Train_loss 26858053632.0, Validation_loss 24782364672.0, Seconds 0.02900242805480957\n",
      "Epoch 438: Train_loss 26857629696.0, Validation_loss 24780240896.0, Seconds 0.027997970581054688\n",
      "Epoch 439: Train_loss 26857277440.0, Validation_loss 24778768384.0, Seconds 0.028002023696899414\n",
      "Epoch 440: Train_loss 26856753152.0, Validation_loss 24778504192.0, Seconds 0.03052663803100586\n",
      "Epoch 441: Train_loss 26856706048.0, Validation_loss 24777035776.0, Seconds 0.0280001163482666\n",
      "Epoch 442: Train_loss 26856257536.0, Validation_loss 24778336256.0, Seconds 0.030006885528564453\n",
      "Epoch 443: Train_loss 26855936000.0, Validation_loss 24777007104.0, Seconds 0.026519298553466797\n",
      "Epoch 444: Train_loss 26855528448.0, Validation_loss 24775456768.0, Seconds 0.027001142501831055\n",
      "Epoch 445: Train_loss 26855411712.0, Validation_loss 24773744640.0, Seconds 0.026000022888183594\n",
      "Epoch 446: Train_loss 26854866944.0, Validation_loss 24773830656.0, Seconds 0.02700018882751465\n",
      "Epoch 447: Train_loss 26854617088.0, Validation_loss 24781375488.0, Seconds 0.09151005744934082\n",
      "Epoch 448: Train_loss 26854119424.0, Validation_loss 24777662464.0, Seconds 0.0325160026550293\n",
      "Epoch 449: Train_loss 26854129664.0, Validation_loss 24776398848.0, Seconds 0.03300070762634277\n",
      "Epoch 450: Train_loss 26853427200.0, Validation_loss 24774920192.0, Seconds 0.026999473571777344\n",
      "Epoch 451: Train_loss 26853312512.0, Validation_loss 24772407296.0, Seconds 0.027002573013305664\n",
      "Epoch 452: Train_loss 26852599808.0, Validation_loss 24771284992.0, Seconds 0.025512218475341797\n",
      "Epoch 453: Train_loss 26852384768.0, Validation_loss 24771657728.0, Seconds 0.027004718780517578\n",
      "Epoch 454: Train_loss 26851743744.0, Validation_loss 24770148352.0, Seconds 0.02999258041381836\n",
      "Epoch 455: Train_loss 26851409920.0, Validation_loss 24771303424.0, Seconds 0.027512311935424805\n",
      "Epoch 456: Train_loss 26850881536.0, Validation_loss 24769411072.0, Seconds 0.029000520706176758\n",
      "Epoch 457: Train_loss 26850676736.0, Validation_loss 24770314240.0, Seconds 0.0260009765625\n",
      "Epoch 458: Train_loss 26850383872.0, Validation_loss 24767868928.0, Seconds 0.02800917625427246\n",
      "Epoch 459: Train_loss 26850080768.0, Validation_loss 24769120256.0, Seconds 0.026520729064941406\n",
      "Epoch 460: Train_loss 26849828864.0, Validation_loss 24769241088.0, Seconds 0.02699565887451172\n",
      "Epoch 461: Train_loss 26849296384.0, Validation_loss 24766990336.0, Seconds 0.0279998779296875\n",
      "Epoch 462: Train_loss 26849144832.0, Validation_loss 24767694848.0, Seconds 0.02500438690185547\n",
      "Epoch 463: Train_loss 26848917504.0, Validation_loss 24765562880.0, Seconds 0.026509761810302734\n",
      "Epoch 464: Train_loss 26848698368.0, Validation_loss 24766885888.0, Seconds 0.029994726181030273\n",
      "Epoch 465: Train_loss 26848163840.0, Validation_loss 24766289920.0, Seconds 0.027004480361938477\n",
      "Epoch 466: Train_loss 26848043008.0, Validation_loss 24765659136.0, Seconds 0.030512094497680664\n",
      "Epoch 467: Train_loss 26847844352.0, Validation_loss 24763555840.0, Seconds 0.02600240707397461\n",
      "Epoch 468: Train_loss 26847492096.0, Validation_loss 24764647424.0, Seconds 0.025998830795288086\n",
      "Epoch 469: Train_loss 26847074304.0, Validation_loss 24764235776.0, Seconds 0.023998737335205078\n",
      "Epoch 470: Train_loss 26846779392.0, Validation_loss 24763832320.0, Seconds 0.02351546287536621\n",
      "Epoch 471: Train_loss 26846726144.0, Validation_loss 24762986496.0, Seconds 0.02899956703186035\n",
      "Epoch 472: Train_loss 26846502912.0, Validation_loss 24760770560.0, Seconds 0.027005434036254883\n",
      "Epoch 473: Train_loss 26846087168.0, Validation_loss 24761980928.0, Seconds 0.0240020751953125\n",
      "Epoch 474: Train_loss 26845917184.0, Validation_loss 24759105536.0, Seconds 0.027509450912475586\n",
      "Epoch 475: Train_loss 26845614080.0, Validation_loss 24761501696.0, Seconds 0.026998519897460938\n",
      "Epoch 476: Train_loss 26845419520.0, Validation_loss 24760027136.0, Seconds 0.025999784469604492\n",
      "Epoch 477: Train_loss 26845327360.0, Validation_loss 24758976512.0, Seconds 0.02300572395324707\n",
      "Epoch 478: Train_loss 26844835840.0, Validation_loss 24759549952.0, Seconds 0.02507615089416504\n",
      "Epoch 479: Train_loss 26844715008.0, Validation_loss 24760823808.0, Seconds 0.02699875831604004\n",
      "Epoch 480: Train_loss 26844606464.0, Validation_loss 24758513664.0, Seconds 0.030001163482666016\n",
      "Epoch 481: Train_loss 26844436480.0, Validation_loss 24758515712.0, Seconds 0.029516935348510742\n",
      "Epoch 482: Train_loss 26843977728.0, Validation_loss 24759562240.0, Seconds 0.026003599166870117\n",
      "Epoch 483: Train_loss 26843932672.0, Validation_loss 24758091776.0, Seconds 0.025999784469604492\n",
      "Epoch 484: Train_loss 26843725824.0, Validation_loss 24757649408.0, Seconds 0.02800440788269043\n",
      "Epoch 485: Train_loss 26843551744.0, Validation_loss 24757291008.0, Seconds 0.027510881423950195\n",
      "Epoch 486: Train_loss 26843084800.0, Validation_loss 24757749760.0, Seconds 0.028999805450439453\n",
      "Epoch 487: Train_loss 26843267072.0, Validation_loss 24756781056.0, Seconds 0.02700066566467285\n",
      "Epoch 488: Train_loss 26842779648.0, Validation_loss 24755394560.0, Seconds 0.02499842643737793\n",
      "Epoch 489: Train_loss 26842759168.0, Validation_loss 24756594688.0, Seconds 0.029505252838134766\n",
      "Epoch 490: Train_loss 26842308608.0, Validation_loss 24757622784.0, Seconds 0.03200101852416992\n",
      "Epoch 491: Train_loss 26842341376.0, Validation_loss 24757092352.0, Seconds 0.026000261306762695\n",
      "Epoch 492: Train_loss 26842161152.0, Validation_loss 24754763776.0, Seconds 0.024509906768798828\n",
      "Epoch 493: Train_loss 26841956352.0, Validation_loss 24755576832.0, Seconds 0.03200030326843262\n",
      "Epoch 494: Train_loss 26841552896.0, Validation_loss 24754206720.0, Seconds 0.023005008697509766\n",
      "Epoch 495: Train_loss 26841360384.0, Validation_loss 24755912704.0, Seconds 0.0310056209564209\n",
      "Epoch 496: Train_loss 26841321472.0, Validation_loss 24752859136.0, Seconds 0.02651238441467285\n",
      "Epoch 497: Train_loss 26840967168.0, Validation_loss 24752158720.0, Seconds 0.026000499725341797\n",
      "Epoch 498: Train_loss 26840672256.0, Validation_loss 24752322560.0, Seconds 0.02899956703186035\n",
      "Epoch 499: Train_loss 26840723456.0, Validation_loss 24751532032.0, Seconds 0.029510498046875\n",
      "Epoch 500: Train_loss 26840242176.0, Validation_loss 24753246208.0, Seconds 0.026999711990356445\n",
      "Epoch 501: Train_loss 26840344576.0, Validation_loss 24750329856.0, Seconds 0.024999141693115234\n",
      "Epoch 502: Train_loss 26839963648.0, Validation_loss 24751032320.0, Seconds 0.029000520706176758\n",
      "Epoch 503: Train_loss 26839599104.0, Validation_loss 24751994880.0, Seconds 0.029521703720092773\n",
      "Epoch 504: Train_loss 26839527424.0, Validation_loss 24749668352.0, Seconds 0.025999069213867188\n",
      "Epoch 505: Train_loss 26839355392.0, Validation_loss 24748761088.0, Seconds 0.028999805450439453\n",
      "Epoch 506: Train_loss 26838988800.0, Validation_loss 24750749696.0, Seconds 0.029005050659179688\n",
      "Epoch 507: Train_loss 26838867968.0, Validation_loss 24749682688.0, Seconds 0.029509782791137695\n",
      "Epoch 508: Train_loss 26838482944.0, Validation_loss 24749686784.0, Seconds 0.026999711990356445\n",
      "Epoch 509: Train_loss 26838560768.0, Validation_loss 24750856192.0, Seconds 0.03100419044494629\n",
      "Epoch 510: Train_loss 26838149120.0, Validation_loss 24748677120.0, Seconds 0.026221752166748047\n",
      "Epoch 511: Train_loss 26838050816.0, Validation_loss 24749651968.0, Seconds 0.027993202209472656\n",
      "Epoch 512: Train_loss 26837788672.0, Validation_loss 24748285952.0, Seconds 0.02901315689086914\n",
      "Epoch 513: Train_loss 26837551104.0, Validation_loss 24748410880.0, Seconds 0.029990434646606445\n",
      "Epoch 514: Train_loss 26837260288.0, Validation_loss 24747878400.0, Seconds 0.03650665283203125\n",
      "Epoch 515: Train_loss 26837194752.0, Validation_loss 24748570624.0, Seconds 0.03500485420227051\n",
      "Epoch 516: Train_loss 26836873216.0, Validation_loss 24747214848.0, Seconds 0.026996612548828125\n",
      "Epoch 517: Train_loss 26836762624.0, Validation_loss 24747237376.0, Seconds 0.025509357452392578\n",
      "Epoch 518: Train_loss 26836400128.0, Validation_loss 24748427264.0, Seconds 0.031003952026367188\n",
      "Epoch 519: Train_loss 26836375552.0, Validation_loss 24748439552.0, Seconds 0.02599334716796875\n",
      "Epoch 520: Train_loss 26836080640.0, Validation_loss 24749152256.0, Seconds 0.029514312744140625\n",
      "Epoch 521: Train_loss 26835949568.0, Validation_loss 24748562432.0, Seconds 0.028998851776123047\n",
      "Epoch 522: Train_loss 26835732480.0, Validation_loss 24747503616.0, Seconds 0.02299976348876953\n",
      "Epoch 523: Train_loss 26835529728.0, Validation_loss 24746831872.0, Seconds 0.03100728988647461\n",
      "Epoch 524: Train_loss 26835367936.0, Validation_loss 24746889216.0, Seconds 0.02350902557373047\n",
      "Epoch 525: Train_loss 26835101696.0, Validation_loss 24746004480.0, Seconds 0.024998903274536133\n",
      "Epoch 526: Train_loss 26835179520.0, Validation_loss 24746764288.0, Seconds 0.026999235153198242\n",
      "Epoch 527: Train_loss 26834851840.0, Validation_loss 24744697856.0, Seconds 0.025004863739013672\n",
      "Epoch 528: Train_loss 26834667520.0, Validation_loss 24745615360.0, Seconds 0.029508590698242188\n",
      "Epoch 529: Train_loss 26834597888.0, Validation_loss 24745324544.0, Seconds 0.029000043869018555\n",
      "Epoch 530: Train_loss 26834315264.0, Validation_loss 24744818688.0, Seconds 0.028999805450439453\n",
      "Epoch 531: Train_loss 26834276352.0, Validation_loss 24745392128.0, Seconds 0.02952122688293457\n",
      "Epoch 532: Train_loss 26834012160.0, Validation_loss 24744525824.0, Seconds 0.02999424934387207\n",
      "Epoch 533: Train_loss 26833850368.0, Validation_loss 24743888896.0, Seconds 0.030004024505615234\n",
      "Epoch 534: Train_loss 26833731584.0, Validation_loss 24742772736.0, Seconds 0.025017738342285156\n",
      "Epoch 535: Train_loss 26833553408.0, Validation_loss 24743497728.0, Seconds 0.031014204025268555\n",
      "Epoch 536: Train_loss 26833195008.0, Validation_loss 24742213632.0, Seconds 0.026999950408935547\n",
      "Epoch 537: Train_loss 26833364992.0, Validation_loss 24743000064.0, Seconds 0.028001070022583008\n",
      "Epoch 538: Train_loss 26832996352.0, Validation_loss 24740999168.0, Seconds 0.030506372451782227\n",
      "Epoch 539: Train_loss 26832939008.0, Validation_loss 24742928384.0, Seconds 0.0260009765625\n",
      "Epoch 540: Train_loss 26832644096.0, Validation_loss 24740913152.0, Seconds 0.023000478744506836\n",
      "Epoch 541: Train_loss 26832793600.0, Validation_loss 24740904960.0, Seconds 0.028001785278320312\n",
      "Epoch 542: Train_loss 26832285696.0, Validation_loss 24741711872.0, Seconds 0.025506973266601562\n",
      "Epoch 543: Train_loss 26832285696.0, Validation_loss 24739756032.0, Seconds 0.03299999237060547\n",
      "Epoch 544: Train_loss 26832029696.0, Validation_loss 24739989504.0, Seconds 0.026000499725341797\n",
      "Epoch 545: Train_loss 26831970304.0, Validation_loss 24741249024.0, Seconds 0.02750873565673828\n",
      "Epoch 546: Train_loss 26831771648.0, Validation_loss 24736305152.0, Seconds 0.03000044822692871\n",
      "Epoch 547: Train_loss 26831687680.0, Validation_loss 24740141056.0, Seconds 0.02899932861328125\n",
      "Epoch 548: Train_loss 26831314944.0, Validation_loss 24741093376.0, Seconds 0.03000473976135254\n",
      "Epoch 549: Train_loss 26831302656.0, Validation_loss 24739731456.0, Seconds 0.027513504028320312\n",
      "Epoch 550: Train_loss 26831108096.0, Validation_loss 24738613248.0, Seconds 0.02499699592590332\n",
      "Epoch 551: Train_loss 26831054848.0, Validation_loss 24738598912.0, Seconds 0.03499865531921387\n",
      "Epoch 552: Train_loss 26830753792.0, Validation_loss 24738744320.0, Seconds 0.032514095306396484\n",
      "Epoch 553: Train_loss 26830698496.0, Validation_loss 24737107968.0, Seconds 0.029004335403442383\n",
      "Epoch 554: Train_loss 26830458880.0, Validation_loss 24736292864.0, Seconds 0.02400040626525879\n",
      "Epoch 555: Train_loss 26830342144.0, Validation_loss 24737601536.0, Seconds 0.023006439208984375\n",
      "Epoch 556: Train_loss 26830311424.0, Validation_loss 24735944704.0, Seconds 0.027504682540893555\n",
      "Epoch 557: Train_loss 26830215168.0, Validation_loss 24734439424.0, Seconds 0.025998830795288086\n",
      "Epoch 558: Train_loss 26829826048.0, Validation_loss 24736409600.0, Seconds 0.10051965713500977\n",
      "Epoch 559: Train_loss 26829893632.0, Validation_loss 24737548288.0, Seconds 0.028998374938964844\n",
      "Epoch 560: Train_loss 26829568000.0, Validation_loss 24734046208.0, Seconds 0.023006916046142578\n",
      "Epoch 561: Train_loss 26829600768.0, Validation_loss 24735336448.0, Seconds 0.025511503219604492\n",
      "Epoch 562: Train_loss 26829164544.0, Validation_loss 24734214144.0, Seconds 0.029998064041137695\n",
      "Epoch 563: Train_loss 26829381632.0, Validation_loss 24734158848.0, Seconds 0.03000164031982422\n",
      "Epoch 564: Train_loss 26828914688.0, Validation_loss 24735543296.0, Seconds 0.028409957885742188\n",
      "Epoch 565: Train_loss 26828912640.0, Validation_loss 24734388224.0, Seconds 0.02899909019470215\n",
      "Epoch 566: Train_loss 26828802048.0, Validation_loss 24733843456.0, Seconds 0.02700185775756836\n",
      "Epoch 567: Train_loss 26828531712.0, Validation_loss 24734238720.0, Seconds 0.028005599975585938\n",
      "Epoch 568: Train_loss 26828613632.0, Validation_loss 24733249536.0, Seconds 0.028510570526123047\n",
      "Epoch 569: Train_loss 26828156928.0, Validation_loss 24733001728.0, Seconds 0.0260012149810791\n",
      "Epoch 570: Train_loss 26828083200.0, Validation_loss 24734935040.0, Seconds 0.023998498916625977\n",
      "Epoch 571: Train_loss 26827966464.0, Validation_loss 24732348416.0, Seconds 0.023005008697509766\n",
      "Epoch 572: Train_loss 26827757568.0, Validation_loss 24732772352.0, Seconds 0.024479389190673828\n",
      "Epoch 573: Train_loss 26827687936.0, Validation_loss 24730800128.0, Seconds 0.024998903274536133\n",
      "Epoch 574: Train_loss 26827399168.0, Validation_loss 24733155328.0, Seconds 0.028000593185424805\n",
      "Epoch 575: Train_loss 26827577344.0, Validation_loss 24730388480.0, Seconds 0.029515981674194336\n",
      "Epoch 576: Train_loss 26827235328.0, Validation_loss 24728549376.0, Seconds 0.02700042724609375\n",
      "Epoch 577: Train_loss 26827157504.0, Validation_loss 24730918912.0, Seconds 0.03099656105041504\n",
      "Epoch 578: Train_loss 26827143168.0, Validation_loss 24727224320.0, Seconds 0.030010461807250977\n",
      "Epoch 579: Train_loss 26826663936.0, Validation_loss 24729942016.0, Seconds 0.027502775192260742\n",
      "Epoch 580: Train_loss 26826844160.0, Validation_loss 24727707648.0, Seconds 0.026000261306762695\n",
      "Epoch 581: Train_loss 26826272768.0, Validation_loss 24726515712.0, Seconds 0.02600407600402832\n",
      "Epoch 582: Train_loss 26826428416.0, Validation_loss 24728154112.0, Seconds 0.0270078182220459\n",
      "Epoch 583: Train_loss 26826076160.0, Validation_loss 24726468608.0, Seconds 0.02849721908569336\n",
      "Epoch 584: Train_loss 26825977856.0, Validation_loss 24726228992.0, Seconds 0.027008056640625\n",
      "Epoch 585: Train_loss 26825664512.0, Validation_loss 24726532096.0, Seconds 0.027992963790893555\n",
      "Epoch 586: Train_loss 26825764864.0, Validation_loss 24725731328.0, Seconds 0.02650928497314453\n",
      "Epoch 587: Train_loss 26825355264.0, Validation_loss 24725104640.0, Seconds 0.029001235961914062\n",
      "Epoch 588: Train_loss 26825375744.0, Validation_loss 24726368256.0, Seconds 0.02599954605102539\n",
      "Epoch 589: Train_loss 26825115648.0, Validation_loss 24722405376.0, Seconds 0.02801036834716797\n",
      "Epoch 590: Train_loss 26825086976.0, Validation_loss 24723525632.0, Seconds 0.023512840270996094\n",
      "Epoch 591: Train_loss 26824704000.0, Validation_loss 24724033536.0, Seconds 0.02899479866027832\n",
      "Epoch 592: Train_loss 26824720384.0, Validation_loss 24722030592.0, Seconds 0.023999691009521484\n",
      "Epoch 593: Train_loss 26824458240.0, Validation_loss 24721858560.0, Seconds 0.02600836753845215\n",
      "Epoch 594: Train_loss 26824527872.0, Validation_loss 24720502784.0, Seconds 0.029159069061279297\n",
      "Epoch 595: Train_loss 26824128512.0, Validation_loss 24719767552.0, Seconds 0.02700209617614746\n",
      "Epoch 596: Train_loss 26824155136.0, Validation_loss 24721526784.0, Seconds 0.02899622917175293\n",
      "Epoch 597: Train_loss 26823983104.0, Validation_loss 24720261120.0, Seconds 0.030254125595092773\n",
      "Epoch 598: Train_loss 26823856128.0, Validation_loss 24719142912.0, Seconds 0.028000354766845703\n",
      "Epoch 599: Train_loss 26823696384.0, Validation_loss 24719669248.0, Seconds 0.032000064849853516\n",
      "Epoch 600: Train_loss 26823532544.0, Validation_loss 24717826048.0, Seconds 0.02500009536743164\n",
      "Epoch 601: Train_loss 26823548928.0, Validation_loss 24716972032.0, Seconds 0.02944469451904297\n",
      "Epoch 602: Train_loss 26823100416.0, Validation_loss 24717008896.0, Seconds 0.02500128746032715\n",
      "Epoch 603: Train_loss 26823272448.0, Validation_loss 24717037568.0, Seconds 0.02399921417236328\n",
      "Epoch 604: Train_loss 26822850560.0, Validation_loss 24716148736.0, Seconds 0.02951359748840332\n",
      "Epoch 605: Train_loss 26823079936.0, Validation_loss 24714407936.0, Seconds 0.023999452590942383\n",
      "Epoch 606: Train_loss 26822639616.0, Validation_loss 24715472896.0, Seconds 0.02599954605102539\n",
      "Epoch 607: Train_loss 26822791168.0, Validation_loss 24716920832.0, Seconds 0.02499866485595703\n",
      "Epoch 608: Train_loss 26822461440.0, Validation_loss 24715223040.0, Seconds 0.025507450103759766\n",
      "Epoch 609: Train_loss 26822660096.0, Validation_loss 24712148992.0, Seconds 0.025002479553222656\n",
      "Epoch 610: Train_loss 26822234112.0, Validation_loss 24717225984.0, Seconds 0.030999183654785156\n",
      "Epoch 611: Train_loss 26822211584.0, Validation_loss 24712955904.0, Seconds 0.029001235961914062\n",
      "Epoch 612: Train_loss 26822060032.0, Validation_loss 24710305792.0, Seconds 0.0315098762512207\n",
      "Epoch 613: Train_loss 26821863424.0, Validation_loss 24712288256.0, Seconds 0.02500438690185547\n",
      "Epoch 614: Train_loss 26821844992.0, Validation_loss 24711249920.0, Seconds 0.029993772506713867\n",
      "Epoch 615: Train_loss 26821545984.0, Validation_loss 24711827456.0, Seconds 0.02850818634033203\n",
      "Epoch 616: Train_loss 26821765120.0, Validation_loss 24710031360.0, Seconds 0.025000333786010742\n",
      "Epoch 617: Train_loss 26821304320.0, Validation_loss 24710510592.0, Seconds 0.029004812240600586\n",
      "Epoch 618: Train_loss 26821394432.0, Validation_loss 24710221824.0, Seconds 0.02499675750732422\n",
      "Epoch 619: Train_loss 26821169152.0, Validation_loss 24709591040.0, Seconds 0.02451944351196289\n",
      "Epoch 620: Train_loss 26821101568.0, Validation_loss 24708315136.0, Seconds 0.023999691009521484\n",
      "Epoch 621: Train_loss 26820775936.0, Validation_loss 24708603904.0, Seconds 0.02600264549255371\n",
      "Epoch 622: Train_loss 26820794368.0, Validation_loss 24708898816.0, Seconds 0.025999784469604492\n",
      "Epoch 623: Train_loss 26820765696.0, Validation_loss 24707389440.0, Seconds 0.029512882232666016\n",
      "Epoch 624: Train_loss 26820665344.0, Validation_loss 24705769472.0, Seconds 0.029999971389770508\n",
      "Epoch 625: Train_loss 26820288512.0, Validation_loss 24706742272.0, Seconds 0.027999401092529297\n",
      "Epoch 626: Train_loss 26820485120.0, Validation_loss 24707069952.0, Seconds 0.02800464630126953\n",
      "Epoch 627: Train_loss 26820222976.0, Validation_loss 24705419264.0, Seconds 0.029506206512451172\n",
      "Epoch 628: Train_loss 26820016128.0, Validation_loss 24706668544.0, Seconds 0.03000164031982422\n",
      "Epoch 629: Train_loss 26819821568.0, Validation_loss 24706361344.0, Seconds 0.029006242752075195\n",
      "Epoch 630: Train_loss 26820048896.0, Validation_loss 24707031040.0, Seconds 0.02450704574584961\n",
      "Epoch 631: Train_loss 26819756032.0, Validation_loss 24703586304.0, Seconds 0.02799820899963379\n",
      "Epoch 632: Train_loss 26819676160.0, Validation_loss 24701812736.0, Seconds 0.0260009765625\n",
      "Epoch 633: Train_loss 26819483648.0, Validation_loss 24704456704.0, Seconds 0.025002241134643555\n",
      "Epoch 634: Train_loss 26819452928.0, Validation_loss 24703979520.0, Seconds 0.028506994247436523\n",
      "Epoch 635: Train_loss 26819239936.0, Validation_loss 24700596224.0, Seconds 0.025008678436279297\n",
      "Epoch 636: Train_loss 26819049472.0, Validation_loss 24703467520.0, Seconds 0.024990320205688477\n",
      "Epoch 637: Train_loss 26819215360.0, Validation_loss 24700301312.0, Seconds 0.030005693435668945\n",
      "Epoch 638: Train_loss 26818844672.0, Validation_loss 24702552064.0, Seconds 0.02950310707092285\n",
      "Epoch 639: Train_loss 26818887680.0, Validation_loss 24702040064.0, Seconds 0.028007030487060547\n",
      "Epoch 640: Train_loss 26818889728.0, Validation_loss 24700862464.0, Seconds 0.027992963790893555\n",
      "Epoch 641: Train_loss 26818820096.0, Validation_loss 24698818560.0, Seconds 0.03550839424133301\n",
      "Epoch 642: Train_loss 26818574336.0, Validation_loss 24699877376.0, Seconds 0.031001567840576172\n",
      "Epoch 643: Train_loss 26818353152.0, Validation_loss 24700045312.0, Seconds 0.029003381729125977\n",
      "Epoch 644: Train_loss 26818357248.0, Validation_loss 24698841088.0, Seconds 0.026482820510864258\n",
      "Epoch 645: Train_loss 26818140160.0, Validation_loss 24698322944.0, Seconds 0.02399730682373047\n",
      "Epoch 646: Train_loss 26818283520.0, Validation_loss 24697640960.0, Seconds 0.025998830795288086\n",
      "Epoch 647: Train_loss 26818037760.0, Validation_loss 24698163200.0, Seconds 0.0279996395111084\n",
      "Epoch 648: Train_loss 26818013184.0, Validation_loss 24697616384.0, Seconds 0.02350902557373047\n",
      "Epoch 649: Train_loss 26817898496.0, Validation_loss 24697968640.0, Seconds 0.027002334594726562\n",
      "Epoch 650: Train_loss 26817820672.0, Validation_loss 24697864192.0, Seconds 0.02499842643737793\n",
      "Epoch 651: Train_loss 26817679360.0, Validation_loss 24695156736.0, Seconds 0.0290067195892334\n",
      "Epoch 652: Train_loss 26817445888.0, Validation_loss 24697296896.0, Seconds 0.02950906753540039\n",
      "Epoch 653: Train_loss 26817454080.0, Validation_loss 24694378496.0, Seconds 0.029998302459716797\n",
      "Epoch 654: Train_loss 26817247232.0, Validation_loss 24698146816.0, Seconds 0.029999494552612305\n",
      "Epoch 655: Train_loss 26817368064.0, Validation_loss 24693829632.0, Seconds 0.027510643005371094\n",
      "Epoch 656: Train_loss 26817175552.0, Validation_loss 24689698816.0, Seconds 0.026999473571777344\n",
      "Epoch 657: Train_loss 26817067008.0, Validation_loss 24697223168.0, Seconds 0.02700018882751465\n",
      "Epoch 658: Train_loss 26817046528.0, Validation_loss 24690739200.0, Seconds 0.024999141693115234\n",
      "Epoch 659: Train_loss 26816661504.0, Validation_loss 24691853312.0, Seconds 0.02651071548461914\n",
      "Epoch 660: Train_loss 26816765952.0, Validation_loss 24693653504.0, Seconds 0.028002500534057617\n",
      "Epoch 661: Train_loss 26816493568.0, Validation_loss 24689958912.0, Seconds 0.02899765968322754\n",
      "Epoch 662: Train_loss 26816591872.0, Validation_loss 24691427328.0, Seconds 0.025005340576171875\n",
      "Epoch 663: Train_loss 26816364544.0, Validation_loss 24689924096.0, Seconds 0.03051280975341797\n",
      "Epoch 664: Train_loss 26816229376.0, Validation_loss 24689891328.0, Seconds 0.029998064041137695\n",
      "Epoch 665: Train_loss 26816102400.0, Validation_loss 24689682432.0, Seconds 0.03099966049194336\n",
      "Epoch 666: Train_loss 26816063488.0, Validation_loss 24687843328.0, Seconds 0.02550959587097168\n",
      "Epoch 667: Train_loss 26815850496.0, Validation_loss 24688490496.0, Seconds 0.026999235153198242\n",
      "Epoch 668: Train_loss 26815754240.0, Validation_loss 24688857088.0, Seconds 0.029999732971191406\n",
      "Epoch 669: Train_loss 26815717376.0, Validation_loss 24686708736.0, Seconds 0.08753442764282227\n",
      "Epoch 670: Train_loss 26815479808.0, Validation_loss 24687529984.0, Seconds 0.02400064468383789\n",
      "Epoch 671: Train_loss 26815481856.0, Validation_loss 24687978496.0, Seconds 0.029503822326660156\n",
      "Epoch 672: Train_loss 26815170560.0, Validation_loss 24687550464.0, Seconds 0.02900218963623047\n",
      "Epoch 673: Train_loss 26815270912.0, Validation_loss 24686602240.0, Seconds 0.026999950408935547\n",
      "Epoch 674: Train_loss 26814885888.0, Validation_loss 24686637056.0, Seconds 0.029000282287597656\n",
      "Epoch 675: Train_loss 26815199232.0, Validation_loss 24685737984.0, Seconds 0.02550673484802246\n",
      "Epoch 676: Train_loss 26814902272.0, Validation_loss 24683997184.0, Seconds 0.027999162673950195\n",
      "Epoch 677: Train_loss 26814603264.0, Validation_loss 24686137344.0, Seconds 0.03099989891052246\n",
      "Epoch 678: Train_loss 26814566400.0, Validation_loss 24686161920.0, Seconds 0.02450871467590332\n",
      "Epoch 679: Train_loss 26814517248.0, Validation_loss 24683143168.0, Seconds 0.02900218963623047\n",
      "Epoch 680: Train_loss 26814377984.0, Validation_loss 24683786240.0, Seconds 0.02599811553955078\n",
      "Epoch 681: Train_loss 26814128128.0, Validation_loss 24684957696.0, Seconds 0.02800726890563965\n",
      "Epoch 682: Train_loss 26814224384.0, Validation_loss 24683032576.0, Seconds 0.026511192321777344\n",
      "Epoch 683: Train_loss 26814083072.0, Validation_loss 24683907072.0, Seconds 0.029000520706176758\n",
      "Epoch 684: Train_loss 26813822976.0, Validation_loss 24684083200.0, Seconds 0.02599644660949707\n",
      "Epoch 685: Train_loss 26813648896.0, Validation_loss 24684312576.0, Seconds 0.026019573211669922\n",
      "Epoch 686: Train_loss 26813507584.0, Validation_loss 24682237952.0, Seconds 0.03050708770751953\n",
      "Epoch 687: Train_loss 26813614080.0, Validation_loss 24682496000.0, Seconds 0.02600264549255371\n",
      "Epoch 688: Train_loss 26813186048.0, Validation_loss 24681103360.0, Seconds 0.029001712799072266\n",
      "Epoch 689: Train_loss 26813224960.0, Validation_loss 24680521728.0, Seconds 0.02851247787475586\n",
      "Epoch 690: Train_loss 26812985344.0, Validation_loss 24681502720.0, Seconds 0.02700328826904297\n",
      "Epoch 691: Train_loss 26812704768.0, Validation_loss 24681949184.0, Seconds 0.024001121520996094\n",
      "Epoch 692: Train_loss 26812958720.0, Validation_loss 24679845888.0, Seconds 0.026996612548828125\n",
      "Epoch 693: Train_loss 26812579840.0, Validation_loss 24681234432.0, Seconds 0.024509191513061523\n",
      "Epoch 694: Train_loss 26812743680.0, Validation_loss 24680816640.0, Seconds 0.026000022888183594\n",
      "Epoch 695: Train_loss 26812213248.0, Validation_loss 24680089600.0, Seconds 0.02499985694885254\n",
      "Epoch 696: Train_loss 26812555264.0, Validation_loss 24680192000.0, Seconds 0.03200721740722656\n",
      "Epoch 697: Train_loss 26811975680.0, Validation_loss 24681068544.0, Seconds 0.02950763702392578\n",
      "Epoch 698: Train_loss 26812100608.0, Validation_loss 24683464704.0, Seconds 0.029001235961914062\n",
      "Epoch 699: Train_loss 26811924480.0, Validation_loss 24684118016.0, Seconds 0.025997638702392578\n",
      "Epoch 700: Train_loss 26811639808.0, Validation_loss 24684666880.0, Seconds 0.024507999420166016\n",
      "Epoch 701: Train_loss 26811623424.0, Validation_loss 24684883968.0, Seconds 0.02499985694885254\n",
      "Epoch 702: Train_loss 26811295744.0, Validation_loss 24684505088.0, Seconds 0.03200125694274902\n",
      "Epoch 703: Train_loss 26811314176.0, Validation_loss 24683124736.0, Seconds 0.029001474380493164\n",
      "Epoch 704: Train_loss 26811258880.0, Validation_loss 24685135872.0, Seconds 0.023508310317993164\n",
      "Epoch 705: Train_loss 26811193344.0, Validation_loss 24684328960.0, Seconds 0.026998043060302734\n",
      "Epoch 706: Train_loss 26810959872.0, Validation_loss 24683663360.0, Seconds 0.026002168655395508\n",
      "Epoch 707: Train_loss 26810863616.0, Validation_loss 24684363776.0, Seconds 0.029001474380493164\n",
      "Epoch 708: Train_loss 26810591232.0, Validation_loss 24684343296.0, Seconds 0.025443315505981445\n",
      "Epoch 709: Train_loss 26810662912.0, Validation_loss 24684240896.0, Seconds 0.02701544761657715\n",
      "Epoch 710: Train_loss 26810423296.0, Validation_loss 24682055680.0, Seconds 0.0239865779876709\n",
      "Epoch 711: Train_loss 26810396672.0, Validation_loss 24682203136.0, Seconds 0.024003982543945312\n",
      "Epoch 712: Train_loss 26810087424.0, Validation_loss 24683546624.0, Seconds 0.030512094497680664\n",
      "Epoch 713: Train_loss 26810312704.0, Validation_loss 24680398848.0, Seconds 0.02800297737121582\n",
      "Epoch 714: Train_loss 26809800704.0, Validation_loss 24681197568.0, Seconds 0.027996063232421875\n",
      "Epoch 715: Train_loss 26809985024.0, Validation_loss 24680503296.0, Seconds 0.026513338088989258\n",
      "Epoch 716: Train_loss 26809638912.0, Validation_loss 24680841216.0, Seconds 0.03100109100341797\n",
      "Epoch 717: Train_loss 26809704448.0, Validation_loss 24680873984.0, Seconds 0.028999805450439453\n",
      "Epoch 718: Train_loss 26809389056.0, Validation_loss 24677851136.0, Seconds 0.02700948715209961\n",
      "Epoch 719: Train_loss 26809483264.0, Validation_loss 24679688192.0, Seconds 0.026501178741455078\n",
      "Epoch 720: Train_loss 26809161728.0, Validation_loss 24680167424.0, Seconds 0.023999691009521484\n",
      "Epoch 721: Train_loss 26809206784.0, Validation_loss 24677414912.0, Seconds 0.027999401092529297\n",
      "Epoch 722: Train_loss 26809090048.0, Validation_loss 24676524032.0, Seconds 0.024004697799682617\n",
      "Epoch 723: Train_loss 26808772608.0, Validation_loss 24679213056.0, Seconds 0.02350330352783203\n",
      "Epoch 724: Train_loss 26808868864.0, Validation_loss 24677869568.0, Seconds 0.028003215789794922\n",
      "Epoch 725: Train_loss 26808539136.0, Validation_loss 24678326272.0, Seconds 0.029000282287597656\n",
      "Epoch 726: Train_loss 26808414208.0, Validation_loss 24676573184.0, Seconds 0.029511451721191406\n",
      "Epoch 727: Train_loss 26808492032.0, Validation_loss 24676999168.0, Seconds 0.026005983352661133\n",
      "Epoch 728: Train_loss 26808299520.0, Validation_loss 24675581952.0, Seconds 0.024991989135742188\n",
      "Epoch 729: Train_loss 26808193024.0, Validation_loss 24676655104.0, Seconds 0.02700042724609375\n",
      "Epoch 730: Train_loss 26807904256.0, Validation_loss 24677267456.0, Seconds 0.026509523391723633\n",
      "Epoch 731: Train_loss 26807873536.0, Validation_loss 24677148672.0, Seconds 0.0260012149810791\n",
      "Epoch 732: Train_loss 26807713792.0, Validation_loss 24675194880.0, Seconds 0.026000499725341797\n",
      "Epoch 733: Train_loss 26807631872.0, Validation_loss 24675702784.0, Seconds 0.029006242752075195\n",
      "Epoch 734: Train_loss 26807437312.0, Validation_loss 24676198400.0, Seconds 0.0315096378326416\n",
      "Epoch 735: Train_loss 26807451648.0, Validation_loss 24676876288.0, Seconds 0.031000614166259766\n",
      "Epoch 736: Train_loss 26807197696.0, Validation_loss 24672892928.0, Seconds 0.02700042724609375\n",
      "Epoch 737: Train_loss 26807199744.0, Validation_loss 24669943808.0, Seconds 0.0280914306640625\n",
      "Epoch 738: Train_loss 26807091200.0, Validation_loss 24671891456.0, Seconds 0.02899646759033203\n",
      "Epoch 739: Train_loss 26806648832.0, Validation_loss 24671991808.0, Seconds 0.029004335403442383\n",
      "Epoch 740: Train_loss 26806859776.0, Validation_loss 24670937088.0, Seconds 0.025998830795288086\n",
      "Epoch 741: Train_loss 26806573056.0, Validation_loss 24670824448.0, Seconds 0.0251004695892334\n",
      "Epoch 742: Train_loss 26806478848.0, Validation_loss 24669276160.0, Seconds 0.031006336212158203\n",
      "Epoch 743: Train_loss 26806431744.0, Validation_loss 24667803648.0, Seconds 0.030995845794677734\n",
      "Epoch 744: Train_loss 26806265856.0, Validation_loss 24668194816.0, Seconds 0.02750682830810547\n",
      "Epoch 745: Train_loss 26806208512.0, Validation_loss 24668194816.0, Seconds 0.026004314422607422\n",
      "Epoch 746: Train_loss 26806005760.0, Validation_loss 24666886144.0, Seconds 0.027005672454833984\n",
      "Epoch 747: Train_loss 26805749760.0, Validation_loss 24667027456.0, Seconds 0.02899622917175293\n",
      "Epoch 748: Train_loss 26805825536.0, Validation_loss 24664897536.0, Seconds 0.025509119033813477\n",
      "Epoch 749: Train_loss 26805612544.0, Validation_loss 24665665536.0, Seconds 0.025000810623168945\n",
      "Epoch 750: Train_loss 26805442560.0, Validation_loss 24666425344.0, Seconds 0.023001909255981445\n",
      "Epoch 751: Train_loss 26805323776.0, Validation_loss 24664000512.0, Seconds 0.030003786087036133\n",
      "Epoch 752: Train_loss 26805286912.0, Validation_loss 24666871808.0, Seconds 0.029511690139770508\n",
      "Epoch 753: Train_loss 26805141504.0, Validation_loss 24665663488.0, Seconds 0.029996871948242188\n",
      "Epoch 754: Train_loss 26805116928.0, Validation_loss 24661180416.0, Seconds 0.027004003524780273\n",
      "Epoch 755: Train_loss 26804819968.0, Validation_loss 24658401280.0, Seconds 0.025519132614135742\n",
      "Epoch 756: Train_loss 26804535296.0, Validation_loss 24660006912.0, Seconds 0.0299985408782959\n",
      "Epoch 757: Train_loss 26804494336.0, Validation_loss 24660205568.0, Seconds 0.02600550651550293\n",
      "Epoch 758: Train_loss 26804402176.0, Validation_loss 24659163136.0, Seconds 0.02600717544555664\n",
      "Epoch 759: Train_loss 26804262912.0, Validation_loss 24657057792.0, Seconds 0.026256322860717773\n",
      "Epoch 760: Train_loss 26804072448.0, Validation_loss 24656465920.0, Seconds 0.02599811553955078\n",
      "Epoch 761: Train_loss 26803863552.0, Validation_loss 24651761664.0, Seconds 0.029998779296875\n",
      "Epoch 762: Train_loss 26803685376.0, Validation_loss 24651501568.0, Seconds 0.026007890701293945\n",
      "Epoch 763: Train_loss 26803738624.0, Validation_loss 24649039872.0, Seconds 0.029432296752929688\n",
      "Epoch 764: Train_loss 26803351552.0, Validation_loss 24649621504.0, Seconds 0.027008771896362305\n",
      "Epoch 765: Train_loss 26803191808.0, Validation_loss 24649455616.0, Seconds 0.027991294860839844\n",
      "Epoch 766: Train_loss 26803007488.0, Validation_loss 24650278912.0, Seconds 0.025518417358398438\n",
      "Epoch 767: Train_loss 26802792448.0, Validation_loss 24651261952.0, Seconds 0.024993181228637695\n",
      "Epoch 768: Train_loss 26802726912.0, Validation_loss 24648577024.0, Seconds 0.022999286651611328\n",
      "Epoch 769: Train_loss 26802778112.0, Validation_loss 24647208960.0, Seconds 0.021999359130859375\n",
      "Epoch 770: Train_loss 26802302976.0, Validation_loss 24645908480.0, Seconds 0.027509689331054688\n",
      "Epoch 771: Train_loss 26802282496.0, Validation_loss 24642621440.0, Seconds 0.029000520706176758\n",
      "Epoch 772: Train_loss 26801831936.0, Validation_loss 24642478080.0, Seconds 0.025998830795288086\n",
      "Epoch 773: Train_loss 26801942528.0, Validation_loss 24642373632.0, Seconds 0.028002262115478516\n",
      "Epoch 774: Train_loss 26801588224.0, Validation_loss 24641988608.0, Seconds 0.029509782791137695\n",
      "Epoch 775: Train_loss 26801680384.0, Validation_loss 24637233152.0, Seconds 0.024997234344482422\n",
      "Epoch 776: Train_loss 26801246208.0, Validation_loss 24636495872.0, Seconds 0.03400850296020508\n",
      "Epoch 777: Train_loss 26800984064.0, Validation_loss 24637155328.0, Seconds 0.026500701904296875\n",
      "Epoch 778: Train_loss 26801027072.0, Validation_loss 24633808896.0, Seconds 0.023005247116088867\n",
      "Epoch 779: Train_loss 26800535552.0, Validation_loss 24634740736.0, Seconds 0.02699589729309082\n",
      "Epoch 780: Train_loss 26800717824.0, Validation_loss 24632535040.0, Seconds 0.09351730346679688\n",
      "Epoch 781: Train_loss 26800269312.0, Validation_loss 24630661120.0, Seconds 0.02899956703186035\n",
      "Epoch 782: Train_loss 26800205824.0, Validation_loss 24625936384.0, Seconds 0.02750229835510254\n",
      "Epoch 783: Train_loss 26800019456.0, Validation_loss 24625498112.0, Seconds 0.02500009536743164\n",
      "Epoch 784: Train_loss 26799759360.0, Validation_loss 24626366464.0, Seconds 0.030002117156982422\n",
      "Epoch 785: Train_loss 26799728640.0, Validation_loss 24626751488.0, Seconds 0.02800273895263672\n",
      "Epoch 786: Train_loss 26799392768.0, Validation_loss 24627279872.0, Seconds 0.022504091262817383\n",
      "Epoch 787: Train_loss 26799366144.0, Validation_loss 24626900992.0, Seconds 0.028999805450439453\n",
      "Epoch 788: Train_loss 26799073280.0, Validation_loss 24628283392.0, Seconds 0.03200030326843262\n",
      "Epoch 789: Train_loss 26799097856.0, Validation_loss 24627666944.0, Seconds 0.029003143310546875\n",
      "Epoch 790: Train_loss 26799017984.0, Validation_loss 24629014528.0, Seconds 0.030507564544677734\n",
      "Epoch 791: Train_loss 26798796800.0, Validation_loss 24628295680.0, Seconds 0.029999256134033203\n",
      "Epoch 792: Train_loss 26798725120.0, Validation_loss 24627697664.0, Seconds 0.02700519561767578\n",
      "Epoch 793: Train_loss 26798491648.0, Validation_loss 24626655232.0, Seconds 0.02651071548461914\n",
      "Epoch 794: Train_loss 26798612480.0, Validation_loss 24624865280.0, Seconds 0.028999805450439453\n",
      "Epoch 795: Train_loss 26798182400.0, Validation_loss 24625936384.0, Seconds 0.029001712799072266\n",
      "Epoch 796: Train_loss 26798329856.0, Validation_loss 24624177152.0, Seconds 0.029504060745239258\n",
      "Epoch 797: Train_loss 26798024704.0, Validation_loss 24623065088.0, Seconds 0.03200364112854004\n",
      "Epoch 798: Train_loss 26798024704.0, Validation_loss 24624590848.0, Seconds 0.0280153751373291\n",
      "Epoch 799: Train_loss 26797748224.0, Validation_loss 24623585280.0, Seconds 0.02298450469970703\n",
      "Epoch 800: Train_loss 26798118912.0, Validation_loss 24622733312.0, Seconds 0.022507190704345703\n",
      "Epoch 801: Train_loss 26797625344.0, Validation_loss 24621318144.0, Seconds 0.0279998779296875\n",
      "Epoch 802: Train_loss 26797580288.0, Validation_loss 24617224192.0, Seconds 0.024001121520996094\n",
      "Epoch 803: Train_loss 26797295616.0, Validation_loss 24615882752.0, Seconds 0.023001670837402344\n",
      "Epoch 804: Train_loss 26797252608.0, Validation_loss 24616599552.0, Seconds 0.024510860443115234\n",
      "Epoch 805: Train_loss 26796931072.0, Validation_loss 24616249344.0, Seconds 0.0300748348236084\n",
      "Epoch 806: Train_loss 26797111296.0, Validation_loss 24613853184.0, Seconds 0.025923490524291992\n",
      "Epoch 807: Train_loss 26796578816.0, Validation_loss 24612419584.0, Seconds 0.029021263122558594\n",
      "Epoch 808: Train_loss 26796687360.0, Validation_loss 24610387968.0, Seconds 0.03150367736816406\n",
      "Epoch 809: Train_loss 26796312576.0, Validation_loss 24610449408.0, Seconds 0.03200078010559082\n",
      "Epoch 810: Train_loss 26796556288.0, Validation_loss 24609325056.0, Seconds 0.02899909019470215\n",
      "Epoch 811: Train_loss 26795993088.0, Validation_loss 24608301056.0, Seconds 0.026526212692260742\n",
      "Epoch 812: Train_loss 26796054528.0, Validation_loss 24609026048.0, Seconds 0.02800273895263672\n",
      "Epoch 813: Train_loss 26795595776.0, Validation_loss 24607019008.0, Seconds 0.03099656105041504\n",
      "Epoch 814: Train_loss 26795761664.0, Validation_loss 24607043584.0, Seconds 0.025008678436279297\n",
      "Epoch 815: Train_loss 26795395072.0, Validation_loss 24604540928.0, Seconds 0.02450728416442871\n",
      "Epoch 816: Train_loss 26795155456.0, Validation_loss 24606517248.0, Seconds 0.030003070831298828\n",
      "Epoch 817: Train_loss 26794999808.0, Validation_loss 24607145984.0, Seconds 0.024004459381103516\n",
      "Epoch 818: Train_loss 26794645504.0, Validation_loss 24605609984.0, Seconds 0.025007963180541992\n",
      "Epoch 819: Train_loss 26794784768.0, Validation_loss 24605145088.0, Seconds 0.0265047550201416\n",
      "Epoch 820: Train_loss 26794211328.0, Validation_loss 24606214144.0, Seconds 0.030000686645507812\n",
      "Epoch 821: Train_loss 26794217472.0, Validation_loss 24605724672.0, Seconds 0.024999618530273438\n",
      "Epoch 822: Train_loss 26794039296.0, Validation_loss 24603287552.0, Seconds 0.027518749237060547\n",
      "Epoch 823: Train_loss 26793637888.0, Validation_loss 24605908992.0, Seconds 0.025005578994750977\n",
      "Epoch 824: Train_loss 26793410560.0, Validation_loss 24604237824.0, Seconds 0.023001909255981445\n",
      "Epoch 825: Train_loss 26793222144.0, Validation_loss 24603267072.0, Seconds 0.026993751525878906\n",
      "Epoch 826: Train_loss 26793164800.0, Validation_loss 24603541504.0, Seconds 0.0295107364654541\n",
      "Epoch 827: Train_loss 26792957952.0, Validation_loss 24602193920.0, Seconds 0.029001235961914062\n",
      "Epoch 828: Train_loss 26792765440.0, Validation_loss 24602157056.0, Seconds 0.03299903869628906\n",
      "Epoch 829: Train_loss 26792572928.0, Validation_loss 24603594752.0, Seconds 0.028510332107543945\n",
      "Epoch 830: Train_loss 26792497152.0, Validation_loss 24600238080.0, Seconds 0.02299976348876953\n",
      "Epoch 831: Train_loss 26792429568.0, Validation_loss 24601929728.0, Seconds 0.024001121520996094\n",
      "Epoch 832: Train_loss 26792146944.0, Validation_loss 24601726976.0, Seconds 0.04100155830383301\n",
      "Epoch 833: Train_loss 26792040448.0, Validation_loss 24603211776.0, Seconds 0.03150582313537598\n",
      "Epoch 834: Train_loss 26791917568.0, Validation_loss 24602648576.0, Seconds 0.024000883102416992\n",
      "Epoch 835: Train_loss 26791874560.0, Validation_loss 24600741888.0, Seconds 0.029001474380493164\n",
      "Epoch 836: Train_loss 26791682048.0, Validation_loss 24599896064.0, Seconds 0.02499985694885254\n",
      "Epoch 837: Train_loss 26791706624.0, Validation_loss 24602759168.0, Seconds 0.026505708694458008\n",
      "Epoch 838: Train_loss 26791632896.0, Validation_loss 24599031808.0, Seconds 0.030000686645507812\n",
      "Epoch 839: Train_loss 26791196672.0, Validation_loss 24600354816.0, Seconds 0.02800154685974121\n",
      "Epoch 840: Train_loss 26791387136.0, Validation_loss 24601581568.0, Seconds 0.03350996971130371\n",
      "Epoch 841: Train_loss 26791063552.0, Validation_loss 24600930304.0, Seconds 0.030001163482666016\n",
      "Epoch 842: Train_loss 26790991872.0, Validation_loss 24599822336.0, Seconds 0.0310060977935791\n",
      "Epoch 843: Train_loss 26790772736.0, Validation_loss 24600995840.0, Seconds 0.028519392013549805\n",
      "Epoch 844: Train_loss 26790828032.0, Validation_loss 24602873856.0, Seconds 0.02899789810180664\n",
      "Epoch 845: Train_loss 26790762496.0, Validation_loss 24599875584.0, Seconds 0.029002666473388672\n",
      "Epoch 846: Train_loss 26790514688.0, Validation_loss 24602544128.0, Seconds 0.028999805450439453\n",
      "Epoch 847: Train_loss 26790488064.0, Validation_loss 24597960704.0, Seconds 0.02751946449279785\n",
      "Epoch 848: Train_loss 26790467584.0, Validation_loss 24600338432.0, Seconds 0.024991750717163086\n",
      "Epoch 849: Train_loss 26790326272.0, Validation_loss 24600569856.0, Seconds 0.025998830795288086\n",
      "Epoch 850: Train_loss 26790117376.0, Validation_loss 24599572480.0, Seconds 0.023006916046142578\n",
      "Epoch 851: Train_loss 26789992448.0, Validation_loss 24600569856.0, Seconds 0.025501489639282227\n",
      "Epoch 852: Train_loss 26789763072.0, Validation_loss 24600788992.0, Seconds 0.0279998779296875\n",
      "Epoch 853: Train_loss 26789978112.0, Validation_loss 24598829056.0, Seconds 0.030001401901245117\n",
      "Epoch 854: Train_loss 26789695488.0, Validation_loss 24598943744.0, Seconds 0.02850937843322754\n",
      "Epoch 855: Train_loss 26789664768.0, Validation_loss 24599070720.0, Seconds 0.029001712799072266\n",
      "Epoch 856: Train_loss 26789611520.0, Validation_loss 24598257664.0, Seconds 0.03099966049194336\n",
      "Epoch 857: Train_loss 26789509120.0, Validation_loss 24597649408.0, Seconds 0.028004884719848633\n",
      "Epoch 858: Train_loss 26789167104.0, Validation_loss 24598274048.0, Seconds 0.02851104736328125\n",
      "Epoch 859: Train_loss 26789466112.0, Validation_loss 24598112256.0, Seconds 0.027997970581054688\n",
      "Epoch 860: Train_loss 26789203968.0, Validation_loss 24598032384.0, Seconds 0.024999618530273438\n",
      "Epoch 861: Train_loss 26789029888.0, Validation_loss 24596918272.0, Seconds 0.027570724487304688\n",
      "Epoch 862: Train_loss 26788964352.0, Validation_loss 24595845120.0, Seconds 0.02399420738220215\n",
      "Epoch 863: Train_loss 26788782080.0, Validation_loss 24598231040.0, Seconds 0.02400040626525879\n",
      "Epoch 864: Train_loss 26788786176.0, Validation_loss 24596611072.0, Seconds 0.025002241134643555\n",
      "Epoch 865: Train_loss 26788569088.0, Validation_loss 24596563968.0, Seconds 0.02551102638244629\n",
      "Epoch 866: Train_loss 26788696064.0, Validation_loss 24596891648.0, Seconds 0.02699875831604004\n",
      "Epoch 867: Train_loss 26788462592.0, Validation_loss 24594067456.0, Seconds 0.029005765914916992\n",
      "Epoch 868: Train_loss 26788546560.0, Validation_loss 24595159040.0, Seconds 0.027019500732421875\n",
      "Epoch 869: Train_loss 26788325376.0, Validation_loss 24595120128.0, Seconds 0.030257225036621094\n",
      "Epoch 870: Train_loss 26788276224.0, Validation_loss 24595585024.0, Seconds 0.02499842643737793\n",
      "Epoch 871: Train_loss 26788194304.0, Validation_loss 24594798592.0, Seconds 0.02699875831604004\n",
      "Epoch 872: Train_loss 26788329472.0, Validation_loss 24592717824.0, Seconds 0.02700638771057129\n",
      "Epoch 873: Train_loss 26787999744.0, Validation_loss 24591679488.0, Seconds 0.028502941131591797\n",
      "Epoch 874: Train_loss 26787788800.0, Validation_loss 24592347136.0, Seconds 0.033000946044921875\n",
      "Epoch 875: Train_loss 26787659776.0, Validation_loss 24592439296.0, Seconds 0.027001142501831055\n",
      "Epoch 876: Train_loss 26787604480.0, Validation_loss 24591183872.0, Seconds 0.0285184383392334\n",
      "Epoch 877: Train_loss 26787629056.0, Validation_loss 24591955968.0, Seconds 0.02300119400024414\n",
      "Epoch 878: Train_loss 26787614720.0, Validation_loss 24588470272.0, Seconds 0.028995513916015625\n",
      "Epoch 879: Train_loss 26787262464.0, Validation_loss 24584876032.0, Seconds 0.028019189834594727\n",
      "Epoch 880: Train_loss 26787065856.0, Validation_loss 24579303424.0, Seconds 0.02752232551574707\n",
      "Epoch 881: Train_loss 26787127296.0, Validation_loss 24574412800.0, Seconds 0.026988983154296875\n",
      "Epoch 882: Train_loss 26786619392.0, Validation_loss 24577552384.0, Seconds 0.025003433227539062\n",
      "Epoch 883: Train_loss 26786582528.0, Validation_loss 24577611776.0, Seconds 0.02851104736328125\n",
      "Epoch 884: Train_loss 26786467840.0, Validation_loss 24576776192.0, Seconds 0.028998613357543945\n",
      "Epoch 885: Train_loss 26786136064.0, Validation_loss 24576909312.0, Seconds 0.023002147674560547\n",
      "Epoch 886: Train_loss 26786197504.0, Validation_loss 24575991808.0, Seconds 0.028997182846069336\n",
      "Epoch 887: Train_loss 26785931264.0, Validation_loss 24573900800.0, Seconds 0.022508859634399414\n",
      "Epoch 888: Train_loss 26785769472.0, Validation_loss 24575145984.0, Seconds 0.023000717163085938\n",
      "Epoch 889: Train_loss 26785703936.0, Validation_loss 24574613504.0, Seconds 0.023000240325927734\n",
      "Epoch 890: Train_loss 26785550336.0, Validation_loss 24572110848.0, Seconds 0.02399897575378418\n",
      "Epoch 891: Train_loss 26785333248.0, Validation_loss 24568315904.0, Seconds 0.09252023696899414\n",
      "Epoch 892: Train_loss 26785282048.0, Validation_loss 24563097600.0, Seconds 0.026996374130249023\n",
      "Epoch 893: Train_loss 26784999424.0, Validation_loss 24563462144.0, Seconds 0.023506879806518555\n",
      "Epoch 894: Train_loss 26784745472.0, Validation_loss 24565385216.0, Seconds 0.027001142501831055\n",
      "Epoch 895: Train_loss 26784729088.0, Validation_loss 24563097600.0, Seconds 0.028997421264648438\n",
      "Epoch 896: Train_loss 26784473088.0, Validation_loss 24563607552.0, Seconds 0.025519132614135742\n",
      "Epoch 897: Train_loss 26784237568.0, Validation_loss 24563191808.0, Seconds 0.030004501342773438\n",
      "Epoch 898: Train_loss 26784342016.0, Validation_loss 24560517120.0, Seconds 0.031000375747680664\n",
      "Epoch 899: Train_loss 26783948800.0, Validation_loss 24560371712.0, Seconds 0.033003807067871094\n",
      "Epoch 900: Train_loss 26784040960.0, Validation_loss 24559710208.0, Seconds 0.029510498046875\n",
      "Epoch 901: Train_loss 26783887360.0, Validation_loss 24557793280.0, Seconds 0.03199911117553711\n",
      "Epoch 902: Train_loss 26783621120.0, Validation_loss 24558583808.0, Seconds 0.029004812240600586\n",
      "Epoch 903: Train_loss 26783713280.0, Validation_loss 24558614528.0, Seconds 0.02452254295349121\n",
      "Epoch 904: Train_loss 26783520768.0, Validation_loss 24556955648.0, Seconds 0.02800273895263672\n",
      "Epoch 905: Train_loss 26783475712.0, Validation_loss 24555522048.0, Seconds 0.024001598358154297\n",
      "Epoch 906: Train_loss 26783029248.0, Validation_loss 24556914688.0, Seconds 0.023995399475097656\n",
      "Epoch 907: Train_loss 26783227904.0, Validation_loss 24553103360.0, Seconds 0.025505542755126953\n",
      "Epoch 908: Train_loss 26782734336.0, Validation_loss 24554620928.0, Seconds 0.02500748634338379\n",
      "Epoch 909: Train_loss 26782855168.0, Validation_loss 24554498048.0, Seconds 0.022999048233032227\n",
      "Epoch 910: Train_loss 26782638080.0, Validation_loss 24555014144.0, Seconds 0.0330049991607666\n",
      "Epoch 911: Train_loss 26782588928.0, Validation_loss 24556369920.0, Seconds 0.023518800735473633\n",
      "Epoch 912: Train_loss 26782541824.0, Validation_loss 24553924608.0, Seconds 0.024001121520996094\n",
      "Epoch 913: Train_loss 26782255104.0, Validation_loss 24555046912.0, Seconds 0.02699565887451172\n",
      "Epoch 914: Train_loss 26782435328.0, Validation_loss 24556140544.0, Seconds 0.02600717544555664\n",
      "Epoch 915: Train_loss 26782111744.0, Validation_loss 24554047488.0, Seconds 0.026514291763305664\n",
      "Epoch 916: Train_loss 26782130176.0, Validation_loss 24553623552.0, Seconds 0.0279998779296875\n",
      "Epoch 917: Train_loss 26781806592.0, Validation_loss 24554366976.0, Seconds 0.025999069213867188\n",
      "Epoch 918: Train_loss 26782031872.0, Validation_loss 24554246144.0, Seconds 0.02851271629333496\n",
      "Epoch 919: Train_loss 26781888512.0, Validation_loss 24552044544.0, Seconds 0.026999235153198242\n",
      "Epoch 920: Train_loss 26781687808.0, Validation_loss 24552105984.0, Seconds 0.0260007381439209\n",
      "Epoch 921: Train_loss 26781480960.0, Validation_loss 24553306112.0, Seconds 0.02700018882751465\n",
      "Epoch 922: Train_loss 26781384704.0, Validation_loss 24554977280.0, Seconds 0.02450871467590332\n",
      "Epoch 923: Train_loss 26781331456.0, Validation_loss 24553758720.0, Seconds 0.0279998779296875\n",
      "Epoch 924: Train_loss 26781181952.0, Validation_loss 24555464704.0, Seconds 0.02499985694885254\n",
      "Epoch 925: Train_loss 26781020160.0, Validation_loss 24553680896.0, Seconds 0.027004003524780273\n",
      "Epoch 926: Train_loss 26781003776.0, Validation_loss 24553140224.0, Seconds 0.021505355834960938\n",
      "Epoch 927: Train_loss 26780811264.0, Validation_loss 24553877504.0, Seconds 0.0279998779296875\n",
      "Epoch 928: Train_loss 26780588032.0, Validation_loss 24554100736.0, Seconds 0.029001235961914062\n",
      "Epoch 929: Train_loss 26780426240.0, Validation_loss 24555220992.0, Seconds 0.030004024505615234\n",
      "Epoch 930: Train_loss 26780436480.0, Validation_loss 24554309632.0, Seconds 0.03050708770751953\n",
      "Epoch 931: Train_loss 26780315648.0, Validation_loss 24554557440.0, Seconds 0.02900099754333496\n",
      "Epoch 932: Train_loss 26780176384.0, Validation_loss 24553496576.0, Seconds 0.03400301933288574\n",
      "Epoch 933: Train_loss 26780147712.0, Validation_loss 24553326592.0, Seconds 0.02350640296936035\n",
      "Epoch 934: Train_loss 26779850752.0, Validation_loss 24551596032.0, Seconds 0.036002397537231445\n",
      "Epoch 935: Train_loss 26779834368.0, Validation_loss 24556795904.0, Seconds 0.035999298095703125\n",
      "Epoch 936: Train_loss 26779770880.0, Validation_loss 24552726528.0, Seconds 0.027513742446899414\n",
      "Epoch 937: Train_loss 26779797504.0, Validation_loss 24552433664.0, Seconds 0.030001401901245117\n",
      "Epoch 938: Train_loss 26779588608.0, Validation_loss 24551602176.0, Seconds 0.027997732162475586\n",
      "Epoch 939: Train_loss 26779420672.0, Validation_loss 24552927232.0, Seconds 0.029529571533203125\n",
      "Epoch 940: Train_loss 26779551744.0, Validation_loss 24551346176.0, Seconds 0.030007600784301758\n",
      "Epoch 941: Train_loss 26779318272.0, Validation_loss 24549869568.0, Seconds 0.03199577331542969\n",
      "Epoch 942: Train_loss 26779252736.0, Validation_loss 24550729728.0, Seconds 0.031010866165161133\n",
      "Epoch 943: Train_loss 26779248640.0, Validation_loss 24550094848.0, Seconds 0.027517318725585938\n",
      "Epoch 944: Train_loss 26779011072.0, Validation_loss 24550547456.0, Seconds 0.027995586395263672\n",
      "Epoch 945: Train_loss 26779058176.0, Validation_loss 24551903232.0, Seconds 0.029000520706176758\n",
      "Epoch 946: Train_loss 26778990592.0, Validation_loss 24550481920.0, Seconds 0.026515722274780273\n",
      "Epoch 947: Train_loss 26778951680.0, Validation_loss 24549928960.0, Seconds 0.0249936580657959\n",
      "Epoch 948: Train_loss 26778869760.0, Validation_loss 24548777984.0, Seconds 0.03399991989135742\n",
      "Epoch 949: Train_loss 26778632192.0, Validation_loss 24549163008.0, Seconds 0.025003910064697266\n",
      "Epoch 950: Train_loss 26778689536.0, Validation_loss 24549906432.0, Seconds 0.024506568908691406\n",
      "Epoch 951: Train_loss 26778490880.0, Validation_loss 24547323904.0, Seconds 0.028001785278320312\n",
      "Epoch 952: Train_loss 26778685440.0, Validation_loss 24547864576.0, Seconds 0.028998136520385742\n",
      "Epoch 953: Train_loss 26778220544.0, Validation_loss 24547735552.0, Seconds 0.02600860595703125\n",
      "Epoch 954: Train_loss 26778435584.0, Validation_loss 24549048320.0, Seconds 0.025527238845825195\n",
      "Epoch 955: Train_loss 26778195968.0, Validation_loss 24547725312.0, Seconds 0.037000417709350586\n",
      "Epoch 956: Train_loss 26778279936.0, Validation_loss 24545564672.0, Seconds 0.031002044677734375\n",
      "Epoch 957: Train_loss 26777976832.0, Validation_loss 24546072576.0, Seconds 0.027506351470947266\n",
      "Epoch 958: Train_loss 26778243072.0, Validation_loss 24546416640.0, Seconds 0.0280001163482666\n",
      "Epoch 959: Train_loss 26777948160.0, Validation_loss 24545650688.0, Seconds 0.025999784469604492\n",
      "Epoch 960: Train_loss 26777999360.0, Validation_loss 24546777088.0, Seconds 0.023003816604614258\n",
      "Epoch 961: Train_loss 26777710592.0, Validation_loss 24546349056.0, Seconds 0.02851104736328125\n",
      "Epoch 962: Train_loss 26778009600.0, Validation_loss 24545261568.0, Seconds 0.024996280670166016\n",
      "Epoch 963: Train_loss 26777550848.0, Validation_loss 24544892928.0, Seconds 0.028005599975585938\n",
      "Epoch 964: Train_loss 26777792512.0, Validation_loss 24545288192.0, Seconds 0.02850484848022461\n",
      "Epoch 965: Train_loss 26777690112.0, Validation_loss 24544839680.0, Seconds 0.02699875831604004\n",
      "Epoch 966: Train_loss 26777516032.0, Validation_loss 24545695744.0, Seconds 0.029001712799072266\n",
      "Epoch 967: Train_loss 26777665536.0, Validation_loss 24544008192.0, Seconds 0.0310056209564209\n",
      "Epoch 968: Train_loss 26777311232.0, Validation_loss 24544038912.0, Seconds 0.023516416549682617\n",
      "Epoch 969: Train_loss 26777501696.0, Validation_loss 24544616448.0, Seconds 0.02700066566467285\n",
      "Epoch 970: Train_loss 26777073664.0, Validation_loss 24544741376.0, Seconds 0.025997638702392578\n",
      "Epoch 971: Train_loss 26777255936.0, Validation_loss 24544563200.0, Seconds 0.024005413055419922\n",
      "Epoch 972: Train_loss 26776907776.0, Validation_loss 24544002048.0, Seconds 0.027507781982421875\n",
      "Epoch 973: Train_loss 26777096192.0, Validation_loss 24544978944.0, Seconds 0.02700185775756836\n",
      "Epoch 974: Train_loss 26777022464.0, Validation_loss 24541442048.0, Seconds 0.025002717971801758\n",
      "Epoch 975: Train_loss 26776924160.0, Validation_loss 24542062592.0, Seconds 0.026000261306762695\n",
      "Epoch 976: Train_loss 26776870912.0, Validation_loss 24543682560.0, Seconds 0.03050994873046875\n",
      "Epoch 977: Train_loss 26776645632.0, Validation_loss 24542078976.0, Seconds 0.0370028018951416\n",
      "Epoch 978: Train_loss 26776809472.0, Validation_loss 24542412800.0, Seconds 0.024007320404052734\n",
      "Epoch 979: Train_loss 26776573952.0, Validation_loss 24542068736.0, Seconds 0.02551579475402832\n",
      "Epoch 980: Train_loss 26776451072.0, Validation_loss 24539965440.0, Seconds 0.029999971389770508\n",
      "Epoch 981: Train_loss 26776616960.0, Validation_loss 24540981248.0, Seconds 0.033000946044921875\n",
      "Epoch 982: Train_loss 26776340480.0, Validation_loss 24540667904.0, Seconds 0.026520252227783203\n",
      "Epoch 983: Train_loss 26776465408.0, Validation_loss 24539232256.0, Seconds 0.026999950408935547\n",
      "Epoch 984: Train_loss 26776272896.0, Validation_loss 24540577792.0, Seconds 0.024007081985473633\n",
      "Epoch 985: Train_loss 26776229888.0, Validation_loss 24542085120.0, Seconds 0.02799057960510254\n",
      "Epoch 986: Train_loss 26776141824.0, Validation_loss 24540469248.0, Seconds 0.02905869483947754\n",
      "Epoch 987: Train_loss 26776107008.0, Validation_loss 24540448768.0, Seconds 0.022998809814453125\n",
      "Epoch 988: Train_loss 26775920640.0, Validation_loss 24538865664.0, Seconds 0.03500199317932129\n",
      "Epoch 989: Train_loss 26775998464.0, Validation_loss 24539670528.0, Seconds 0.029519319534301758\n",
      "Epoch 990: Train_loss 26775887872.0, Validation_loss 24540215296.0, Seconds 0.0250091552734375\n",
      "Epoch 991: Train_loss 26775801856.0, Validation_loss 24539969536.0, Seconds 0.02499675750732422\n",
      "Epoch 992: Train_loss 26775832576.0, Validation_loss 24539117568.0, Seconds 0.028998136520385742\n",
      "Epoch 993: Train_loss 26775742464.0, Validation_loss 24538355712.0, Seconds 0.025508403778076172\n",
      "Epoch 994: Train_loss 26775461888.0, Validation_loss 24539942912.0, Seconds 0.031008243560791016\n",
      "Epoch 995: Train_loss 26775531520.0, Validation_loss 24537743360.0, Seconds 0.034993886947631836\n",
      "Epoch 996: Train_loss 26775492608.0, Validation_loss 24539260928.0, Seconds 0.029504776000976562\n",
      "Epoch 997: Train_loss 26775416832.0, Validation_loss 24539953152.0, Seconds 0.027000904083251953\n",
      "Epoch 998: Train_loss 26775205888.0, Validation_loss 24536766464.0, Seconds 0.02899956703186035\n",
      "Epoch 999: Train_loss 26775330816.0, Validation_loss 24537833472.0, Seconds 0.025001049041748047\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).view(-1, 1)\n",
    "        output = net(data)\n",
    "        L = loss(output, target)\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    y_train_pred = net(X_train)\n",
    "    training_loss = loss(y_train_pred, y_train.view(-1, 1)).item()\n",
    "    y_test_pred = net(X_test)\n",
    "    test_loss = loss(y_test_pred, y_test.view(-1, 1)).item()\n",
    "    \n",
    "    train_losses.append(training_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Epoch {}: Train_loss {}, Validation_loss {}, Seconds {}\".format(epoch, training_loss, test_loss, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2d3288ba910>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(test_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss values\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = net(X_train)\n",
    "y_test_pred = net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.04e+05\n",
      "train MSE: 2.68e+10\n",
      "train R2: 0.446\n"
     ]
    }
   ],
   "source": [
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred.detach().numpy())))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred.detach().numpy())))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 1.03e+05\n",
      "test MSE: 2.45e+10\n",
      "test R2: 0.507\n"
     ]
    }
   ],
   "source": [
    "print('test MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred.detach().numpy())))\n",
    "print('test MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred.detach().numpy())))\n",
    "print('test R2: {0:.3f}'.format(r2_score(y_test, y_test_pred.detach().numpy())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
