{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2.csv')\n",
    "df.dropna(subset=['price'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "target = 'price'\n",
    "features.remove(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target].str.strip(\"$\").str.replace(\",\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "class Data_Transformer(object):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        self.mean_weight = new_df[\"Weight\"].mean() # obtain mean weight\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase weekday\n",
    "        self.majority_month = new_df[\"Month\"].mode()[0] # obtain majority purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        self.majority_weekday = new_df[\"Weekday\"].mode()[0] # obtain majority purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df[\"Ingredient Number\"] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        self.mean_ingredient_number = new_df[\"Ingredient Number\"].mean() # obtain mean ingredient number\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with median ingredient number\n",
    "        self.pl_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Level\"] = pd.Series(self.pl_le.fit_transform(X[\"product_level\"])) # fit and transform product level with label-encoder\n",
    "        self.majority_product_level = new_df[\"Product Level\"].mode()[0] # obtain majority product level code\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        self.pt_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Type\"] = pd.Series(self.pt_le.fit_transform(X[\"product_type\"])) # fit and transform product type with label-encoder\n",
    "        self.majority_product_type = new_df[\"Product Type\"].mode()[0] # obtain majority product type code\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        self.cost_imputer = XGBRegressor() # create a XGBoost imputer for cost\n",
    "        df_for_imputing_cost = new_df.dropna() # create training data for cost imputer by dropping missing data\n",
    "        self.cost_imputer.fit(df_for_imputing_cost[[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]], df_for_imputing_cost[\"Cost\"]) # fit cost imputer\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df['Ingredient Number'] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with mean ingredient number\n",
    "        new_df[\"Product Level\"] = self.pl_le.transform(X[\"product_level\"]) # transform product level with label-encoder\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        new_df[\"Product Type\"] = self.pt_le.transform(X[\"product_type\"]) # transform product type with label-encoder\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        imputed_cost = pd.Series(self.cost_imputer.predict(new_df[new_df[\"Cost\"].isnull()][[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]])) # obtain imputed cost\n",
    "        imputed_cost.index = new_df[new_df[\"Cost\"].isnull()][\"Cost\"].index # set index of imputed cost\n",
    "        new_df[\"Cost\"].fillna(imputed_cost,inplace=True) # fill in missing cost with imputed cost\n",
    "        return new_df # return new_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def weight2num(self, x): # function to convert weight to number\n",
    "        if type(x) == str:\n",
    "            x = x.strip('Kg').split(' Ton ')\n",
    "            return float(x[0])*1000+float(x[1])\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def get_numbers(self, x): # function to get number of ingredients in recipe\n",
    "        if type(x) == str:\n",
    "            return len(x.split(','))\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = Data_Transformer()\n",
    "X_train = np.array(dft.fit_transform(X_train))\n",
    "X_test = np.array(dft.transform(X_test))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = nn.Sequential(nn.Linear(7, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "batch_size = 500\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSELoss(reduction='mean')\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train_loss 77560274944.0, Validation_loss 79471566848.0, Seconds 0.031000375747680664\n",
      "Epoch 1: Train_loss 73004261376.0, Validation_loss 74446602240.0, Seconds 0.02299976348876953\n",
      "Epoch 2: Train_loss 67429691392.0, Validation_loss 68305014784.0, Seconds 0.020002365112304688\n",
      "Epoch 3: Train_loss 60373929984.0, Validation_loss 60544319488.0, Seconds 0.10002374649047852\n",
      "Epoch 4: Train_loss 51825283072.0, Validation_loss 51164545024.0, Seconds 0.0220034122467041\n",
      "Epoch 5: Train_loss 42614366208.0, Validation_loss 41109454848.0, Seconds 0.023000717163085938\n",
      "Epoch 6: Train_loss 35103309824.0, Validation_loss 33018689536.0, Seconds 0.019999980926513672\n",
      "Epoch 7: Train_loss 32265117696.0, Validation_loss 30167531520.0, Seconds 0.025005102157592773\n",
      "Epoch 8: Train_loss 33121460224.0, Validation_loss 31321493504.0, Seconds 0.02402782440185547\n",
      "Epoch 9: Train_loss 32896624640.0, Validation_loss 31043618816.0, Seconds 0.02199864387512207\n",
      "Epoch 10: Train_loss 32283432960.0, Validation_loss 30232365056.0, Seconds 0.026000499725341797\n",
      "Epoch 11: Train_loss 32351318016.0, Validation_loss 30215852032.0, Seconds 0.023001909255981445\n",
      "Epoch 12: Train_loss 32389392384.0, Validation_loss 30246973440.0, Seconds 0.020061254501342773\n",
      "Epoch 13: Train_loss 32273772544.0, Validation_loss 30163965952.0, Seconds 0.02100062370300293\n",
      "Epoch 14: Train_loss 32245114880.0, Validation_loss 30167836672.0, Seconds 0.02299976348876953\n",
      "Epoch 15: Train_loss 32242937856.0, Validation_loss 30162571264.0, Seconds 0.022000551223754883\n",
      "Epoch 16: Train_loss 32250800128.0, Validation_loss 30152194048.0, Seconds 0.022003173828125\n",
      "Epoch 17: Train_loss 32258111488.0, Validation_loss 30150195200.0, Seconds 0.01650691032409668\n",
      "Epoch 18: Train_loss 32243087360.0, Validation_loss 30143121408.0, Seconds 0.01699686050415039\n",
      "Epoch 19: Train_loss 32236703744.0, Validation_loss 30141106176.0, Seconds 0.018000364303588867\n",
      "Epoch 20: Train_loss 32235462656.0, Validation_loss 30138693632.0, Seconds 0.01800060272216797\n",
      "Epoch 21: Train_loss 32235409408.0, Validation_loss 30136508416.0, Seconds 0.01800084114074707\n",
      "Epoch 22: Train_loss 32233265152.0, Validation_loss 30135275520.0, Seconds 0.02350926399230957\n",
      "Epoch 23: Train_loss 32229328896.0, Validation_loss 30132586496.0, Seconds 0.0220029354095459\n",
      "Epoch 24: Train_loss 32225746944.0, Validation_loss 30130161664.0, Seconds 0.021996736526489258\n",
      "Epoch 25: Train_loss 32222930944.0, Validation_loss 30128191488.0, Seconds 0.020007848739624023\n",
      "Epoch 26: Train_loss 32220411904.0, Validation_loss 30126610432.0, Seconds 0.02300119400024414\n",
      "Epoch 27: Train_loss 32217722880.0, Validation_loss 30124582912.0, Seconds 0.022050142288208008\n",
      "Epoch 28: Train_loss 32214509568.0, Validation_loss 30122432512.0, Seconds 0.0240023136138916\n",
      "Epoch 29: Train_loss 32210868224.0, Validation_loss 30120798208.0, Seconds 0.02299785614013672\n",
      "Epoch 30: Train_loss 32207345664.0, Validation_loss 30118389760.0, Seconds 0.02199864387512207\n",
      "Epoch 31: Train_loss 32202485760.0, Validation_loss 30114879488.0, Seconds 0.022048473358154297\n",
      "Epoch 32: Train_loss 32196245504.0, Validation_loss 30113275904.0, Seconds 0.023000717163085938\n",
      "Epoch 33: Train_loss 32190388224.0, Validation_loss 30108882944.0, Seconds 0.018999099731445312\n",
      "Epoch 34: Train_loss 32171786240.0, Validation_loss 30091489280.0, Seconds 0.017999887466430664\n",
      "Epoch 35: Train_loss 32159365120.0, Validation_loss 30105546752.0, Seconds 0.017006635665893555\n",
      "Epoch 36: Train_loss 32161445888.0, Validation_loss 30092402688.0, Seconds 0.018006563186645508\n",
      "Epoch 37: Train_loss 32153518080.0, Validation_loss 30089986048.0, Seconds 0.020506620407104492\n",
      "Epoch 38: Train_loss 32138831872.0, Validation_loss 30091718656.0, Seconds 0.017998218536376953\n",
      "Epoch 39: Train_loss 32139646976.0, Validation_loss 30086991872.0, Seconds 0.02100062370300293\n",
      "Epoch 40: Train_loss 32136767488.0, Validation_loss 30085144576.0, Seconds 0.02200007438659668\n",
      "Epoch 41: Train_loss 32126038016.0, Validation_loss 30082734080.0, Seconds 0.02451038360595703\n",
      "Epoch 42: Train_loss 32119394304.0, Validation_loss 30078777344.0, Seconds 0.021999835968017578\n",
      "Epoch 43: Train_loss 32108292096.0, Validation_loss 30078060544.0, Seconds 0.02400064468383789\n",
      "Epoch 44: Train_loss 32109162496.0, Validation_loss 30070974464.0, Seconds 0.020999431610107422\n",
      "Epoch 45: Train_loss 32100841472.0, Validation_loss 30067890176.0, Seconds 0.021015644073486328\n",
      "Epoch 46: Train_loss 32092012544.0, Validation_loss 30065119232.0, Seconds 0.020227670669555664\n",
      "Epoch 47: Train_loss 32089718784.0, Validation_loss 30063489024.0, Seconds 0.016997814178466797\n",
      "Epoch 48: Train_loss 32078389248.0, Validation_loss 30057218048.0, Seconds 0.02000117301940918\n",
      "Epoch 49: Train_loss 32067438592.0, Validation_loss 30050596864.0, Seconds 0.01900005340576172\n",
      "Epoch 50: Train_loss 32049149952.0, Validation_loss 30033874944.0, Seconds 0.022008657455444336\n",
      "Epoch 51: Train_loss 32026836992.0, Validation_loss 30028083200.0, Seconds 0.020511627197265625\n",
      "Epoch 52: Train_loss 32018829312.0, Validation_loss 30008176640.0, Seconds 0.02001047134399414\n",
      "Epoch 53: Train_loss 32004610048.0, Validation_loss 30002030592.0, Seconds 0.02298593521118164\n",
      "Epoch 54: Train_loss 31994322944.0, Validation_loss 29996193792.0, Seconds 0.022998571395874023\n",
      "Epoch 55: Train_loss 31986348032.0, Validation_loss 29988620288.0, Seconds 0.026513338088989258\n",
      "Epoch 56: Train_loss 31974680576.0, Validation_loss 29981960192.0, Seconds 0.02299976348876953\n",
      "Epoch 57: Train_loss 31963322368.0, Validation_loss 29975224320.0, Seconds 0.024999618530273438\n",
      "Epoch 58: Train_loss 31953379328.0, Validation_loss 29966884864.0, Seconds 0.021000385284423828\n",
      "Epoch 59: Train_loss 31939473408.0, Validation_loss 29958053888.0, Seconds 0.020005226135253906\n",
      "Epoch 60: Train_loss 31924137984.0, Validation_loss 29942841344.0, Seconds 0.025094985961914062\n",
      "Epoch 61: Train_loss 31905572864.0, Validation_loss 29924599808.0, Seconds 0.023014307022094727\n",
      "Epoch 62: Train_loss 31869724672.0, Validation_loss 29890717696.0, Seconds 0.02298736572265625\n",
      "Epoch 63: Train_loss 31836854272.0, Validation_loss 29866835968.0, Seconds 0.024004459381103516\n",
      "Epoch 64: Train_loss 31828428800.0, Validation_loss 29842288640.0, Seconds 0.02666759490966797\n",
      "Epoch 65: Train_loss 31807283200.0, Validation_loss 29829744640.0, Seconds 0.02500009536743164\n",
      "Epoch 66: Train_loss 31792064512.0, Validation_loss 29817366528.0, Seconds 0.024001121520996094\n",
      "Epoch 67: Train_loss 31784722432.0, Validation_loss 29807374336.0, Seconds 0.021005630493164062\n",
      "Epoch 68: Train_loss 31769511936.0, Validation_loss 29796947968.0, Seconds 0.02251434326171875\n",
      "Epoch 69: Train_loss 31757568000.0, Validation_loss 29785622528.0, Seconds 0.023998737335205078\n",
      "Epoch 70: Train_loss 31747733504.0, Validation_loss 29775337472.0, Seconds 0.09308052062988281\n",
      "Epoch 71: Train_loss 31735541760.0, Validation_loss 29764835328.0, Seconds 0.016999244689941406\n",
      "Epoch 72: Train_loss 31725715456.0, Validation_loss 29754398720.0, Seconds 0.017998456954956055\n",
      "Epoch 73: Train_loss 31715325952.0, Validation_loss 29744750592.0, Seconds 0.022001266479492188\n",
      "Epoch 74: Train_loss 31705194496.0, Validation_loss 29734848512.0, Seconds 0.023023128509521484\n",
      "Epoch 75: Train_loss 31696148480.0, Validation_loss 29725216768.0, Seconds 0.023000717163085938\n",
      "Epoch 76: Train_loss 31687376896.0, Validation_loss 29715959808.0, Seconds 0.018998146057128906\n",
      "Epoch 77: Train_loss 31677550592.0, Validation_loss 29706543104.0, Seconds 0.020001888275146484\n",
      "Epoch 78: Train_loss 31669813248.0, Validation_loss 29697644544.0, Seconds 0.02000141143798828\n",
      "Epoch 79: Train_loss 31661099008.0, Validation_loss 29688576000.0, Seconds 0.022020339965820312\n",
      "Epoch 80: Train_loss 31652818944.0, Validation_loss 29679687680.0, Seconds 0.021009206771850586\n",
      "Epoch 81: Train_loss 31645532160.0, Validation_loss 29671174144.0, Seconds 0.023998737335205078\n",
      "Epoch 82: Train_loss 31638155264.0, Validation_loss 29662748672.0, Seconds 0.02199268341064453\n",
      "Epoch 83: Train_loss 31631017984.0, Validation_loss 29654560768.0, Seconds 0.020018815994262695\n",
      "Epoch 84: Train_loss 31624710144.0, Validation_loss 29646692352.0, Seconds 0.02851104736328125\n",
      "Epoch 85: Train_loss 31618740224.0, Validation_loss 29639077888.0, Seconds 0.0299985408782959\n",
      "Epoch 86: Train_loss 31609620480.0, Validation_loss 29620996096.0, Seconds 0.022998571395874023\n",
      "Epoch 87: Train_loss 31602644992.0, Validation_loss 29613600768.0, Seconds 0.021004438400268555\n",
      "Epoch 88: Train_loss 31597475840.0, Validation_loss 29606895616.0, Seconds 0.022507429122924805\n",
      "Epoch 89: Train_loss 31592116224.0, Validation_loss 29599571968.0, Seconds 0.022000551223754883\n",
      "Epoch 90: Train_loss 31587031040.0, Validation_loss 29592225792.0, Seconds 0.02300095558166504\n",
      "Epoch 91: Train_loss 31582789632.0, Validation_loss 29585010688.0, Seconds 0.022001266479492188\n",
      "Epoch 92: Train_loss 31576737792.0, Validation_loss 29577709568.0, Seconds 0.022533893585205078\n",
      "Epoch 93: Train_loss 31570917376.0, Validation_loss 29571184640.0, Seconds 0.019999027252197266\n",
      "Epoch 94: Train_loss 31568287744.0, Validation_loss 29565034496.0, Seconds 0.020001649856567383\n",
      "Epoch 95: Train_loss 31563220992.0, Validation_loss 29558368256.0, Seconds 0.01999974250793457\n",
      "Epoch 96: Train_loss 31557140480.0, Validation_loss 29551794176.0, Seconds 0.017086505889892578\n",
      "Epoch 97: Train_loss 31552946176.0, Validation_loss 29545324544.0, Seconds 0.01650381088256836\n",
      "Epoch 98: Train_loss 31548254208.0, Validation_loss 29538457600.0, Seconds 0.017999887466430664\n",
      "Epoch 99: Train_loss 31544158208.0, Validation_loss 29531432960.0, Seconds 0.01699995994567871\n",
      "Epoch 100: Train_loss 31540365312.0, Validation_loss 29524834304.0, Seconds 0.017001867294311523\n",
      "Epoch 101: Train_loss 31535335424.0, Validation_loss 29517684736.0, Seconds 0.01799917221069336\n",
      "Epoch 102: Train_loss 31531061248.0, Validation_loss 29510393856.0, Seconds 0.021013498306274414\n",
      "Epoch 103: Train_loss 31527569408.0, Validation_loss 29501722624.0, Seconds 0.017513751983642578\n",
      "Epoch 104: Train_loss 31524751360.0, Validation_loss 29495666688.0, Seconds 0.022007465362548828\n",
      "Epoch 105: Train_loss 31523479552.0, Validation_loss 29493325824.0, Seconds 0.021994829177856445\n",
      "Epoch 106: Train_loss 31521632256.0, Validation_loss 29490657280.0, Seconds 0.018998384475708008\n",
      "Epoch 107: Train_loss 31519371264.0, Validation_loss 29486804992.0, Seconds 0.023002147674560547\n",
      "Epoch 108: Train_loss 31517706240.0, Validation_loss 29483446272.0, Seconds 0.01850605010986328\n",
      "Epoch 109: Train_loss 31515512832.0, Validation_loss 29479778304.0, Seconds 0.02000117301940918\n",
      "Epoch 110: Train_loss 31513513984.0, Validation_loss 29476249600.0, Seconds 0.021999120712280273\n",
      "Epoch 111: Train_loss 31511578624.0, Validation_loss 29472264192.0, Seconds 0.02200007438659668\n",
      "Epoch 112: Train_loss 31509778432.0, Validation_loss 29468483584.0, Seconds 0.02218484878540039\n",
      "Epoch 113: Train_loss 31508211712.0, Validation_loss 29464940544.0, Seconds 0.021999597549438477\n",
      "Epoch 114: Train_loss 31506624512.0, Validation_loss 29461415936.0, Seconds 0.021999120712280273\n",
      "Epoch 115: Train_loss 31504924672.0, Validation_loss 29457907712.0, Seconds 0.023000240325927734\n",
      "Epoch 116: Train_loss 31504885760.0, Validation_loss 29456416768.0, Seconds 0.023012876510620117\n",
      "Epoch 117: Train_loss 31503423488.0, Validation_loss 29453983744.0, Seconds 0.020523786544799805\n",
      "Epoch 118: Train_loss 31502143488.0, Validation_loss 29451294720.0, Seconds 0.023001432418823242\n",
      "Epoch 119: Train_loss 31501961216.0, Validation_loss 29449461760.0, Seconds 0.020001649856567383\n",
      "Epoch 120: Train_loss 31501148160.0, Validation_loss 29447821312.0, Seconds 0.021008729934692383\n",
      "Epoch 121: Train_loss 31499706368.0, Validation_loss 29445773312.0, Seconds 0.023498058319091797\n",
      "Epoch 122: Train_loss 31499749376.0, Validation_loss 29444399104.0, Seconds 0.023000478744506836\n",
      "Epoch 123: Train_loss 31499321344.0, Validation_loss 29443219456.0, Seconds 0.017999887466430664\n",
      "Epoch 124: Train_loss 31497926656.0, Validation_loss 29441339392.0, Seconds 0.01999950408935547\n",
      "Epoch 125: Train_loss 31497082880.0, Validation_loss 29439260672.0, Seconds 0.01900172233581543\n",
      "Epoch 126: Train_loss 31496622080.0, Validation_loss 29437321216.0, Seconds 0.02250838279724121\n",
      "Epoch 127: Train_loss 31495581696.0, Validation_loss 29435211776.0, Seconds 0.019000768661499023\n",
      "Epoch 128: Train_loss 31494772736.0, Validation_loss 29433350144.0, Seconds 0.019999980926513672\n",
      "Epoch 129: Train_loss 31493715968.0, Validation_loss 29431246848.0, Seconds 0.02299952507019043\n",
      "Epoch 130: Train_loss 31493382144.0, Validation_loss 29429663744.0, Seconds 0.021003246307373047\n",
      "Epoch 131: Train_loss 31492855808.0, Validation_loss 29428248576.0, Seconds 0.021507740020751953\n",
      "Epoch 132: Train_loss 31491713024.0, Validation_loss 29426401280.0, Seconds 0.023000240325927734\n",
      "Epoch 133: Train_loss 31490746368.0, Validation_loss 29424402432.0, Seconds 0.022000551223754883\n",
      "Epoch 134: Train_loss 31490863104.0, Validation_loss 29423179776.0, Seconds 0.021999835968017578\n",
      "Epoch 135: Train_loss 31490070528.0, Validation_loss 29421789184.0, Seconds 0.021004915237426758\n",
      "Epoch 136: Train_loss 31489089536.0, Validation_loss 29420288000.0, Seconds 0.021031856536865234\n",
      "Epoch 137: Train_loss 31488245760.0, Validation_loss 29418444800.0, Seconds 0.017993450164794922\n",
      "Epoch 138: Train_loss 31488233472.0, Validation_loss 29417113600.0, Seconds 0.021002531051635742\n",
      "Epoch 139: Train_loss 31487950848.0, Validation_loss 29416056832.0, Seconds 0.018007755279541016\n",
      "Epoch 140: Train_loss 31486597120.0, Validation_loss 29414393856.0, Seconds 0.017995834350585938\n",
      "Epoch 141: Train_loss 31485495296.0, Validation_loss 29412421632.0, Seconds 0.023507118225097656\n",
      "Epoch 142: Train_loss 31486201856.0, Validation_loss 29411620864.0, Seconds 0.02100086212158203\n",
      "Epoch 143: Train_loss 31484958720.0, Validation_loss 29410025472.0, Seconds 0.021999120712280273\n",
      "Epoch 144: Train_loss 31483707392.0, Validation_loss 29408204800.0, Seconds 0.023000478744506836\n",
      "Epoch 145: Train_loss 31484387328.0, Validation_loss 29407399936.0, Seconds 0.02151036262512207\n",
      "Epoch 146: Train_loss 31483422720.0, Validation_loss 29405911040.0, Seconds 0.022001981735229492\n",
      "Epoch 147: Train_loss 31481862144.0, Validation_loss 29403973632.0, Seconds 0.022997617721557617\n",
      "Epoch 148: Train_loss 31482494976.0, Validation_loss 29403256832.0, Seconds 0.021999597549438477\n",
      "Epoch 149: Train_loss 31481438208.0, Validation_loss 29401643008.0, Seconds 0.023056507110595703\n",
      "Epoch 150: Train_loss 31481323520.0, Validation_loss 29400817664.0, Seconds 0.022031545639038086\n",
      "Epoch 151: Train_loss 31480711168.0, Validation_loss 29399799808.0, Seconds 0.019002676010131836\n",
      "Epoch 152: Train_loss 31479547904.0, Validation_loss 29398198272.0, Seconds 0.020995616912841797\n",
      "Epoch 153: Train_loss 31480336384.0, Validation_loss 29397817344.0, Seconds 0.017999649047851562\n",
      "Epoch 154: Train_loss 31479877632.0, Validation_loss 29396981760.0, Seconds 0.025017738342285156\n",
      "Epoch 155: Train_loss 31478063104.0, Validation_loss 29395056640.0, Seconds 0.019540071487426758\n",
      "Epoch 156: Train_loss 31478366208.0, Validation_loss 29393827840.0, Seconds 0.017994165420532227\n",
      "Epoch 157: Train_loss 31477803008.0, Validation_loss 29392459776.0, Seconds 0.022001028060913086\n",
      "Epoch 158: Train_loss 31476854784.0, Validation_loss 29391204352.0, Seconds 0.020998477935791016\n",
      "Epoch 159: Train_loss 31476686848.0, Validation_loss 29390309376.0, Seconds 0.019004344940185547\n",
      "Epoch 160: Train_loss 31476262912.0, Validation_loss 29389123584.0, Seconds 0.017514705657958984\n",
      "Epoch 161: Train_loss 31475806208.0, Validation_loss 29387890688.0, Seconds 0.02100515365600586\n",
      "Epoch 162: Train_loss 31474900992.0, Validation_loss 29386407936.0, Seconds 0.024988651275634766\n",
      "Epoch 163: Train_loss 31474831360.0, Validation_loss 29385549824.0, Seconds 0.021001338958740234\n",
      "Epoch 164: Train_loss 31474522112.0, Validation_loss 29384749056.0, Seconds 0.01862335205078125\n",
      "Epoch 165: Train_loss 31473289216.0, Validation_loss 29383262208.0, Seconds 0.02200794219970703\n",
      "Epoch 166: Train_loss 31473172480.0, Validation_loss 29382148096.0, Seconds 0.02499675750732422\n",
      "Epoch 167: Train_loss 31473326080.0, Validation_loss 29381447680.0, Seconds 0.023998737335205078\n",
      "Epoch 168: Train_loss 31472257024.0, Validation_loss 29380231168.0, Seconds 0.023004531860351562\n",
      "Epoch 169: Train_loss 31471468544.0, Validation_loss 29378947072.0, Seconds 0.022508859634399414\n",
      "Epoch 170: Train_loss 31471820800.0, Validation_loss 29378154496.0, Seconds 0.02300286293029785\n",
      "Epoch 171: Train_loss 31471482880.0, Validation_loss 29377355776.0, Seconds 0.022998332977294922\n",
      "Epoch 172: Train_loss 31470235648.0, Validation_loss 29375977472.0, Seconds 0.021997690200805664\n",
      "Epoch 173: Train_loss 31469926400.0, Validation_loss 29374797824.0, Seconds 0.01950812339782715\n",
      "Epoch 174: Train_loss 31470051328.0, Validation_loss 29374091264.0, Seconds 0.023000001907348633\n",
      "Epoch 175: Train_loss 31468875776.0, Validation_loss 29372547072.0, Seconds 0.020999670028686523\n",
      "Epoch 176: Train_loss 31468951552.0, Validation_loss 29371744256.0, Seconds 0.019075393676757812\n",
      "Epoch 177: Train_loss 31468720128.0, Validation_loss 29370902528.0, Seconds 0.02192997932434082\n",
      "Epoch 178: Train_loss 31467765760.0, Validation_loss 29369669632.0, Seconds 0.024506092071533203\n",
      "Epoch 179: Train_loss 31467640832.0, Validation_loss 29368717312.0, Seconds 0.020003557205200195\n",
      "Epoch 180: Train_loss 31467073536.0, Validation_loss 29367554048.0, Seconds 0.017000675201416016\n",
      "Epoch 181: Train_loss 31466936320.0, Validation_loss 29366790144.0, Seconds 0.01799607276916504\n",
      "Epoch 182: Train_loss 31466774528.0, Validation_loss 29366104064.0, Seconds 0.0240018367767334\n",
      "Epoch 183: Train_loss 31465695232.0, Validation_loss 29364789248.0, Seconds 0.01853799819946289\n",
      "Epoch 184: Train_loss 31465553920.0, Validation_loss 29363810304.0, Seconds 0.02196788787841797\n",
      "Epoch 185: Train_loss 31464976384.0, Validation_loss 29362604032.0, Seconds 0.023999691009521484\n",
      "Epoch 186: Train_loss 31465039872.0, Validation_loss 29361876992.0, Seconds 0.02199840545654297\n",
      "Epoch 187: Train_loss 31464427520.0, Validation_loss 29360916480.0, Seconds 0.023509740829467773\n",
      "Epoch 188: Train_loss 31463716864.0, Validation_loss 29359747072.0, Seconds 0.01999950408935547\n",
      "Epoch 189: Train_loss 31463567360.0, Validation_loss 29358841856.0, Seconds 0.020000696182250977\n",
      "Epoch 190: Train_loss 31463143424.0, Validation_loss 29357793280.0, Seconds 0.022001028060913086\n",
      "Epoch 191: Train_loss 31462727680.0, Validation_loss 29356910592.0, Seconds 0.023009300231933594\n",
      "Epoch 192: Train_loss 31462787072.0, Validation_loss 29356269568.0, Seconds 0.03049945831298828\n",
      "Epoch 193: Train_loss 31461816320.0, Validation_loss 29354960896.0, Seconds 0.02400493621826172\n",
      "Epoch 194: Train_loss 31461394432.0, Validation_loss 29353945088.0, Seconds 0.018996477127075195\n",
      "Epoch 195: Train_loss 31461029888.0, Validation_loss 29352949760.0, Seconds 0.01999831199645996\n",
      "Epoch 196: Train_loss 31461279744.0, Validation_loss 29352380416.0, Seconds 0.02152848243713379\n",
      "Epoch 197: Train_loss 31460364288.0, Validation_loss 29351223296.0, Seconds 0.019994735717773438\n",
      "Epoch 198: Train_loss 31459708928.0, Validation_loss 29350049792.0, Seconds 0.021998167037963867\n",
      "Epoch 199: Train_loss 31459766272.0, Validation_loss 29349208064.0, Seconds 0.01699995994567871\n",
      "Epoch 200: Train_loss 31459481600.0, Validation_loss 29348599808.0, Seconds 0.01800060272216797\n",
      "Epoch 201: Train_loss 31458199552.0, Validation_loss 29347000320.0, Seconds 0.01800251007080078\n",
      "Epoch 202: Train_loss 31458791424.0, Validation_loss 29346566144.0, Seconds 0.09251093864440918\n",
      "Epoch 203: Train_loss 31458629632.0, Validation_loss 29345810432.0, Seconds 0.023507356643676758\n",
      "Epoch 204: Train_loss 31457312768.0, Validation_loss 29344403456.0, Seconds 0.023001432418823242\n",
      "Epoch 205: Train_loss 31457316864.0, Validation_loss 29343600640.0, Seconds 0.01999950408935547\n",
      "Epoch 206: Train_loss 31457273856.0, Validation_loss 29342916608.0, Seconds 0.022999048233032227\n",
      "Epoch 207: Train_loss 31456358400.0, Validation_loss 29341868032.0, Seconds 0.024074077606201172\n",
      "Epoch 208: Train_loss 31456075776.0, Validation_loss 29340966912.0, Seconds 0.01700568199157715\n",
      "Epoch 209: Train_loss 31455539200.0, Validation_loss 29339901952.0, Seconds 0.01699233055114746\n",
      "Epoch 210: Train_loss 31455606784.0, Validation_loss 29339351040.0, Seconds 0.017999887466430664\n",
      "Epoch 211: Train_loss 31454976000.0, Validation_loss 29338275840.0, Seconds 0.019001007080078125\n",
      "Epoch 212: Train_loss 31454373888.0, Validation_loss 29337155584.0, Seconds 0.01900315284729004\n",
      "Epoch 213: Train_loss 31454439424.0, Validation_loss 29336598528.0, Seconds 0.019507884979248047\n",
      "Epoch 214: Train_loss 31454001152.0, Validation_loss 29335609344.0, Seconds 0.02000141143798828\n",
      "Epoch 215: Train_loss 31453691904.0, Validation_loss 29334646784.0, Seconds 0.01800084114074707\n",
      "Epoch 216: Train_loss 31453339648.0, Validation_loss 29333618688.0, Seconds 0.018000364303588867\n",
      "Epoch 217: Train_loss 31452516352.0, Validation_loss 29332344832.0, Seconds 0.017003297805786133\n",
      "Epoch 218: Train_loss 31452284928.0, Validation_loss 29331529728.0, Seconds 0.01953434944152832\n",
      "Epoch 219: Train_loss 31452104704.0, Validation_loss 29330821120.0, Seconds 0.017000198364257812\n",
      "Epoch 220: Train_loss 31451568128.0, Validation_loss 29330139136.0, Seconds 0.017992258071899414\n",
      "Epoch 221: Train_loss 31451404288.0, Validation_loss 29329518592.0, Seconds 0.020000219345092773\n",
      "Epoch 222: Train_loss 31451074560.0, Validation_loss 29328588800.0, Seconds 0.022004127502441406\n",
      "Epoch 223: Train_loss 31450284032.0, Validation_loss 29327237120.0, Seconds 0.021039247512817383\n",
      "Epoch 224: Train_loss 31450277888.0, Validation_loss 29326643200.0, Seconds 0.021001338958740234\n",
      "Epoch 225: Train_loss 31449520128.0, Validation_loss 29325854720.0, Seconds 0.019998788833618164\n",
      "Epoch 226: Train_loss 31449042944.0, Validation_loss 29325047808.0, Seconds 0.022003650665283203\n",
      "Epoch 227: Train_loss 31449071616.0, Validation_loss 29324431360.0, Seconds 0.02300119400024414\n",
      "Epoch 228: Train_loss 31448150016.0, Validation_loss 29323040768.0, Seconds 0.02303767204284668\n",
      "Epoch 229: Train_loss 31448641536.0, Validation_loss 29322649600.0, Seconds 0.021999120712280273\n",
      "Epoch 230: Train_loss 31447595008.0, Validation_loss 29321308160.0, Seconds 0.01999974250793457\n",
      "Epoch 231: Train_loss 31447646208.0, Validation_loss 29320617984.0, Seconds 0.01900005340576172\n",
      "Epoch 232: Train_loss 31447271424.0, Validation_loss 29319811072.0, Seconds 0.022548675537109375\n",
      "Epoch 233: Train_loss 31446622208.0, Validation_loss 29318895616.0, Seconds 0.024008512496948242\n",
      "Epoch 234: Train_loss 31446630400.0, Validation_loss 29318240256.0, Seconds 0.017987489700317383\n",
      "Epoch 235: Train_loss 31446110208.0, Validation_loss 29317140480.0, Seconds 0.018998384475708008\n",
      "Epoch 236: Train_loss 31445852160.0, Validation_loss 29316241408.0, Seconds 0.02099919319152832\n",
      "Epoch 237: Train_loss 31445401600.0, Validation_loss 29315321856.0, Seconds 0.0185091495513916\n",
      "Epoch 238: Train_loss 31445118976.0, Validation_loss 29314506752.0, Seconds 0.020000934600830078\n",
      "Epoch 239: Train_loss 31444725760.0, Validation_loss 29313761280.0, Seconds 0.01799917221069336\n",
      "Epoch 240: Train_loss 31444398080.0, Validation_loss 29312899072.0, Seconds 0.018000125885009766\n",
      "Epoch 241: Train_loss 31443845120.0, Validation_loss 29311735808.0, Seconds 0.023006916046142578\n",
      "Epoch 242: Train_loss 31444226048.0, Validation_loss 29311186944.0, Seconds 0.0245511531829834\n",
      "Epoch 243: Train_loss 31443314688.0, Validation_loss 29310042112.0, Seconds 0.028069257736206055\n",
      "Epoch 244: Train_loss 31442956288.0, Validation_loss 29309276160.0, Seconds 0.023925065994262695\n",
      "Epoch 245: Train_loss 31442751488.0, Validation_loss 29308547072.0, Seconds 0.02200031280517578\n",
      "Epoch 246: Train_loss 31442352128.0, Validation_loss 29307561984.0, Seconds 0.017076730728149414\n",
      "Epoch 247: Train_loss 31442192384.0, Validation_loss 29306775552.0, Seconds 0.02060079574584961\n",
      "Epoch 248: Train_loss 31441346560.0, Validation_loss 29305747456.0, Seconds 0.019992589950561523\n",
      "Epoch 249: Train_loss 31441217536.0, Validation_loss 29304872960.0, Seconds 0.02100205421447754\n",
      "Epoch 250: Train_loss 31441186816.0, Validation_loss 29304274944.0, Seconds 0.01899862289428711\n",
      "Epoch 251: Train_loss 31440476160.0, Validation_loss 29303277568.0, Seconds 0.023545503616333008\n",
      "Epoch 252: Train_loss 31440691200.0, Validation_loss 29302552576.0, Seconds 0.02200007438659668\n",
      "Epoch 253: Train_loss 31439867904.0, Validation_loss 29301286912.0, Seconds 0.019001007080078125\n",
      "Epoch 254: Train_loss 31439603712.0, Validation_loss 29300629504.0, Seconds 0.02100396156311035\n",
      "Epoch 255: Train_loss 31439396864.0, Validation_loss 29299918848.0, Seconds 0.016995668411254883\n",
      "Epoch 256: Train_loss 31439165440.0, Validation_loss 29299038208.0, Seconds 0.019519329071044922\n",
      "Epoch 257: Train_loss 31438569472.0, Validation_loss 29297881088.0, Seconds 0.023004770278930664\n",
      "Epoch 258: Train_loss 31438075904.0, Validation_loss 29296918528.0, Seconds 0.01799917221069336\n",
      "Epoch 259: Train_loss 31438200832.0, Validation_loss 29296404480.0, Seconds 0.021001100540161133\n",
      "Epoch 260: Train_loss 31437467648.0, Validation_loss 29295296512.0, Seconds 0.020999431610107422\n",
      "Epoch 261: Train_loss 31437185024.0, Validation_loss 29294446592.0, Seconds 0.022507905960083008\n",
      "Epoch 262: Train_loss 31437049856.0, Validation_loss 29293574144.0, Seconds 0.023001432418823242\n",
      "Epoch 263: Train_loss 31436558336.0, Validation_loss 29292513280.0, Seconds 0.021998167037963867\n",
      "Epoch 264: Train_loss 31436236800.0, Validation_loss 29291763712.0, Seconds 0.023001909255981445\n",
      "Epoch 265: Train_loss 31435909120.0, Validation_loss 29290975232.0, Seconds 0.025011539459228516\n",
      "Epoch 266: Train_loss 31435583488.0, Validation_loss 29290004480.0, Seconds 0.021510601043701172\n",
      "Epoch 267: Train_loss 31435051008.0, Validation_loss 29288896512.0, Seconds 0.02599787712097168\n",
      "Epoch 268: Train_loss 31434819584.0, Validation_loss 29288243200.0, Seconds 0.02299976348876953\n",
      "Epoch 269: Train_loss 31434735616.0, Validation_loss 29287520256.0, Seconds 0.023003816604614258\n",
      "Epoch 270: Train_loss 31434080256.0, Validation_loss 29286307840.0, Seconds 0.08950972557067871\n",
      "Epoch 271: Train_loss 31433719808.0, Validation_loss 29285429248.0, Seconds 0.019509315490722656\n",
      "Epoch 272: Train_loss 31433611264.0, Validation_loss 29284718592.0, Seconds 0.021001100540161133\n",
      "Epoch 273: Train_loss 31433285632.0, Validation_loss 29283835904.0, Seconds 0.01999950408935547\n",
      "Epoch 274: Train_loss 31432697856.0, Validation_loss 29282803712.0, Seconds 0.018999338150024414\n",
      "Epoch 275: Train_loss 31432407040.0, Validation_loss 29281886208.0, Seconds 0.01899886131286621\n",
      "Epoch 276: Train_loss 31432288256.0, Validation_loss 29281218560.0, Seconds 0.016002416610717773\n",
      "Epoch 277: Train_loss 31431782400.0, Validation_loss 29280317440.0, Seconds 0.01950526237487793\n",
      "Epoch 278: Train_loss 31431393280.0, Validation_loss 29279246336.0, Seconds 0.01900029182434082\n",
      "Epoch 279: Train_loss 31431172096.0, Validation_loss 29278404608.0, Seconds 0.023004531860351562\n",
      "Epoch 280: Train_loss 31430842368.0, Validation_loss 29277622272.0, Seconds 0.019001007080078125\n",
      "Epoch 281: Train_loss 31430346752.0, Validation_loss 29276536832.0, Seconds 0.021003246307373047\n",
      "Epoch 282: Train_loss 31430330368.0, Validation_loss 29275791360.0, Seconds 0.02150702476501465\n",
      "Epoch 283: Train_loss 31429685248.0, Validation_loss 29274748928.0, Seconds 0.021999597549438477\n",
      "Epoch 284: Train_loss 31429433344.0, Validation_loss 29273927680.0, Seconds 0.021001815795898438\n",
      "Epoch 285: Train_loss 31429068800.0, Validation_loss 29273096192.0, Seconds 0.01999831199645996\n",
      "Epoch 286: Train_loss 31428814848.0, Validation_loss 29272291328.0, Seconds 0.02450871467590332\n",
      "Epoch 287: Train_loss 31428390912.0, Validation_loss 29271117824.0, Seconds 0.01999950408935547\n",
      "Epoch 288: Train_loss 31427850240.0, Validation_loss 29269858304.0, Seconds 0.021999597549438477\n",
      "Epoch 289: Train_loss 31427848192.0, Validation_loss 29269272576.0, Seconds 0.02300095558166504\n",
      "Epoch 290: Train_loss 31427301376.0, Validation_loss 29268281344.0, Seconds 0.021081209182739258\n",
      "Epoch 291: Train_loss 31426938880.0, Validation_loss 29267374080.0, Seconds 0.01951289176940918\n",
      "Epoch 292: Train_loss 31426942976.0, Validation_loss 29266620416.0, Seconds 0.019992828369140625\n",
      "Epoch 293: Train_loss 31426138112.0, Validation_loss 29265453056.0, Seconds 0.022002458572387695\n",
      "Epoch 294: Train_loss 31425875968.0, Validation_loss 29264537600.0, Seconds 0.016999483108520508\n",
      "Epoch 295: Train_loss 31425753088.0, Validation_loss 29263714304.0, Seconds 0.01800251007080078\n",
      "Epoch 296: Train_loss 31424743424.0, Validation_loss 29262530560.0, Seconds 0.02150750160217285\n",
      "Epoch 297: Train_loss 31424647168.0, Validation_loss 29261832192.0, Seconds 0.027002334594726562\n",
      "Epoch 298: Train_loss 31424778240.0, Validation_loss 29261182976.0, Seconds 0.023005247116088867\n",
      "Epoch 299: Train_loss 31423784960.0, Validation_loss 29259757568.0, Seconds 0.024016141891479492\n",
      "Epoch 300: Train_loss 31423655936.0, Validation_loss 29258762240.0, Seconds 0.028502941131591797\n",
      "Epoch 301: Train_loss 31423475712.0, Validation_loss 29257795584.0, Seconds 0.02299809455871582\n",
      "Epoch 302: Train_loss 31422615552.0, Validation_loss 29256798208.0, Seconds 0.02199864387512207\n",
      "Epoch 303: Train_loss 31423037440.0, Validation_loss 29256380416.0, Seconds 0.020000934600830078\n",
      "Epoch 304: Train_loss 31421618176.0, Validation_loss 29254850560.0, Seconds 0.02051544189453125\n",
      "Epoch 305: Train_loss 31420452864.0, Validation_loss 29253758976.0, Seconds 0.018062114715576172\n",
      "Epoch 306: Train_loss 31421423616.0, Validation_loss 29253656576.0, Seconds 0.018023967742919922\n",
      "Epoch 307: Train_loss 31420723200.0, Validation_loss 29252663296.0, Seconds 0.021993160247802734\n",
      "Epoch 308: Train_loss 31419670528.0, Validation_loss 29251454976.0, Seconds 0.01893162727355957\n",
      "Epoch 309: Train_loss 31420542976.0, Validation_loss 29251158016.0, Seconds 0.020005464553833008\n",
      "Epoch 310: Train_loss 31419346944.0, Validation_loss 29249695744.0, Seconds 0.019505023956298828\n",
      "Epoch 311: Train_loss 31419054080.0, Validation_loss 29248608256.0, Seconds 0.02500009536743164\n",
      "Epoch 312: Train_loss 31419136000.0, Validation_loss 29248002048.0, Seconds 0.023999691009521484\n",
      "Epoch 313: Train_loss 31418257408.0, Validation_loss 29247076352.0, Seconds 0.023007869720458984\n",
      "Epoch 314: Train_loss 31418578944.0, Validation_loss 29246353408.0, Seconds 0.022292613983154297\n",
      "Epoch 315: Train_loss 31417714688.0, Validation_loss 29245175808.0, Seconds 0.022990703582763672\n",
      "Epoch 316: Train_loss 31417266176.0, Validation_loss 29244172288.0, Seconds 0.03100132942199707\n",
      "Epoch 317: Train_loss 31417700352.0, Validation_loss 29243611136.0, Seconds 0.022001266479492188\n",
      "Epoch 318: Train_loss 31416973312.0, Validation_loss 29242384384.0, Seconds 0.02051091194152832\n",
      "Epoch 319: Train_loss 31416262656.0, Validation_loss 29241227264.0, Seconds 0.02299952507019043\n",
      "Epoch 320: Train_loss 31416035328.0, Validation_loss 29240195072.0, Seconds 0.022002458572387695\n",
      "Epoch 321: Train_loss 31415781376.0, Validation_loss 29239242752.0, Seconds 0.020997285842895508\n",
      "Epoch 322: Train_loss 31414767616.0, Validation_loss 29237944320.0, Seconds 0.019004344940185547\n",
      "Epoch 323: Train_loss 31414452224.0, Validation_loss 29236787200.0, Seconds 0.01750802993774414\n",
      "Epoch 324: Train_loss 31413202944.0, Validation_loss 29235847168.0, Seconds 0.020077228546142578\n",
      "Epoch 325: Train_loss 31412363264.0, Validation_loss 29235183616.0, Seconds 0.019924640655517578\n",
      "Epoch 326: Train_loss 31412649984.0, Validation_loss 29234337792.0, Seconds 0.022001266479492188\n",
      "Epoch 327: Train_loss 31411488768.0, Validation_loss 29232891904.0, Seconds 0.02100348472595215\n",
      "Epoch 328: Train_loss 31411300352.0, Validation_loss 29232261120.0, Seconds 0.018509387969970703\n",
      "Epoch 329: Train_loss 31411349504.0, Validation_loss 29231439872.0, Seconds 0.022000551223754883\n",
      "Epoch 330: Train_loss 31410987008.0, Validation_loss 29230196736.0, Seconds 0.02699899673461914\n",
      "Epoch 331: Train_loss 31410552832.0, Validation_loss 29229293568.0, Seconds 0.028007030487060547\n",
      "Epoch 332: Train_loss 31410341888.0, Validation_loss 29228800000.0, Seconds 0.01951313018798828\n",
      "Epoch 333: Train_loss 31410333696.0, Validation_loss 29227816960.0, Seconds 0.018000125885009766\n",
      "Epoch 334: Train_loss 31408887808.0, Validation_loss 29226291200.0, Seconds 0.019001007080078125\n",
      "Epoch 335: Train_loss 31409889280.0, Validation_loss 29225791488.0, Seconds 0.021003246307373047\n",
      "Epoch 336: Train_loss 31409555456.0, Validation_loss 29224949760.0, Seconds 0.020000696182250977\n",
      "Epoch 337: Train_loss 31408179200.0, Validation_loss 29223208960.0, Seconds 0.021506309509277344\n",
      "Epoch 338: Train_loss 31407824896.0, Validation_loss 29222244352.0, Seconds 0.017999887466430664\n",
      "Epoch 339: Train_loss 31407063040.0, Validation_loss 29221492736.0, Seconds 0.02400660514831543\n",
      "Epoch 340: Train_loss 31407044608.0, Validation_loss 29220997120.0, Seconds 0.023994922637939453\n",
      "Epoch 341: Train_loss 31406661632.0, Validation_loss 29220036608.0, Seconds 0.02401280403137207\n",
      "Epoch 342: Train_loss 31405901824.0, Validation_loss 29218596864.0, Seconds 0.02352285385131836\n",
      "Epoch 343: Train_loss 31406266368.0, Validation_loss 29217691648.0, Seconds 0.021999120712280273\n",
      "Epoch 344: Train_loss 31404931072.0, Validation_loss 29216194560.0, Seconds 0.022011995315551758\n",
      "Epoch 345: Train_loss 31405074432.0, Validation_loss 29215408128.0, Seconds 0.020992755889892578\n",
      "Epoch 346: Train_loss 31404863488.0, Validation_loss 29214464000.0, Seconds 0.0225069522857666\n",
      "Epoch 347: Train_loss 31404175360.0, Validation_loss 29213440000.0, Seconds 0.02200150489807129\n",
      "Epoch 348: Train_loss 31404169216.0, Validation_loss 29212469248.0, Seconds 0.017998456954956055\n",
      "Epoch 349: Train_loss 31404005376.0, Validation_loss 29211633664.0, Seconds 0.01800084114074707\n",
      "Epoch 350: Train_loss 31402915840.0, Validation_loss 29210468352.0, Seconds 0.01799917221069336\n",
      "Epoch 351: Train_loss 31403620352.0, Validation_loss 29209819136.0, Seconds 0.01751255989074707\n",
      "Epoch 352: Train_loss 31402180608.0, Validation_loss 29208502272.0, Seconds 0.018003463745117188\n",
      "Epoch 353: Train_loss 31402694656.0, Validation_loss 29207437312.0, Seconds 0.0189971923828125\n",
      "Epoch 354: Train_loss 31401773056.0, Validation_loss 29206401024.0, Seconds 0.02199840545654297\n",
      "Epoch 355: Train_loss 31401351168.0, Validation_loss 29205458944.0, Seconds 0.018999814987182617\n",
      "Epoch 356: Train_loss 31401324544.0, Validation_loss 29204576256.0, Seconds 0.018016815185546875\n",
      "Epoch 357: Train_loss 31401404416.0, Validation_loss 29203607552.0, Seconds 0.02150750160217285\n",
      "Epoch 358: Train_loss 31399680000.0, Validation_loss 29202345984.0, Seconds 0.02299976348876953\n",
      "Epoch 359: Train_loss 31400482816.0, Validation_loss 29201776640.0, Seconds 0.021999835968017578\n",
      "Epoch 360: Train_loss 31399528448.0, Validation_loss 29200506880.0, Seconds 0.02200484275817871\n",
      "Epoch 361: Train_loss 31399211008.0, Validation_loss 29199159296.0, Seconds 0.021506786346435547\n",
      "Epoch 362: Train_loss 31399335936.0, Validation_loss 29198147584.0, Seconds 0.022999286651611328\n",
      "Epoch 363: Train_loss 31397756928.0, Validation_loss 29196974080.0, Seconds 0.017999887466430664\n",
      "Epoch 364: Train_loss 31398598656.0, Validation_loss 29196257280.0, Seconds 0.02300095558166504\n",
      "Epoch 365: Train_loss 31398230016.0, Validation_loss 29195206656.0, Seconds 0.021011829376220703\n",
      "Epoch 366: Train_loss 31396669440.0, Validation_loss 29193828352.0, Seconds 0.022534608840942383\n",
      "Epoch 367: Train_loss 31397752832.0, Validation_loss 29193459712.0, Seconds 0.018003463745117188\n",
      "Epoch 368: Train_loss 31396896768.0, Validation_loss 29192169472.0, Seconds 0.02199554443359375\n",
      "Epoch 369: Train_loss 31395518464.0, Validation_loss 29190318080.0, Seconds 0.019998788833618164\n",
      "Epoch 370: Train_loss 31395317760.0, Validation_loss 29188829184.0, Seconds 0.020003318786621094\n",
      "Epoch 371: Train_loss 31394365440.0, Validation_loss 29187491840.0, Seconds 0.023508787155151367\n",
      "Epoch 372: Train_loss 31393943552.0, Validation_loss 29186269184.0, Seconds 0.02000117301940918\n",
      "Epoch 373: Train_loss 31391758336.0, Validation_loss 29185177600.0, Seconds 0.016998767852783203\n",
      "Epoch 374: Train_loss 31392219136.0, Validation_loss 29184227328.0, Seconds 0.018002033233642578\n",
      "Epoch 375: Train_loss 31391660032.0, Validation_loss 29183139840.0, Seconds 0.020005464553833008\n",
      "Epoch 376: Train_loss 31391526912.0, Validation_loss 29182642176.0, Seconds 0.022516489028930664\n",
      "Epoch 377: Train_loss 31390717952.0, Validation_loss 29181456384.0, Seconds 0.02199101448059082\n",
      "Epoch 378: Train_loss 31390310400.0, Validation_loss 29180121088.0, Seconds 0.02500009536743164\n",
      "Epoch 379: Train_loss 31390695424.0, Validation_loss 29179000832.0, Seconds 0.02001047134399414\n",
      "Epoch 380: Train_loss 31389585408.0, Validation_loss 29177892864.0, Seconds 0.0195159912109375\n",
      "Epoch 381: Train_loss 31389104128.0, Validation_loss 29176920064.0, Seconds 0.02300715446472168\n",
      "Epoch 382: Train_loss 31389542400.0, Validation_loss 29175887872.0, Seconds 0.01899123191833496\n",
      "Epoch 383: Train_loss 31388522496.0, Validation_loss 29174763520.0, Seconds 0.01900196075439453\n",
      "Epoch 384: Train_loss 31388405760.0, Validation_loss 29173686272.0, Seconds 0.018999576568603516\n",
      "Epoch 385: Train_loss 31388366848.0, Validation_loss 29172623360.0, Seconds 0.02251124382019043\n",
      "Epoch 386: Train_loss 31387115520.0, Validation_loss 29171417088.0, Seconds 0.02799701690673828\n",
      "Epoch 387: Train_loss 31387189248.0, Validation_loss 29170411520.0, Seconds 0.0279996395111084\n",
      "Epoch 388: Train_loss 31387023360.0, Validation_loss 29169315840.0, Seconds 0.02300262451171875\n",
      "Epoch 389: Train_loss 31385921536.0, Validation_loss 29168277504.0, Seconds 0.020509004592895508\n",
      "Epoch 390: Train_loss 31386441728.0, Validation_loss 29167060992.0, Seconds 0.023000240325927734\n",
      "Epoch 391: Train_loss 31385348096.0, Validation_loss 29165944832.0, Seconds 0.021001338958740234\n",
      "Epoch 392: Train_loss 31385796608.0, Validation_loss 29164843008.0, Seconds 0.018998146057128906\n",
      "Epoch 393: Train_loss 31384854528.0, Validation_loss 29163745280.0, Seconds 0.018014907836914062\n",
      "Epoch 394: Train_loss 31385225216.0, Validation_loss 29162657792.0, Seconds 0.019491910934448242\n",
      "Epoch 395: Train_loss 31383250944.0, Validation_loss 29161424896.0, Seconds 0.023002147674560547\n",
      "Epoch 396: Train_loss 31383992320.0, Validation_loss 29160171520.0, Seconds 0.022005081176757812\n",
      "Epoch 397: Train_loss 31383224320.0, Validation_loss 29158963200.0, Seconds 0.021993398666381836\n",
      "Epoch 398: Train_loss 31383615488.0, Validation_loss 29157781504.0, Seconds 0.02100348472595215\n",
      "Epoch 399: Train_loss 31381561344.0, Validation_loss 29156665344.0, Seconds 0.023525714874267578\n",
      "Epoch 400: Train_loss 31382693888.0, Validation_loss 29156292608.0, Seconds 0.022002458572387695\n",
      "Epoch 401: Train_loss 31381241856.0, Validation_loss 29154824192.0, Seconds 0.018001317977905273\n",
      "Epoch 402: Train_loss 31381702656.0, Validation_loss 29152989184.0, Seconds 0.09051346778869629\n",
      "Epoch 403: Train_loss 31380070400.0, Validation_loss 29151731712.0, Seconds 0.023998022079467773\n",
      "Epoch 404: Train_loss 31380215808.0, Validation_loss 29150504960.0, Seconds 0.019002914428710938\n",
      "Epoch 405: Train_loss 31379949568.0, Validation_loss 29149308928.0, Seconds 0.020507097244262695\n",
      "Epoch 406: Train_loss 31379783680.0, Validation_loss 29147990016.0, Seconds 0.01999807357788086\n",
      "Epoch 407: Train_loss 31378044928.0, Validation_loss 29146763264.0, Seconds 0.018000125885009766\n",
      "Epoch 408: Train_loss 31378296832.0, Validation_loss 29145540608.0, Seconds 0.017006397247314453\n",
      "Epoch 409: Train_loss 31377903616.0, Validation_loss 29144207360.0, Seconds 0.022997617721557617\n",
      "Epoch 410: Train_loss 31378065408.0, Validation_loss 29142968320.0, Seconds 0.019504785537719727\n",
      "Epoch 411: Train_loss 31376283648.0, Validation_loss 29141655552.0, Seconds 0.022000551223754883\n",
      "Epoch 412: Train_loss 31376422912.0, Validation_loss 29140346880.0, Seconds 0.0240023136138916\n",
      "Epoch 413: Train_loss 31375804416.0, Validation_loss 29139007488.0, Seconds 0.021001100540161133\n",
      "Epoch 414: Train_loss 31375544320.0, Validation_loss 29137623040.0, Seconds 0.017000913619995117\n",
      "Epoch 415: Train_loss 31374104576.0, Validation_loss 29136369664.0, Seconds 0.01850748062133789\n",
      "Epoch 416: Train_loss 31374993408.0, Validation_loss 29135069184.0, Seconds 0.021006345748901367\n",
      "Epoch 417: Train_loss 31373658112.0, Validation_loss 29133707264.0, Seconds 0.01799321174621582\n",
      "Epoch 418: Train_loss 31373572096.0, Validation_loss 29132382208.0, Seconds 0.019001007080078125\n",
      "Epoch 419: Train_loss 31372726272.0, Validation_loss 29131110400.0, Seconds 0.025005340576171875\n",
      "Epoch 420: Train_loss 31372820480.0, Validation_loss 29129771008.0, Seconds 0.018506288528442383\n",
      "Epoch 421: Train_loss 31371253760.0, Validation_loss 29128497152.0, Seconds 0.018004655838012695\n",
      "Epoch 422: Train_loss 31372077056.0, Validation_loss 29127192576.0, Seconds 0.021996736526489258\n",
      "Epoch 423: Train_loss 31371237376.0, Validation_loss 29125883904.0, Seconds 0.02199864387512207\n",
      "Epoch 424: Train_loss 31370174464.0, Validation_loss 29124583424.0, Seconds 0.024524450302124023\n",
      "Epoch 425: Train_loss 31370661888.0, Validation_loss 29123303424.0, Seconds 0.022996187210083008\n",
      "Epoch 426: Train_loss 31369357312.0, Validation_loss 29121937408.0, Seconds 0.020004749298095703\n",
      "Epoch 427: Train_loss 31368869888.0, Validation_loss 29120671744.0, Seconds 0.01999688148498535\n",
      "Epoch 428: Train_loss 31369531392.0, Validation_loss 29119406080.0, Seconds 0.02000284194946289\n",
      "Epoch 429: Train_loss 31367585792.0, Validation_loss 29118021632.0, Seconds 0.016517162322998047\n",
      "Epoch 430: Train_loss 31367692288.0, Validation_loss 29116733440.0, Seconds 0.017008543014526367\n",
      "Epoch 431: Train_loss 31367686144.0, Validation_loss 29115392000.0, Seconds 0.017999887466430664\n",
      "Epoch 432: Train_loss 31366176768.0, Validation_loss 29114042368.0, Seconds 0.019997119903564453\n",
      "Epoch 433: Train_loss 31366453248.0, Validation_loss 29112793088.0, Seconds 0.020004749298095703\n",
      "Epoch 434: Train_loss 31366078464.0, Validation_loss 29111408640.0, Seconds 0.0180051326751709\n",
      "Epoch 435: Train_loss 31364907008.0, Validation_loss 29110013952.0, Seconds 0.02151036262512207\n",
      "Epoch 436: Train_loss 31365613568.0, Validation_loss 29108817920.0, Seconds 0.023001670837402344\n",
      "Epoch 437: Train_loss 31363737600.0, Validation_loss 29107476480.0, Seconds 0.02200031280517578\n",
      "Epoch 438: Train_loss 31365156864.0, Validation_loss 29106290688.0, Seconds 0.021997690200805664\n",
      "Epoch 439: Train_loss 31363342336.0, Validation_loss 29104795648.0, Seconds 0.018515825271606445\n",
      "Epoch 440: Train_loss 31362637824.0, Validation_loss 29103472640.0, Seconds 0.023998737335205078\n",
      "Epoch 441: Train_loss 31363819520.0, Validation_loss 29102323712.0, Seconds 0.02200007438659668\n",
      "Epoch 442: Train_loss 31361894400.0, Validation_loss 29100892160.0, Seconds 0.018006324768066406\n",
      "Epoch 443: Train_loss 31361916928.0, Validation_loss 29099505664.0, Seconds 0.021004199981689453\n",
      "Epoch 444: Train_loss 31361370112.0, Validation_loss 29098137600.0, Seconds 0.01950860023498535\n",
      "Epoch 445: Train_loss 31360718848.0, Validation_loss 29096814592.0, Seconds 0.02199864387512207\n",
      "Epoch 446: Train_loss 31360555008.0, Validation_loss 29095458816.0, Seconds 0.02200460433959961\n",
      "Epoch 447: Train_loss 31360139264.0, Validation_loss 29094197248.0, Seconds 0.019998788833618164\n",
      "Epoch 448: Train_loss 31359522816.0, Validation_loss 29092919296.0, Seconds 0.02200484275817871\n",
      "Epoch 449: Train_loss 31359633408.0, Validation_loss 29091606528.0, Seconds 0.020512104034423828\n",
      "Epoch 450: Train_loss 31358156800.0, Validation_loss 29090138112.0, Seconds 0.021999359130859375\n",
      "Epoch 451: Train_loss 31358285824.0, Validation_loss 29088858112.0, Seconds 0.019014596939086914\n",
      "Epoch 452: Train_loss 31357943808.0, Validation_loss 29087537152.0, Seconds 0.01998591423034668\n",
      "Epoch 453: Train_loss 31356768256.0, Validation_loss 29086167040.0, Seconds 0.02300882339477539\n",
      "Epoch 454: Train_loss 31357722624.0, Validation_loss 29084858368.0, Seconds 0.020535945892333984\n",
      "Epoch 455: Train_loss 31356303360.0, Validation_loss 29083375616.0, Seconds 0.022988080978393555\n",
      "Epoch 456: Train_loss 31355338752.0, Validation_loss 29081847808.0, Seconds 0.022995710372924805\n",
      "Epoch 457: Train_loss 31355787264.0, Validation_loss 29080553472.0, Seconds 0.021013498306274414\n",
      "Epoch 458: Train_loss 31354935296.0, Validation_loss 29079197696.0, Seconds 0.02252650260925293\n",
      "Epoch 459: Train_loss 31354255360.0, Validation_loss 29077827584.0, Seconds 0.02100086212158203\n",
      "Epoch 460: Train_loss 31354658816.0, Validation_loss 29076559872.0, Seconds 0.019999027252197266\n",
      "Epoch 461: Train_loss 31353673728.0, Validation_loss 29075126272.0, Seconds 0.02300119400024414\n",
      "Epoch 462: Train_loss 31353266176.0, Validation_loss 29073666048.0, Seconds 0.022012948989868164\n",
      "Epoch 463: Train_loss 31353133056.0, Validation_loss 29072297984.0, Seconds 0.019507646560668945\n",
      "Epoch 464: Train_loss 31351977984.0, Validation_loss 29070800896.0, Seconds 0.018999814987182617\n",
      "Epoch 465: Train_loss 31351939072.0, Validation_loss 29069350912.0, Seconds 0.017000436782836914\n",
      "Epoch 466: Train_loss 31351857152.0, Validation_loss 29068005376.0, Seconds 0.018001556396484375\n",
      "Epoch 467: Train_loss 31350878208.0, Validation_loss 29066582016.0, Seconds 0.025004148483276367\n",
      "Epoch 468: Train_loss 31350145024.0, Validation_loss 29065050112.0, Seconds 0.021522998809814453\n",
      "Epoch 469: Train_loss 31350108160.0, Validation_loss 29063620608.0, Seconds 0.08650350570678711\n",
      "Epoch 470: Train_loss 31349583872.0, Validation_loss 29062244352.0, Seconds 0.02200150489807129\n",
      "Epoch 471: Train_loss 31348701184.0, Validation_loss 29060745216.0, Seconds 0.022009849548339844\n",
      "Epoch 472: Train_loss 31348711424.0, Validation_loss 29059348480.0, Seconds 0.01698899269104004\n",
      "Epoch 473: Train_loss 31347974144.0, Validation_loss 29057908736.0, Seconds 0.02099919319152832\n",
      "Epoch 474: Train_loss 31347826688.0, Validation_loss 29056550912.0, Seconds 0.021509408950805664\n",
      "Epoch 475: Train_loss 31347292160.0, Validation_loss 29055209472.0, Seconds 0.022002220153808594\n",
      "Epoch 476: Train_loss 31346808832.0, Validation_loss 29053825024.0, Seconds 0.017997264862060547\n",
      "Epoch 477: Train_loss 31346311168.0, Validation_loss 29052432384.0, Seconds 0.019999980926513672\n",
      "Epoch 478: Train_loss 31345623040.0, Validation_loss 29050959872.0, Seconds 0.022002458572387695\n",
      "Epoch 479: Train_loss 31345594368.0, Validation_loss 29049636864.0, Seconds 0.017505168914794922\n",
      "Epoch 480: Train_loss 31345068032.0, Validation_loss 29048297472.0, Seconds 0.020999908447265625\n",
      "Epoch 481: Train_loss 31344590848.0, Validation_loss 29046898688.0, Seconds 0.018999576568603516\n",
      "Epoch 482: Train_loss 31343945728.0, Validation_loss 29045456896.0, Seconds 0.022001981735229492\n",
      "Epoch 483: Train_loss 31343329280.0, Validation_loss 29043978240.0, Seconds 0.017006635665893555\n",
      "Epoch 484: Train_loss 31343493120.0, Validation_loss 29042688000.0, Seconds 0.017511844635009766\n",
      "Epoch 485: Train_loss 31342907392.0, Validation_loss 29041321984.0, Seconds 0.020002365112304688\n",
      "Epoch 486: Train_loss 31342266368.0, Validation_loss 29039892480.0, Seconds 0.023998022079467773\n",
      "Epoch 487: Train_loss 31341590528.0, Validation_loss 29038405632.0, Seconds 0.02299976348876953\n",
      "Epoch 488: Train_loss 31341182976.0, Validation_loss 29036998656.0, Seconds 0.02200603485107422\n",
      "Epoch 489: Train_loss 31341285376.0, Validation_loss 29035726848.0, Seconds 0.025507450103759766\n",
      "Epoch 490: Train_loss 31340640256.0, Validation_loss 29034342400.0, Seconds 0.020006656646728516\n",
      "Epoch 491: Train_loss 31339902976.0, Validation_loss 29032826880.0, Seconds 0.018996477127075195\n",
      "Epoch 492: Train_loss 31339649024.0, Validation_loss 29031221248.0, Seconds 0.02199864387512207\n",
      "Epoch 493: Train_loss 31339180032.0, Validation_loss 29029849088.0, Seconds 0.02200484275817871\n",
      "Epoch 494: Train_loss 31338467328.0, Validation_loss 29028284416.0, Seconds 0.02550530433654785\n",
      "Epoch 495: Train_loss 31338452992.0, Validation_loss 29026934784.0, Seconds 0.02400684356689453\n",
      "Epoch 496: Train_loss 31338186752.0, Validation_loss 29025636352.0, Seconds 0.018000125885009766\n",
      "Epoch 497: Train_loss 31337596928.0, Validation_loss 29024198656.0, Seconds 0.017993450164794922\n",
      "Epoch 498: Train_loss 31336951808.0, Validation_loss 29022683136.0, Seconds 0.017508506774902344\n",
      "Epoch 499: Train_loss 31336837120.0, Validation_loss 29021329408.0, Seconds 0.022000789642333984\n",
      "Epoch 500: Train_loss 31336079360.0, Validation_loss 29019791360.0, Seconds 0.023000001907348633\n",
      "Epoch 501: Train_loss 31335981056.0, Validation_loss 29018421248.0, Seconds 0.021999120712280273\n",
      "Epoch 502: Train_loss 31335411712.0, Validation_loss 29017042944.0, Seconds 0.023003578186035156\n",
      "Epoch 503: Train_loss 31335096320.0, Validation_loss 29015607296.0, Seconds 0.02453136444091797\n",
      "Epoch 504: Train_loss 31334750208.0, Validation_loss 29014169600.0, Seconds 0.01900029182434082\n",
      "Epoch 505: Train_loss 31334123520.0, Validation_loss 29012707328.0, Seconds 0.018001794815063477\n",
      "Epoch 506: Train_loss 31333920768.0, Validation_loss 29011298304.0, Seconds 0.022999048233032227\n",
      "Epoch 507: Train_loss 31333488640.0, Validation_loss 29009870848.0, Seconds 0.021002531051635742\n",
      "Epoch 508: Train_loss 31333081088.0, Validation_loss 29008459776.0, Seconds 0.02050638198852539\n",
      "Epoch 509: Train_loss 31332755456.0, Validation_loss 29007056896.0, Seconds 0.022001981735229492\n",
      "Epoch 510: Train_loss 31332352000.0, Validation_loss 29005649920.0, Seconds 0.024999618530273438\n",
      "Epoch 511: Train_loss 31331950592.0, Validation_loss 29004216320.0, Seconds 0.022014617919921875\n",
      "Epoch 512: Train_loss 31331487744.0, Validation_loss 29002776576.0, Seconds 0.017508268356323242\n",
      "Epoch 513: Train_loss 31331229696.0, Validation_loss 29001416704.0, Seconds 0.016997814178466797\n",
      "Epoch 514: Train_loss 31330826240.0, Validation_loss 28999983104.0, Seconds 0.020002365112304688\n",
      "Epoch 515: Train_loss 31330324480.0, Validation_loss 28998553600.0, Seconds 0.021997928619384766\n",
      "Epoch 516: Train_loss 31330105344.0, Validation_loss 28997277696.0, Seconds 0.0220029354095459\n",
      "Epoch 517: Train_loss 31329878016.0, Validation_loss 28995960832.0, Seconds 0.02252793312072754\n",
      "Epoch 518: Train_loss 31329132544.0, Validation_loss 28994469888.0, Seconds 0.021999359130859375\n",
      "Epoch 519: Train_loss 31328714752.0, Validation_loss 28993132544.0, Seconds 0.025000810623168945\n",
      "Epoch 520: Train_loss 31328653312.0, Validation_loss 28992008192.0, Seconds 0.02200174331665039\n",
      "Epoch 521: Train_loss 31328086016.0, Validation_loss 28990666752.0, Seconds 0.0220029354095459\n",
      "Epoch 522: Train_loss 31327842304.0, Validation_loss 28989319168.0, Seconds 0.021510839462280273\n",
      "Epoch 523: Train_loss 31327612928.0, Validation_loss 28988203008.0, Seconds 0.018001317977905273\n",
      "Epoch 524: Train_loss 31327117312.0, Validation_loss 28986927104.0, Seconds 0.020994901657104492\n",
      "Epoch 525: Train_loss 31326621696.0, Validation_loss 28985591808.0, Seconds 0.02000117301940918\n",
      "Epoch 526: Train_loss 31326162944.0, Validation_loss 28984274944.0, Seconds 0.021514177322387695\n",
      "Epoch 527: Train_loss 31325863936.0, Validation_loss 28982804480.0, Seconds 0.021000385284423828\n",
      "Epoch 528: Train_loss 31325257728.0, Validation_loss 28981303296.0, Seconds 0.019000530242919922\n",
      "Epoch 529: Train_loss 31325159424.0, Validation_loss 28979935232.0, Seconds 0.017999649047851562\n",
      "Epoch 530: Train_loss 31324504064.0, Validation_loss 28978458624.0, Seconds 0.020998239517211914\n",
      "Epoch 531: Train_loss 31324260352.0, Validation_loss 28977086464.0, Seconds 0.020504474639892578\n",
      "Epoch 532: Train_loss 31323799552.0, Validation_loss 28975605760.0, Seconds 0.021004676818847656\n",
      "Epoch 533: Train_loss 31323209728.0, Validation_loss 28974131200.0, Seconds 0.02599811553955078\n",
      "Epoch 534: Train_loss 31323015168.0, Validation_loss 28972707840.0, Seconds 0.024002790451049805\n",
      "Epoch 535: Train_loss 31322384384.0, Validation_loss 28971253760.0, Seconds 0.023000240325927734\n",
      "Epoch 536: Train_loss 31322390528.0, Validation_loss 28969971712.0, Seconds 0.02050638198852539\n",
      "Epoch 537: Train_loss 31321696256.0, Validation_loss 28968509440.0, Seconds 0.02200031280517578\n",
      "Epoch 538: Train_loss 31321479168.0, Validation_loss 28967206912.0, Seconds 0.01900172233581543\n",
      "Epoch 539: Train_loss 31321169920.0, Validation_loss 28965879808.0, Seconds 0.021999120712280273\n",
      "Epoch 540: Train_loss 31320791040.0, Validation_loss 28964478976.0, Seconds 0.019002199172973633\n",
      "Epoch 541: Train_loss 31320530944.0, Validation_loss 28963184640.0, Seconds 0.022505521774291992\n",
      "Epoch 542: Train_loss 31319945216.0, Validation_loss 28961757184.0, Seconds 0.016999483108520508\n",
      "Epoch 543: Train_loss 31319582720.0, Validation_loss 28960458752.0, Seconds 0.021999597549438477\n",
      "Epoch 544: Train_loss 31319283712.0, Validation_loss 28959109120.0, Seconds 0.023000478744506836\n",
      "Epoch 545: Train_loss 31318804480.0, Validation_loss 28957753344.0, Seconds 0.02150893211364746\n",
      "Epoch 546: Train_loss 31318521856.0, Validation_loss 28956557312.0, Seconds 0.021999359130859375\n",
      "Epoch 547: Train_loss 31318288384.0, Validation_loss 28955213824.0, Seconds 0.018000364303588867\n",
      "Epoch 548: Train_loss 31317702656.0, Validation_loss 28953780224.0, Seconds 0.016999483108520508\n",
      "Epoch 549: Train_loss 31317395456.0, Validation_loss 28952481792.0, Seconds 0.020002365112304688\n",
      "Epoch 550: Train_loss 31317078016.0, Validation_loss 28951287808.0, Seconds 0.022513628005981445\n",
      "Epoch 551: Train_loss 31316867072.0, Validation_loss 28949987328.0, Seconds 0.023999691009521484\n",
      "Epoch 552: Train_loss 31316303872.0, Validation_loss 28948602880.0, Seconds 0.020998477935791016\n",
      "Epoch 553: Train_loss 31315961856.0, Validation_loss 28947417088.0, Seconds 0.02500009536743164\n",
      "Epoch 554: Train_loss 31315664896.0, Validation_loss 28946108416.0, Seconds 0.021003007888793945\n",
      "Epoch 555: Train_loss 31315329024.0, Validation_loss 28944766976.0, Seconds 0.018504858016967773\n",
      "Epoch 556: Train_loss 31315075072.0, Validation_loss 28943491072.0, Seconds 0.024002552032470703\n",
      "Epoch 557: Train_loss 31314581504.0, Validation_loss 28942252032.0, Seconds 0.021002531051635742\n",
      "Epoch 558: Train_loss 31314278400.0, Validation_loss 28940898304.0, Seconds 0.02000117301940918\n",
      "Epoch 559: Train_loss 31313909760.0, Validation_loss 28939669504.0, Seconds 0.01700425148010254\n",
      "Epoch 560: Train_loss 31313596416.0, Validation_loss 28938389504.0, Seconds 0.02150869369506836\n",
      "Epoch 561: Train_loss 31313313792.0, Validation_loss 28937064448.0, Seconds 0.023003578186035156\n",
      "Epoch 562: Train_loss 31312941056.0, Validation_loss 28935866368.0, Seconds 0.017000675201416016\n",
      "Epoch 563: Train_loss 31312537600.0, Validation_loss 28934535168.0, Seconds 0.01800084114074707\n",
      "Epoch 564: Train_loss 31312336896.0, Validation_loss 28933261312.0, Seconds 0.01700615882873535\n",
      "Epoch 565: Train_loss 31311941632.0, Validation_loss 28932079616.0, Seconds 0.01651597023010254\n",
      "Epoch 566: Train_loss 31311661056.0, Validation_loss 28930783232.0, Seconds 0.022994279861450195\n",
      "Epoch 567: Train_loss 31311351808.0, Validation_loss 28929525760.0, Seconds 0.023002147674560547\n",
      "Epoch 568: Train_loss 31311114240.0, Validation_loss 28928319488.0, Seconds 0.021998167037963867\n",
      "Epoch 569: Train_loss 31310811136.0, Validation_loss 28927105024.0, Seconds 0.021004676818847656\n",
      "Epoch 570: Train_loss 31310522368.0, Validation_loss 28925919232.0, Seconds 0.02150869369506836\n",
      "Epoch 571: Train_loss 31310245888.0, Validation_loss 28924633088.0, Seconds 0.02299976348876953\n",
      "Epoch 572: Train_loss 31309791232.0, Validation_loss 28923328512.0, Seconds 0.021999597549438477\n",
      "Epoch 573: Train_loss 31309518848.0, Validation_loss 28922161152.0, Seconds 0.023004531860351562\n",
      "Epoch 574: Train_loss 31309326336.0, Validation_loss 28920965120.0, Seconds 0.02251577377319336\n",
      "Epoch 575: Train_loss 31308750848.0, Validation_loss 28919568384.0, Seconds 0.0209963321685791\n",
      "Epoch 576: Train_loss 31308277760.0, Validation_loss 28918286336.0, Seconds 0.0209958553314209\n",
      "Epoch 577: Train_loss 31307931648.0, Validation_loss 28917168128.0, Seconds 0.023002147674560547\n",
      "Epoch 578: Train_loss 31307622400.0, Validation_loss 28915929088.0, Seconds 0.02000284194946289\n",
      "Epoch 579: Train_loss 31307429888.0, Validation_loss 28914601984.0, Seconds 0.02250981330871582\n",
      "Epoch 580: Train_loss 31307124736.0, Validation_loss 28913549312.0, Seconds 0.01999950408935547\n",
      "Epoch 581: Train_loss 31306831872.0, Validation_loss 28912465920.0, Seconds 0.02299809455871582\n",
      "Epoch 582: Train_loss 31306465280.0, Validation_loss 28911091712.0, Seconds 0.023007631301879883\n",
      "Epoch 583: Train_loss 31306258432.0, Validation_loss 28909926400.0, Seconds 0.019515037536621094\n",
      "Epoch 584: Train_loss 31306149888.0, Validation_loss 28908941312.0, Seconds 0.02300095558166504\n",
      "Epoch 585: Train_loss 31305760768.0, Validation_loss 28907681792.0, Seconds 0.02199864387512207\n",
      "Epoch 586: Train_loss 31305564160.0, Validation_loss 28906534912.0, Seconds 0.02200174331665039\n",
      "Epoch 587: Train_loss 31305179136.0, Validation_loss 28905388032.0, Seconds 0.019002437591552734\n",
      "Epoch 588: Train_loss 31304826880.0, Validation_loss 28904155136.0, Seconds 0.0225064754486084\n",
      "Epoch 589: Train_loss 31304767488.0, Validation_loss 28903106560.0, Seconds 0.018000125885009766\n",
      "Epoch 590: Train_loss 31304484864.0, Validation_loss 28902117376.0, Seconds 0.01699995994567871\n",
      "Epoch 591: Train_loss 31304224768.0, Validation_loss 28900880384.0, Seconds 0.01699972152709961\n",
      "Epoch 592: Train_loss 31303895040.0, Validation_loss 28899700736.0, Seconds 0.02000117301940918\n",
      "Epoch 593: Train_loss 31303503872.0, Validation_loss 28898625536.0, Seconds 0.02050924301147461\n",
      "Epoch 594: Train_loss 31303407616.0, Validation_loss 28897433600.0, Seconds 0.01900339126586914\n",
      "Epoch 595: Train_loss 31303114752.0, Validation_loss 28896385024.0, Seconds 0.023996591567993164\n",
      "Epoch 596: Train_loss 31302723584.0, Validation_loss 28895234048.0, Seconds 0.023001670837402344\n",
      "Epoch 597: Train_loss 31302709248.0, Validation_loss 28894181376.0, Seconds 0.02700185775756836\n",
      "Epoch 598: Train_loss 31302367232.0, Validation_loss 28893114368.0, Seconds 0.02351093292236328\n",
      "Epoch 599: Train_loss 31302086656.0, Validation_loss 28891930624.0, Seconds 0.021996498107910156\n",
      "Epoch 600: Train_loss 31301928960.0, Validation_loss 28890894336.0, Seconds 0.024002552032470703\n",
      "Epoch 601: Train_loss 31301580800.0, Validation_loss 28889843712.0, Seconds 0.09452962875366211\n",
      "Epoch 602: Train_loss 31301310464.0, Validation_loss 28888805376.0, Seconds 0.023000717163085938\n",
      "Epoch 603: Train_loss 31301197824.0, Validation_loss 28887631872.0, Seconds 0.022151708602905273\n",
      "Epoch 604: Train_loss 31300954112.0, Validation_loss 28886667264.0, Seconds 0.020993947982788086\n",
      "Epoch 605: Train_loss 31300702208.0, Validation_loss 28885751808.0, Seconds 0.020998239517211914\n",
      "Epoch 606: Train_loss 31300507648.0, Validation_loss 28884645888.0, Seconds 0.023000478744506836\n",
      "Epoch 607: Train_loss 31300220928.0, Validation_loss 28883453952.0, Seconds 0.017003774642944336\n",
      "Epoch 608: Train_loss 31299946496.0, Validation_loss 28882429952.0, Seconds 0.017505407333374023\n",
      "Epoch 609: Train_loss 31299753984.0, Validation_loss 28881598464.0, Seconds 0.041998863220214844\n",
      "Epoch 610: Train_loss 31299618816.0, Validation_loss 28880691200.0, Seconds 0.02700018882751465\n",
      "Epoch 611: Train_loss 31299440640.0, Validation_loss 28879591424.0, Seconds 0.021005630493164062\n",
      "Epoch 612: Train_loss 31299125248.0, Validation_loss 28878395392.0, Seconds 0.018533706665039062\n",
      "Epoch 613: Train_loss 31298893824.0, Validation_loss 28877365248.0, Seconds 0.02100229263305664\n",
      "Epoch 614: Train_loss 31298699264.0, Validation_loss 28876505088.0, Seconds 0.022999048233032227\n",
      "Epoch 615: Train_loss 31298508800.0, Validation_loss 28875573248.0, Seconds 0.018999099731445312\n",
      "Epoch 616: Train_loss 31298271232.0, Validation_loss 28874539008.0, Seconds 0.020002365112304688\n",
      "Epoch 617: Train_loss 31298041856.0, Validation_loss 28873365504.0, Seconds 0.021508216857910156\n",
      "Epoch 618: Train_loss 31297857536.0, Validation_loss 28872359936.0, Seconds 0.019999265670776367\n",
      "Epoch 619: Train_loss 31297593344.0, Validation_loss 28871518208.0, Seconds 0.019000530242919922\n",
      "Epoch 620: Train_loss 31297431552.0, Validation_loss 28870584320.0, Seconds 0.02099919319152832\n",
      "Epoch 621: Train_loss 31297163264.0, Validation_loss 28869556224.0, Seconds 0.01800370216369629\n",
      "Epoch 622: Train_loss 31296991232.0, Validation_loss 28868474880.0, Seconds 0.019512653350830078\n",
      "Epoch 623: Train_loss 31296763904.0, Validation_loss 28867454976.0, Seconds 0.019994020462036133\n",
      "Epoch 624: Train_loss 31296458752.0, Validation_loss 28866594816.0, Seconds 0.020000934600830078\n",
      "Epoch 625: Train_loss 31296346112.0, Validation_loss 28865673216.0, Seconds 0.023998022079467773\n",
      "Epoch 626: Train_loss 31296155648.0, Validation_loss 28864720896.0, Seconds 0.023514986038208008\n",
      "Epoch 627: Train_loss 31295895552.0, Validation_loss 28863744000.0, Seconds 0.022995948791503906\n",
      "Epoch 628: Train_loss 31295627264.0, Validation_loss 28862896128.0, Seconds 0.022006988525390625\n",
      "Epoch 629: Train_loss 31295479808.0, Validation_loss 28862017536.0, Seconds 0.0229952335357666\n",
      "Epoch 630: Train_loss 31295295488.0, Validation_loss 28860999680.0, Seconds 0.01900196075439453\n",
      "Epoch 631: Train_loss 31295002624.0, Validation_loss 28860151808.0, Seconds 0.01750636100769043\n",
      "Epoch 632: Train_loss 31294867456.0, Validation_loss 28859344896.0, Seconds 0.01800060272216797\n",
      "Epoch 633: Train_loss 31294640128.0, Validation_loss 28858462208.0, Seconds 0.018999099731445312\n",
      "Epoch 634: Train_loss 31294330880.0, Validation_loss 28857403392.0, Seconds 0.01999974250793457\n",
      "Epoch 635: Train_loss 31294234624.0, Validation_loss 28856426496.0, Seconds 0.022004365921020508\n",
      "Epoch 636: Train_loss 31294001152.0, Validation_loss 28855611392.0, Seconds 0.02251887321472168\n",
      "Epoch 637: Train_loss 31293767680.0, Validation_loss 28854884352.0, Seconds 0.017998456954956055\n",
      "Epoch 638: Train_loss 31293343744.0, Validation_loss 28854020096.0, Seconds 0.021994352340698242\n",
      "Epoch 639: Train_loss 31293067264.0, Validation_loss 28853104640.0, Seconds 0.02000117301940918\n",
      "Epoch 640: Train_loss 31292921856.0, Validation_loss 28852107264.0, Seconds 0.02200174331665039\n",
      "Epoch 641: Train_loss 31292661760.0, Validation_loss 28851236864.0, Seconds 0.019507408142089844\n",
      "Epoch 642: Train_loss 31291815936.0, Validation_loss 28849721344.0, Seconds 0.01899886131286621\n",
      "Epoch 643: Train_loss 31292698624.0, Validation_loss 28849668096.0, Seconds 0.01799917221069336\n",
      "Epoch 644: Train_loss 31291858944.0, Validation_loss 28849326080.0, Seconds 0.020001888275146484\n",
      "Epoch 645: Train_loss 31292628992.0, Validation_loss 28847978496.0, Seconds 0.022003889083862305\n",
      "Epoch 646: Train_loss 31291600896.0, Validation_loss 28847417344.0, Seconds 0.017505645751953125\n",
      "Epoch 647: Train_loss 31291756544.0, Validation_loss 28846440448.0, Seconds 0.01900005340576172\n",
      "Epoch 648: Train_loss 31291541504.0, Validation_loss 28845713408.0, Seconds 0.018999814987182617\n",
      "Epoch 649: Train_loss 31291305984.0, Validation_loss 28845178880.0, Seconds 0.01900029182434082\n",
      "Epoch 650: Train_loss 31291410432.0, Validation_loss 28844261376.0, Seconds 0.02400374412536621\n",
      "Epoch 651: Train_loss 31291095040.0, Validation_loss 28843587584.0, Seconds 0.01851797103881836\n",
      "Epoch 652: Train_loss 31290912768.0, Validation_loss 28842690560.0, Seconds 0.017000913619995117\n",
      "Epoch 653: Train_loss 31290636288.0, Validation_loss 28841891840.0, Seconds 0.01999950408935547\n",
      "Epoch 654: Train_loss 31290488832.0, Validation_loss 28841273344.0, Seconds 0.023995637893676758\n",
      "Epoch 655: Train_loss 31290462208.0, Validation_loss 28840675328.0, Seconds 0.019002199172973633\n",
      "Epoch 656: Train_loss 31290277888.0, Validation_loss 28839913472.0, Seconds 0.026076793670654297\n",
      "Epoch 657: Train_loss 31290195968.0, Validation_loss 28839045120.0, Seconds 0.01900005340576172\n",
      "Epoch 658: Train_loss 31289915392.0, Validation_loss 28838373376.0, Seconds 0.022999286651611328\n",
      "Epoch 659: Train_loss 31289833472.0, Validation_loss 28837660672.0, Seconds 0.021004438400268555\n",
      "Epoch 660: Train_loss 31289620480.0, Validation_loss 28837062656.0, Seconds 0.019008159637451172\n",
      "Epoch 661: Train_loss 31289530368.0, Validation_loss 28836313088.0, Seconds 0.018526315689086914\n",
      "Epoch 662: Train_loss 31289393152.0, Validation_loss 28835643392.0, Seconds 0.02200007438659668\n",
      "Epoch 663: Train_loss 31289257984.0, Validation_loss 28834981888.0, Seconds 0.020000457763671875\n",
      "Epoch 664: Train_loss 31289118720.0, Validation_loss 28834258944.0, Seconds 0.02200460433959961\n",
      "Epoch 665: Train_loss 31288997888.0, Validation_loss 28833525760.0, Seconds 0.01952195167541504\n",
      "Epoch 666: Train_loss 31288770560.0, Validation_loss 28832911360.0, Seconds 0.021994829177856445\n",
      "Epoch 667: Train_loss 31288694784.0, Validation_loss 28832241664.0, Seconds 0.024000883102416992\n",
      "Epoch 668: Train_loss 31288530944.0, Validation_loss 28831537152.0, Seconds 0.022999286651611328\n",
      "Epoch 669: Train_loss 31288467456.0, Validation_loss 28831031296.0, Seconds 0.08451437950134277\n",
      "Epoch 670: Train_loss 31288256512.0, Validation_loss 28830386176.0, Seconds 0.02199840545654297\n",
      "Epoch 671: Train_loss 31288162304.0, Validation_loss 28829683712.0, Seconds 0.02250385284423828\n",
      "Epoch 672: Train_loss 31287914496.0, Validation_loss 28829028352.0, Seconds 0.02300572395324707\n",
      "Epoch 673: Train_loss 31287865344.0, Validation_loss 28828289024.0, Seconds 0.021998167037963867\n",
      "Epoch 674: Train_loss 31287709696.0, Validation_loss 28827684864.0, Seconds 0.023998737335205078\n",
      "Epoch 675: Train_loss 31287476224.0, Validation_loss 28827129856.0, Seconds 0.023003816604614258\n",
      "Epoch 676: Train_loss 31287296000.0, Validation_loss 28826515456.0, Seconds 0.021538734436035156\n",
      "Epoch 677: Train_loss 31286695936.0, Validation_loss 28825524224.0, Seconds 0.017992496490478516\n",
      "Epoch 678: Train_loss 31286792192.0, Validation_loss 28824924160.0, Seconds 0.018999814987182617\n",
      "Epoch 679: Train_loss 31287130112.0, Validation_loss 28824576000.0, Seconds 0.024007320404052734\n",
      "Epoch 680: Train_loss 31286695936.0, Validation_loss 28823885824.0, Seconds 0.020009517669677734\n",
      "Epoch 681: Train_loss 31286228992.0, Validation_loss 28823132160.0, Seconds 0.019507884979248047\n",
      "Epoch 682: Train_loss 31286439936.0, Validation_loss 28822530048.0, Seconds 0.018998384475708008\n",
      "Epoch 683: Train_loss 31286228992.0, Validation_loss 28822083584.0, Seconds 0.02299976348876953\n",
      "Epoch 684: Train_loss 31286122496.0, Validation_loss 28821436416.0, Seconds 0.023000001907348633\n",
      "Epoch 685: Train_loss 31285942272.0, Validation_loss 28820838400.0, Seconds 0.023514270782470703\n",
      "Epoch 686: Train_loss 31285737472.0, Validation_loss 28820230144.0, Seconds 0.022997379302978516\n",
      "Epoch 687: Train_loss 31285905408.0, Validation_loss 28819775488.0, Seconds 0.02200007438659668\n",
      "Epoch 688: Train_loss 31285633024.0, Validation_loss 28819214336.0, Seconds 0.01999974250793457\n",
      "Epoch 689: Train_loss 31285469184.0, Validation_loss 28818550784.0, Seconds 0.02300286293029785\n",
      "Epoch 690: Train_loss 31285432320.0, Validation_loss 28818046976.0, Seconds 0.019506216049194336\n",
      "Epoch 691: Train_loss 31285401600.0, Validation_loss 28817494016.0, Seconds 0.018999338150024414\n",
      "Epoch 692: Train_loss 31285192704.0, Validation_loss 28816883712.0, Seconds 0.01900029182434082\n",
      "Epoch 693: Train_loss 31284983808.0, Validation_loss 28816455680.0, Seconds 0.023001909255981445\n",
      "Epoch 694: Train_loss 31284918272.0, Validation_loss 28815982592.0, Seconds 0.019004344940185547\n",
      "Epoch 695: Train_loss 31284848640.0, Validation_loss 28815466496.0, Seconds 0.020525217056274414\n",
      "Epoch 696: Train_loss 31284658176.0, Validation_loss 28814813184.0, Seconds 0.018999814987182617\n",
      "Epoch 697: Train_loss 31284566016.0, Validation_loss 28814358528.0, Seconds 0.023001432418823242\n",
      "Epoch 698: Train_loss 31284500480.0, Validation_loss 28813916160.0, Seconds 0.02000737190246582\n",
      "Epoch 699: Train_loss 31284453376.0, Validation_loss 28813406208.0, Seconds 0.01899886131286621\n",
      "Epoch 700: Train_loss 31284310016.0, Validation_loss 28812742656.0, Seconds 0.022508859634399414\n",
      "Epoch 701: Train_loss 31283910656.0, Validation_loss 28812152832.0, Seconds 0.021999359130859375\n",
      "Epoch 702: Train_loss 31283884032.0, Validation_loss 28811702272.0, Seconds 0.019999265670776367\n",
      "Epoch 703: Train_loss 31283857408.0, Validation_loss 28811292672.0, Seconds 0.021998167037963867\n",
      "Epoch 704: Train_loss 31283621888.0, Validation_loss 28810754048.0, Seconds 0.02100682258605957\n",
      "Epoch 705: Train_loss 31283677184.0, Validation_loss 28810407936.0, Seconds 0.02051067352294922\n",
      "Epoch 706: Train_loss 31283699712.0, Validation_loss 28809908224.0, Seconds 0.02099919319152832\n",
      "Epoch 707: Train_loss 31283499008.0, Validation_loss 28809398272.0, Seconds 0.018999576568603516\n",
      "Epoch 708: Train_loss 31283509248.0, Validation_loss 28808859648.0, Seconds 0.018004179000854492\n",
      "Epoch 709: Train_loss 31283542016.0, Validation_loss 28808497152.0, Seconds 0.018008708953857422\n",
      "Epoch 710: Train_loss 31283210240.0, Validation_loss 28807979008.0, Seconds 0.0205080509185791\n",
      "Epoch 711: Train_loss 31283038208.0, Validation_loss 28807475200.0, Seconds 0.023001909255981445\n",
      "Epoch 712: Train_loss 31282853888.0, Validation_loss 28807057408.0, Seconds 0.021998882293701172\n",
      "Epoch 713: Train_loss 31282706432.0, Validation_loss 28806576128.0, Seconds 0.01999831199645996\n",
      "Epoch 714: Train_loss 31282749440.0, Validation_loss 28806197248.0, Seconds 0.022521495819091797\n",
      "Epoch 715: Train_loss 31282706432.0, Validation_loss 28805767168.0, Seconds 0.01999950408935547\n",
      "Epoch 716: Train_loss 31282350080.0, Validation_loss 28805201920.0, Seconds 0.024001121520996094\n",
      "Epoch 717: Train_loss 31282630656.0, Validation_loss 28804818944.0, Seconds 0.02100086212158203\n",
      "Epoch 718: Train_loss 31282464768.0, Validation_loss 28804540416.0, Seconds 0.0220034122467041\n",
      "Epoch 719: Train_loss 31282219008.0, Validation_loss 28803981312.0, Seconds 0.01851511001586914\n",
      "Epoch 720: Train_loss 31282038784.0, Validation_loss 28803530752.0, Seconds 0.01900029182434082\n",
      "Epoch 721: Train_loss 31282014208.0, Validation_loss 28803147776.0, Seconds 0.020003080368041992\n",
      "Epoch 722: Train_loss 31281926144.0, Validation_loss 28802838528.0, Seconds 0.018000125885009766\n",
      "Epoch 723: Train_loss 31281698816.0, Validation_loss 28802506752.0, Seconds 0.02200007438659668\n",
      "Epoch 724: Train_loss 31281668096.0, Validation_loss 28802025472.0, Seconds 0.021519899368286133\n",
      "Epoch 725: Train_loss 31281684480.0, Validation_loss 28801650688.0, Seconds 0.022996187210083008\n",
      "Epoch 726: Train_loss 31281369088.0, Validation_loss 28801181696.0, Seconds 0.020995616912841797\n",
      "Epoch 727: Train_loss 31281405952.0, Validation_loss 28800792576.0, Seconds 0.022996902465820312\n",
      "Epoch 728: Train_loss 31281231872.0, Validation_loss 28800434176.0, Seconds 0.02100825309753418\n",
      "Epoch 729: Train_loss 31281039360.0, Validation_loss 28800018432.0, Seconds 0.018505334854125977\n",
      "Epoch 730: Train_loss 31281014784.0, Validation_loss 28799600640.0, Seconds 0.024006366729736328\n",
      "Epoch 731: Train_loss 31280947200.0, Validation_loss 28799334400.0, Seconds 0.01899576187133789\n",
      "Epoch 732: Train_loss 31280869376.0, Validation_loss 28799074304.0, Seconds 0.021999597549438477\n",
      "Epoch 733: Train_loss 31280822272.0, Validation_loss 28798744576.0, Seconds 0.018517494201660156\n",
      "Epoch 734: Train_loss 31280619520.0, Validation_loss 28798466048.0, Seconds 0.020006656646728516\n",
      "Epoch 735: Train_loss 31280535552.0, Validation_loss 28798058496.0, Seconds 0.02299785614013672\n",
      "Epoch 736: Train_loss 31280535552.0, Validation_loss 28797720576.0, Seconds 0.02200007438659668\n",
      "Epoch 737: Train_loss 31280328704.0, Validation_loss 28797259776.0, Seconds 0.02001357078552246\n",
      "Epoch 738: Train_loss 31280187392.0, Validation_loss 28796901376.0, Seconds 0.022525787353515625\n",
      "Epoch 739: Train_loss 31280177152.0, Validation_loss 28796655616.0, Seconds 0.02399897575378418\n",
      "Epoch 740: Train_loss 31280072704.0, Validation_loss 28796329984.0, Seconds 0.019999980926513672\n",
      "Epoch 741: Train_loss 31279831040.0, Validation_loss 28796080128.0, Seconds 0.02400040626525879\n",
      "Epoch 742: Train_loss 31279716352.0, Validation_loss 28795789312.0, Seconds 0.018002748489379883\n",
      "Epoch 743: Train_loss 31279618048.0, Validation_loss 28795582464.0, Seconds 0.017506122589111328\n",
      "Epoch 744: Train_loss 31279411200.0, Validation_loss 28795172864.0, Seconds 0.01700735092163086\n",
      "Epoch 745: Train_loss 31279005696.0, Validation_loss 28794783744.0, Seconds 0.018993139266967773\n",
      "Epoch 746: Train_loss 31278989312.0, Validation_loss 28794439680.0, Seconds 0.017998456954956055\n",
      "Epoch 747: Train_loss 31279124480.0, Validation_loss 28794267648.0, Seconds 0.021003007888793945\n",
      "Epoch 748: Train_loss 31278929920.0, Validation_loss 28793919488.0, Seconds 0.020507335662841797\n",
      "Epoch 749: Train_loss 31278934016.0, Validation_loss 28793640960.0, Seconds 0.02100515365600586\n",
      "Epoch 750: Train_loss 31278491648.0, Validation_loss 28793331712.0, Seconds 0.01899266242980957\n",
      "Epoch 751: Train_loss 31278622720.0, Validation_loss 28792995840.0, Seconds 0.023999929428100586\n",
      "Epoch 752: Train_loss 31278479360.0, Validation_loss 28792819712.0, Seconds 0.02301812171936035\n",
      "Epoch 753: Train_loss 31278413824.0, Validation_loss 28792537088.0, Seconds 0.021224260330200195\n",
      "Epoch 754: Train_loss 31278323712.0, Validation_loss 28792266752.0, Seconds 0.0240023136138916\n",
      "Epoch 755: Train_loss 31278161920.0, Validation_loss 28791937024.0, Seconds 0.018000125885009766\n",
      "Epoch 756: Train_loss 31278063616.0, Validation_loss 28791681024.0, Seconds 0.019999027252197266\n",
      "Epoch 757: Train_loss 31278053376.0, Validation_loss 28791404544.0, Seconds 0.021503925323486328\n",
      "Epoch 758: Train_loss 31277916160.0, Validation_loss 28791138304.0, Seconds 0.021004676818847656\n",
      "Epoch 759: Train_loss 31277975552.0, Validation_loss 28790882304.0, Seconds 0.020000696182250977\n",
      "Epoch 760: Train_loss 31277824000.0, Validation_loss 28790620160.0, Seconds 0.017000198364257812\n",
      "Epoch 761: Train_loss 31277602816.0, Validation_loss 28790323200.0, Seconds 0.018997907638549805\n",
      "Epoch 762: Train_loss 31277709312.0, Validation_loss 28790126592.0, Seconds 0.017002344131469727\n",
      "Epoch 763: Train_loss 31277287424.0, Validation_loss 28789848064.0, Seconds 0.016506433486938477\n",
      "Epoch 764: Train_loss 31277451264.0, Validation_loss 28789489664.0, Seconds 0.016999244689941406\n",
      "Epoch 765: Train_loss 31277201408.0, Validation_loss 28789338112.0, Seconds 0.018999814987182617\n",
      "Epoch 766: Train_loss 31277191168.0, Validation_loss 28789073920.0, Seconds 0.023999691009521484\n",
      "Epoch 767: Train_loss 31277103104.0, Validation_loss 28788844544.0, Seconds 0.020016908645629883\n",
      "Epoch 768: Train_loss 31277049856.0, Validation_loss 28788572160.0, Seconds 0.023513317108154297\n",
      "Epoch 769: Train_loss 31277099008.0, Validation_loss 28788350976.0, Seconds 0.023005008697509766\n",
      "Epoch 770: Train_loss 31276713984.0, Validation_loss 28788101120.0, Seconds 0.024993181228637695\n",
      "Epoch 771: Train_loss 31276701696.0, Validation_loss 28787810304.0, Seconds 0.02099609375\n",
      "Epoch 772: Train_loss 31276871680.0, Validation_loss 28787709952.0, Seconds 0.02251291275024414\n",
      "Epoch 773: Train_loss 31276339200.0, Validation_loss 28787451904.0, Seconds 0.02200007438659668\n",
      "Epoch 774: Train_loss 31276675072.0, Validation_loss 28787267584.0, Seconds 0.021998167037963867\n",
      "Epoch 775: Train_loss 31276312576.0, Validation_loss 28787128320.0, Seconds 0.017002582550048828\n",
      "Epoch 776: Train_loss 31276324864.0, Validation_loss 28786724864.0, Seconds 0.02301812171936035\n",
      "Epoch 777: Train_loss 31276316672.0, Validation_loss 28786661376.0, Seconds 0.02051377296447754\n",
      "Epoch 778: Train_loss 31275966464.0, Validation_loss 28786362368.0, Seconds 0.02098989486694336\n",
      "Epoch 779: Train_loss 31276042240.0, Validation_loss 28786100224.0, Seconds 0.019006729125976562\n",
      "Epoch 780: Train_loss 31276029952.0, Validation_loss 28785997824.0, Seconds 0.019995927810668945\n",
      "Epoch 781: Train_loss 31275732992.0, Validation_loss 28785678336.0, Seconds 0.0220029354095459\n",
      "Epoch 782: Train_loss 31275857920.0, Validation_loss 28785553408.0, Seconds 0.020511388778686523\n",
      "Epoch 783: Train_loss 31275755520.0, Validation_loss 28785362944.0, Seconds 0.020995616912841797\n",
      "Epoch 784: Train_loss 31275304960.0, Validation_loss 28785047552.0, Seconds 0.021999359130859375\n",
      "Epoch 785: Train_loss 31275472896.0, Validation_loss 28784949248.0, Seconds 0.02299809455871582\n",
      "Epoch 786: Train_loss 31275419648.0, Validation_loss 28784797696.0, Seconds 0.02052760124206543\n",
      "Epoch 787: Train_loss 31275235328.0, Validation_loss 28784476160.0, Seconds 0.02500772476196289\n",
      "Epoch 788: Train_loss 31275061248.0, Validation_loss 28784330752.0, Seconds 0.022999048233032227\n",
      "Epoch 789: Train_loss 31275083776.0, Validation_loss 28784173056.0, Seconds 0.023000240325927734\n",
      "Epoch 790: Train_loss 31274962944.0, Validation_loss 28784015360.0, Seconds 0.022002458572387695\n",
      "Epoch 791: Train_loss 31274856448.0, Validation_loss 28783769600.0, Seconds 0.020519733428955078\n",
      "Epoch 792: Train_loss 31274790912.0, Validation_loss 28783562752.0, Seconds 0.020998477935791016\n",
      "Epoch 793: Train_loss 31274741760.0, Validation_loss 28783443968.0, Seconds 0.016999483108520508\n",
      "Epoch 794: Train_loss 31274547200.0, Validation_loss 28783319040.0, Seconds 0.01900005340576172\n",
      "Epoch 795: Train_loss 31274452992.0, Validation_loss 28783306752.0, Seconds 0.022003173828125\n",
      "Epoch 796: Train_loss 31274194944.0, Validation_loss 28783366144.0, Seconds 0.01650524139404297\n",
      "Epoch 797: Train_loss 31274311680.0, Validation_loss 28783558656.0, Seconds 0.019007205963134766\n",
      "Epoch 798: Train_loss 31274254336.0, Validation_loss 28783536128.0, Seconds 0.017993450164794922\n",
      "Epoch 799: Train_loss 31274176512.0, Validation_loss 28783204352.0, Seconds 0.01900029182434082\n",
      "Epoch 800: Train_loss 31273998336.0, Validation_loss 28782741504.0, Seconds 0.022004365921020508\n",
      "Epoch 801: Train_loss 31273809920.0, Validation_loss 28782237696.0, Seconds 0.0915062427520752\n",
      "Epoch 802: Train_loss 31273523200.0, Validation_loss 28782176256.0, Seconds 0.023508787155151367\n",
      "Epoch 803: Train_loss 31273682944.0, Validation_loss 28782118912.0, Seconds 0.02299976348876953\n",
      "Epoch 804: Train_loss 31273592832.0, Validation_loss 28782069760.0, Seconds 0.020999670028686523\n",
      "Epoch 805: Train_loss 31273428992.0, Validation_loss 28781684736.0, Seconds 0.023002147674560547\n",
      "Epoch 806: Train_loss 31273355264.0, Validation_loss 28781373440.0, Seconds 0.01700282096862793\n",
      "Epoch 807: Train_loss 31273027584.0, Validation_loss 28781375488.0, Seconds 0.018504619598388672\n",
      "Epoch 808: Train_loss 31272767488.0, Validation_loss 28781774848.0, Seconds 0.022001266479492188\n",
      "Epoch 809: Train_loss 31272974336.0, Validation_loss 28781334528.0, Seconds 0.01899886131286621\n",
      "Epoch 810: Train_loss 31273054208.0, Validation_loss 28781002752.0, Seconds 0.019001245498657227\n",
      "Epoch 811: Train_loss 31272525824.0, Validation_loss 28780769280.0, Seconds 0.016998767852783203\n",
      "Epoch 812: Train_loss 31272314880.0, Validation_loss 28780652544.0, Seconds 0.0185091495513916\n",
      "Epoch 813: Train_loss 31271495680.0, Validation_loss 28779761664.0, Seconds 0.01999974250793457\n",
      "Epoch 814: Train_loss 31270909952.0, Validation_loss 28779386880.0, Seconds 0.02299976348876953\n",
      "Epoch 815: Train_loss 31271960576.0, Validation_loss 28779411456.0, Seconds 0.01999974250793457\n",
      "Epoch 816: Train_loss 31271245824.0, Validation_loss 28779329536.0, Seconds 0.02300286293029785\n",
      "Epoch 817: Train_loss 31270789120.0, Validation_loss 28779053056.0, Seconds 0.019513607025146484\n",
      "Epoch 818: Train_loss 31271174144.0, Validation_loss 28779079680.0, Seconds 0.02199864387512207\n",
      "Epoch 819: Train_loss 31271360512.0, Validation_loss 28779112448.0, Seconds 0.022996187210083008\n",
      "Epoch 820: Train_loss 31270817792.0, Validation_loss 28779038720.0, Seconds 0.02199697494506836\n",
      "Epoch 821: Train_loss 31271426048.0, Validation_loss 28779288576.0, Seconds 0.019002914428710938\n",
      "Epoch 822: Train_loss 31271485440.0, Validation_loss 28779249664.0, Seconds 0.017505407333374023\n",
      "Epoch 823: Train_loss 31270959104.0, Validation_loss 28778657792.0, Seconds 0.01900172233581543\n",
      "Epoch 824: Train_loss 31270856704.0, Validation_loss 28778450944.0, Seconds 0.0180056095123291\n",
      "Epoch 825: Train_loss 31270729728.0, Validation_loss 28778336256.0, Seconds 0.0229952335357666\n",
      "Epoch 826: Train_loss 31270643712.0, Validation_loss 28778076160.0, Seconds 0.01900315284729004\n",
      "Epoch 827: Train_loss 31270563840.0, Validation_loss 28777803776.0, Seconds 0.022513389587402344\n",
      "Epoch 828: Train_loss 31270320128.0, Validation_loss 28777715712.0, Seconds 0.021995067596435547\n",
      "Epoch 829: Train_loss 31270443008.0, Validation_loss 28777592832.0, Seconds 0.020998001098632812\n",
      "Epoch 830: Train_loss 31270264832.0, Validation_loss 28777365504.0, Seconds 0.021999120712280273\n",
      "Epoch 831: Train_loss 31270193152.0, Validation_loss 28777086976.0, Seconds 0.021002769470214844\n",
      "Epoch 832: Train_loss 31269939200.0, Validation_loss 28777005056.0, Seconds 0.017505645751953125\n",
      "Epoch 833: Train_loss 31269951488.0, Validation_loss 28776708096.0, Seconds 0.024999618530273438\n",
      "Epoch 834: Train_loss 31269873664.0, Validation_loss 28776517632.0, Seconds 0.024000167846679688\n",
      "Epoch 835: Train_loss 31269599232.0, Validation_loss 28776433664.0, Seconds 0.023005008697509766\n",
      "Epoch 836: Train_loss 31269771264.0, Validation_loss 28776304640.0, Seconds 0.0225067138671875\n",
      "Epoch 837: Train_loss 31269548032.0, Validation_loss 28776185856.0, Seconds 0.020005464553833008\n",
      "Epoch 838: Train_loss 31269615616.0, Validation_loss 28776169472.0, Seconds 0.018991947174072266\n",
      "Epoch 839: Train_loss 31269402624.0, Validation_loss 28776022016.0, Seconds 0.023999929428100586\n",
      "Epoch 840: Train_loss 31269083136.0, Validation_loss 28775608320.0, Seconds 0.01900458335876465\n",
      "Epoch 841: Train_loss 31269322752.0, Validation_loss 28775403520.0, Seconds 0.01750922203063965\n",
      "Epoch 842: Train_loss 31269001216.0, Validation_loss 28775446528.0, Seconds 0.020999431610107422\n",
      "Epoch 843: Train_loss 31269185536.0, Validation_loss 28775223296.0, Seconds 0.018001556396484375\n",
      "Epoch 844: Train_loss 31268812800.0, Validation_loss 28775243776.0, Seconds 0.01699995994567871\n",
      "Epoch 845: Train_loss 31268792320.0, Validation_loss 28775010304.0, Seconds 0.0180051326751709\n",
      "Epoch 846: Train_loss 31268700160.0, Validation_loss 28774909952.0, Seconds 0.022530794143676758\n",
      "Epoch 847: Train_loss 31268583424.0, Validation_loss 28774746112.0, Seconds 0.022002696990966797\n",
      "Epoch 848: Train_loss 31268624384.0, Validation_loss 28774811648.0, Seconds 0.02899765968322754\n",
      "Epoch 849: Train_loss 31268454400.0, Validation_loss 28774643712.0, Seconds 0.02100658416748047\n",
      "Epoch 850: Train_loss 31268415488.0, Validation_loss 28774234112.0, Seconds 0.021518945693969727\n",
      "Epoch 851: Train_loss 31268036608.0, Validation_loss 28774078464.0, Seconds 0.017996788024902344\n",
      "Epoch 852: Train_loss 31268042752.0, Validation_loss 28774010880.0, Seconds 0.017999649047851562\n",
      "Epoch 853: Train_loss 31267983360.0, Validation_loss 28774144000.0, Seconds 0.02000737190246582\n",
      "Epoch 854: Train_loss 31267930112.0, Validation_loss 28774277120.0, Seconds 0.02399444580078125\n",
      "Epoch 855: Train_loss 31268206592.0, Validation_loss 28774105088.0, Seconds 0.020507335662841797\n",
      "Epoch 856: Train_loss 31267719168.0, Validation_loss 28773806080.0, Seconds 0.02600264549255371\n",
      "Epoch 857: Train_loss 31267627008.0, Validation_loss 28773478400.0, Seconds 0.01999950408935547\n",
      "Epoch 858: Train_loss 31267383296.0, Validation_loss 28773593088.0, Seconds 0.021999835968017578\n",
      "Epoch 859: Train_loss 31267549184.0, Validation_loss 28773453824.0, Seconds 0.023001670837402344\n",
      "Epoch 860: Train_loss 31267436544.0, Validation_loss 28773365760.0, Seconds 0.019504547119140625\n",
      "Epoch 861: Train_loss 31267338240.0, Validation_loss 28773345280.0, Seconds 0.022001981735229492\n",
      "Epoch 862: Train_loss 31267332096.0, Validation_loss 28773332992.0, Seconds 0.026000022888183594\n",
      "Epoch 863: Train_loss 31266854912.0, Validation_loss 28773093376.0, Seconds 0.022003173828125\n",
      "Epoch 864: Train_loss 31267022848.0, Validation_loss 28773007360.0, Seconds 0.021507978439331055\n",
      "Epoch 865: Train_loss 31266725888.0, Validation_loss 28773013504.0, Seconds 0.0240020751953125\n",
      "Epoch 866: Train_loss 31266922496.0, Validation_loss 28772892672.0, Seconds 0.020998716354370117\n",
      "Epoch 867: Train_loss 31266521088.0, Validation_loss 28772833280.0, Seconds 0.024001121520996094\n",
      "Epoch 868: Train_loss 31266541568.0, Validation_loss 28772554752.0, Seconds 0.08751535415649414\n",
      "Epoch 869: Train_loss 31266541568.0, Validation_loss 28772855808.0, Seconds 0.02100062370300293\n",
      "Epoch 870: Train_loss 31266383872.0, Validation_loss 28772560896.0, Seconds 0.022523164749145508\n",
      "Epoch 871: Train_loss 31266242560.0, Validation_loss 28772343808.0, Seconds 0.019001245498657227\n",
      "Epoch 872: Train_loss 31266189312.0, Validation_loss 28772212736.0, Seconds 0.020998477935791016\n",
      "Epoch 873: Train_loss 31265929216.0, Validation_loss 28772122624.0, Seconds 0.021999835968017578\n",
      "Epoch 874: Train_loss 31265984512.0, Validation_loss 28772300800.0, Seconds 0.024005413055419922\n",
      "Epoch 875: Train_loss 31265988608.0, Validation_loss 28772245504.0, Seconds 0.02151012420654297\n",
      "Epoch 876: Train_loss 31265622016.0, Validation_loss 28772061184.0, Seconds 0.01999950408935547\n",
      "Epoch 877: Train_loss 31265761280.0, Validation_loss 28771887104.0, Seconds 0.02199840545654297\n",
      "Epoch 878: Train_loss 31265323008.0, Validation_loss 28771731456.0, Seconds 0.02300119400024414\n",
      "Epoch 879: Train_loss 31265529856.0, Validation_loss 28771796992.0, Seconds 0.020012378692626953\n",
      "Epoch 880: Train_loss 31265501184.0, Validation_loss 28772001792.0, Seconds 0.02251410484313965\n",
      "Epoch 881: Train_loss 31265355776.0, Validation_loss 28771772416.0, Seconds 0.018004655838012695\n",
      "Epoch 882: Train_loss 31265167360.0, Validation_loss 28771643392.0, Seconds 0.024988651275634766\n",
      "Epoch 883: Train_loss 31264858112.0, Validation_loss 28771405824.0, Seconds 0.02300572395324707\n",
      "Epoch 884: Train_loss 31264960512.0, Validation_loss 28771348480.0, Seconds 0.021503925323486328\n",
      "Epoch 885: Train_loss 31264694272.0, Validation_loss 28771465216.0, Seconds 0.022001981735229492\n",
      "Epoch 886: Train_loss 31264833536.0, Validation_loss 28771557376.0, Seconds 0.018997669219970703\n",
      "Epoch 887: Train_loss 31264774144.0, Validation_loss 28771452928.0, Seconds 0.020002126693725586\n",
      "Epoch 888: Train_loss 31264499712.0, Validation_loss 28771301376.0, Seconds 0.022012710571289062\n",
      "Epoch 889: Train_loss 31264315392.0, Validation_loss 28771115008.0, Seconds 0.01750326156616211\n",
      "Epoch 890: Train_loss 31263653888.0, Validation_loss 28770965504.0, Seconds 0.019011259078979492\n",
      "Epoch 891: Train_loss 31263868928.0, Validation_loss 28770920448.0, Seconds 0.018990039825439453\n",
      "Epoch 892: Train_loss 31264071680.0, Validation_loss 28771041280.0, Seconds 0.019000768661499023\n",
      "Epoch 893: Train_loss 31263707136.0, Validation_loss 28770822144.0, Seconds 0.017998218536376953\n",
      "Epoch 894: Train_loss 31263674368.0, Validation_loss 28770822144.0, Seconds 0.017505645751953125\n",
      "Epoch 895: Train_loss 31263344640.0, Validation_loss 28770963456.0, Seconds 0.018005847930908203\n",
      "Epoch 896: Train_loss 31263604736.0, Validation_loss 28770897920.0, Seconds 0.019997358322143555\n",
      "Epoch 897: Train_loss 31263518720.0, Validation_loss 28771006464.0, Seconds 0.021007776260375977\n",
      "Epoch 898: Train_loss 31263272960.0, Validation_loss 28770805760.0, Seconds 0.017992496490478516\n",
      "Epoch 899: Train_loss 31263264768.0, Validation_loss 28770899968.0, Seconds 0.017003297805786133\n",
      "Epoch 900: Train_loss 31263004672.0, Validation_loss 28770942976.0, Seconds 0.02050614356994629\n",
      "Epoch 901: Train_loss 31263172608.0, Validation_loss 28770768896.0, Seconds 0.022998332977294922\n",
      "Epoch 902: Train_loss 31263002624.0, Validation_loss 28770785280.0, Seconds 0.02200031280517578\n",
      "Epoch 903: Train_loss 31262574592.0, Validation_loss 28770664448.0, Seconds 0.018001079559326172\n",
      "Epoch 904: Train_loss 31262689280.0, Validation_loss 28770713600.0, Seconds 0.02100372314453125\n",
      "Epoch 905: Train_loss 31262863360.0, Validation_loss 28770707456.0, Seconds 0.02550530433654785\n",
      "Epoch 906: Train_loss 31262324736.0, Validation_loss 28770615296.0, Seconds 0.022005081176757812\n",
      "Epoch 907: Train_loss 31262359552.0, Validation_loss 28770713600.0, Seconds 0.017999887466430664\n",
      "Epoch 908: Train_loss 31262683136.0, Validation_loss 28770693120.0, Seconds 0.021004199981689453\n",
      "Epoch 909: Train_loss 31262027776.0, Validation_loss 28770459648.0, Seconds 0.02350759506225586\n",
      "Epoch 910: Train_loss 31262169088.0, Validation_loss 28770392064.0, Seconds 0.023003816604614258\n",
      "Epoch 911: Train_loss 31262083072.0, Validation_loss 28770398208.0, Seconds 0.021994590759277344\n",
      "Epoch 912: Train_loss 31261661184.0, Validation_loss 28770299904.0, Seconds 0.022999048233032227\n",
      "Epoch 913: Train_loss 31261718528.0, Validation_loss 28770332672.0, Seconds 0.019004106521606445\n",
      "Epoch 914: Train_loss 31261685760.0, Validation_loss 28770404352.0, Seconds 0.017505407333374023\n",
      "Epoch 915: Train_loss 31261603840.0, Validation_loss 28770404352.0, Seconds 0.018000364303588867\n",
      "Epoch 916: Train_loss 31261485056.0, Validation_loss 28770437120.0, Seconds 0.022001266479492188\n",
      "Epoch 917: Train_loss 31261204480.0, Validation_loss 28770344960.0, Seconds 0.022998571395874023\n",
      "Epoch 918: Train_loss 31261452288.0, Validation_loss 28770371584.0, Seconds 0.01900482177734375\n",
      "Epoch 919: Train_loss 31261138944.0, Validation_loss 28770312192.0, Seconds 0.02250838279724121\n",
      "Epoch 920: Train_loss 31260899328.0, Validation_loss 28770142208.0, Seconds 0.018001079559326172\n",
      "Epoch 921: Train_loss 31260874752.0, Validation_loss 28770299904.0, Seconds 0.01699972152709961\n",
      "Epoch 922: Train_loss 31260710912.0, Validation_loss 28770392064.0, Seconds 0.018999338150024414\n",
      "Epoch 923: Train_loss 31260934144.0, Validation_loss 28770476032.0, Seconds 0.023003339767456055\n",
      "Epoch 924: Train_loss 31260696576.0, Validation_loss 28770269184.0, Seconds 0.019509553909301758\n",
      "Epoch 925: Train_loss 31260344320.0, Validation_loss 28770131968.0, Seconds 0.017998456954956055\n",
      "Epoch 926: Train_loss 31260434432.0, Validation_loss 28770371584.0, Seconds 0.024001598358154297\n",
      "Epoch 927: Train_loss 31260364800.0, Validation_loss 28770338816.0, Seconds 0.01800084114074707\n",
      "Epoch 928: Train_loss 31260143616.0, Validation_loss 28770148352.0, Seconds 0.017010211944580078\n",
      "Epoch 929: Train_loss 31260055552.0, Validation_loss 28770041856.0, Seconds 0.018518447875976562\n",
      "Epoch 930: Train_loss 31259877376.0, Validation_loss 28770289664.0, Seconds 0.01800060272216797\n",
      "Epoch 931: Train_loss 31259850752.0, Validation_loss 28770252800.0, Seconds 0.016999006271362305\n",
      "Epoch 932: Train_loss 31259746304.0, Validation_loss 28770250752.0, Seconds 0.021000146865844727\n",
      "Epoch 933: Train_loss 31259631616.0, Validation_loss 28770207744.0, Seconds 0.023006916046142578\n",
      "Epoch 934: Train_loss 31259719680.0, Validation_loss 28770191360.0, Seconds 0.02250528335571289\n",
      "Epoch 935: Train_loss 31259383808.0, Validation_loss 28770256896.0, Seconds 0.022006988525390625\n",
      "Epoch 936: Train_loss 31259269120.0, Validation_loss 28770301952.0, Seconds 0.022002458572387695\n",
      "Epoch 937: Train_loss 31259525120.0, Validation_loss 28770447360.0, Seconds 0.021992206573486328\n",
      "Epoch 938: Train_loss 31258890240.0, Validation_loss 28770240512.0, Seconds 0.024516820907592773\n",
      "Epoch 939: Train_loss 31258992640.0, Validation_loss 28770148352.0, Seconds 0.02300262451171875\n",
      "Epoch 940: Train_loss 31259140096.0, Validation_loss 28770676736.0, Seconds 0.018991708755493164\n",
      "Epoch 941: Train_loss 31259146240.0, Validation_loss 28770664448.0, Seconds 0.018000364303588867\n",
      "Epoch 942: Train_loss 31258826752.0, Validation_loss 28770621440.0, Seconds 0.023001670837402344\n",
      "Epoch 943: Train_loss 31258918912.0, Validation_loss 28770664448.0, Seconds 0.020510435104370117\n",
      "Epoch 944: Train_loss 31258451968.0, Validation_loss 28770611200.0, Seconds 0.017998456954956055\n",
      "Epoch 945: Train_loss 31258462208.0, Validation_loss 28770617344.0, Seconds 0.018001317977905273\n",
      "Epoch 946: Train_loss 31258398720.0, Validation_loss 28770631680.0, Seconds 0.02099919319152832\n",
      "Epoch 947: Train_loss 31257675776.0, Validation_loss 28770258944.0, Seconds 0.021000385284423828\n",
      "Epoch 948: Train_loss 31258079232.0, Validation_loss 28770250752.0, Seconds 0.022548437118530273\n",
      "Epoch 949: Train_loss 31257839616.0, Validation_loss 28770533376.0, Seconds 0.022993087768554688\n",
      "Epoch 950: Train_loss 31258195968.0, Validation_loss 28770828288.0, Seconds 0.020999431610107422\n",
      "Epoch 951: Train_loss 31258087424.0, Validation_loss 28771072000.0, Seconds 0.02300119400024414\n",
      "Epoch 952: Train_loss 31257919488.0, Validation_loss 28770742272.0, Seconds 0.02300405502319336\n",
      "Epoch 953: Train_loss 31257427968.0, Validation_loss 28770605056.0, Seconds 0.02251148223876953\n",
      "Epoch 954: Train_loss 31256989696.0, Validation_loss 28770355200.0, Seconds 0.020997047424316406\n",
      "Epoch 955: Train_loss 31257237504.0, Validation_loss 28770291712.0, Seconds 0.022001028060913086\n",
      "Epoch 956: Train_loss 31256989696.0, Validation_loss 28770549760.0, Seconds 0.020000219345092773\n",
      "Epoch 957: Train_loss 31257409536.0, Validation_loss 28770670592.0, Seconds 0.02350926399230957\n",
      "Epoch 958: Train_loss 31257264128.0, Validation_loss 28770811904.0, Seconds 0.01900768280029297\n",
      "Epoch 959: Train_loss 31256901632.0, Validation_loss 28770512896.0, Seconds 0.019994020462036133\n",
      "Epoch 960: Train_loss 31256737792.0, Validation_loss 28770367488.0, Seconds 0.022000789642333984\n",
      "Epoch 961: Train_loss 31256729600.0, Validation_loss 28770443264.0, Seconds 0.022006750106811523\n",
      "Epoch 962: Train_loss 31256385536.0, Validation_loss 28770416640.0, Seconds 0.0175168514251709\n",
      "Epoch 963: Train_loss 31256078336.0, Validation_loss 28770197504.0, Seconds 0.018000364303588867\n",
      "Epoch 964: Train_loss 31256078336.0, Validation_loss 28770095104.0, Seconds 0.01800084114074707\n",
      "Epoch 965: Train_loss 31256279040.0, Validation_loss 28770289664.0, Seconds 0.017999887466430664\n",
      "Epoch 966: Train_loss 31256467456.0, Validation_loss 28770506752.0, Seconds 0.01799917221069336\n",
      "Epoch 967: Train_loss 31256180736.0, Validation_loss 28770408448.0, Seconds 0.017005443572998047\n",
      "Epoch 968: Train_loss 31255769088.0, Validation_loss 28770283520.0, Seconds 0.018511533737182617\n",
      "Epoch 969: Train_loss 31255721984.0, Validation_loss 28770588672.0, Seconds 0.017998933792114258\n",
      "Epoch 970: Train_loss 31255588864.0, Validation_loss 28770605056.0, Seconds 0.018999099731445312\n",
      "Epoch 971: Train_loss 31255177216.0, Validation_loss 28770375680.0, Seconds 0.018001079559326172\n",
      "Epoch 972: Train_loss 31255443456.0, Validation_loss 28770181120.0, Seconds 0.022003889083862305\n",
      "Epoch 973: Train_loss 31255101440.0, Validation_loss 28770187264.0, Seconds 0.021509647369384766\n",
      "Epoch 974: Train_loss 31255384064.0, Validation_loss 28770441216.0, Seconds 0.022002458572387695\n",
      "Epoch 975: Train_loss 31255394304.0, Validation_loss 28770627584.0, Seconds 0.019000530242919922\n",
      "Epoch 976: Train_loss 31254833152.0, Validation_loss 28770258944.0, Seconds 0.016997814178466797\n",
      "Epoch 977: Train_loss 31254982656.0, Validation_loss 28770019328.0, Seconds 0.02100205421447754\n",
      "Epoch 978: Train_loss 31254063104.0, Validation_loss 28769933312.0, Seconds 0.017505168914794922\n",
      "Epoch 979: Train_loss 31254501376.0, Validation_loss 28769865728.0, Seconds 0.022005558013916016\n",
      "Epoch 980: Train_loss 31254497280.0, Validation_loss 28770105344.0, Seconds 0.019002437591552734\n",
      "Epoch 981: Train_loss 31254540288.0, Validation_loss 28770039808.0, Seconds 0.02199411392211914\n",
      "Epoch 982: Train_loss 31254566912.0, Validation_loss 28770213888.0, Seconds 0.020009756088256836\n",
      "Epoch 983: Train_loss 31254202368.0, Validation_loss 28770078720.0, Seconds 0.019506216049194336\n",
      "Epoch 984: Train_loss 31253868544.0, Validation_loss 28769718272.0, Seconds 0.02099776268005371\n",
      "Epoch 985: Train_loss 31253428224.0, Validation_loss 28769542144.0, Seconds 0.021001577377319336\n",
      "Epoch 986: Train_loss 31253504000.0, Validation_loss 28769562624.0, Seconds 0.021000146865844727\n",
      "Epoch 987: Train_loss 31253774336.0, Validation_loss 28769816576.0, Seconds 0.020006895065307617\n",
      "Epoch 988: Train_loss 31253835776.0, Validation_loss 28769916928.0, Seconds 0.018514394760131836\n",
      "Epoch 989: Train_loss 31253731328.0, Validation_loss 28769779712.0, Seconds 0.019994497299194336\n",
      "Epoch 990: Train_loss 31253264384.0, Validation_loss 28769579008.0, Seconds 0.02100372314453125\n",
      "Epoch 991: Train_loss 31253141504.0, Validation_loss 28769523712.0, Seconds 0.02199697494506836\n",
      "Epoch 992: Train_loss 31252516864.0, Validation_loss 28769474560.0, Seconds 0.0220034122467041\n",
      "Epoch 993: Train_loss 31252779008.0, Validation_loss 28769409024.0, Seconds 0.023507118225097656\n",
      "Epoch 994: Train_loss 31252989952.0, Validation_loss 28769605632.0, Seconds 0.02200627326965332\n",
      "Epoch 995: Train_loss 31253129216.0, Validation_loss 28769562624.0, Seconds 0.019994020462036133\n",
      "Epoch 996: Train_loss 31252719616.0, Validation_loss 28769677312.0, Seconds 0.021000385284423828\n",
      "Epoch 997: Train_loss 31252584448.0, Validation_loss 28769566720.0, Seconds 0.02550792694091797\n",
      "Epoch 998: Train_loss 31252252672.0, Validation_loss 28769492992.0, Seconds 0.02000737190246582\n",
      "Epoch 999: Train_loss 31251867648.0, Validation_loss 28769175552.0, Seconds 0.022996187210083008\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).view(-1, 1)\n",
    "        output = net(data)\n",
    "        L = loss(output, target)\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    y_train_pred = net(X_train)\n",
    "    training_loss = loss(y_train_pred, y_train.view(-1, 1)).item()\n",
    "    y_test_pred = net(X_test)\n",
    "    test_loss = loss(y_test_pred, y_test.view(-1, 1)).item()\n",
    "    \n",
    "    train_losses.append(training_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Epoch {}: Train_loss {}, Validation_loss {}, Seconds {}\".format(epoch, training_loss, test_loss, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27467cfb510>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(test_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss values\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = net(X_train)\n",
    "y_test_pred = net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.10e+05\n",
      "train MSE: 3.13e+10\n",
      "train R2: 0.353\n"
     ]
    }
   ],
   "source": [
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred.detach().numpy())))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred.detach().numpy())))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 1.12e+05\n",
      "test MSE: 2.88e+10\n",
      "test R2: 0.424\n"
     ]
    }
   ],
   "source": [
    "print('test MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred.detach().numpy())))\n",
    "print('test MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred.detach().numpy())))\n",
    "print('test R2: {0:.3f}'.format(r2_score(y_test, y_test_pred.detach().numpy())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
