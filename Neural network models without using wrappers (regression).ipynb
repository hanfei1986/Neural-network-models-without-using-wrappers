{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2.csv')\n",
    "df.dropna(subset=['price'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "target = 'price'\n",
    "features.remove(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target].str.strip(\"$\").str.replace(\",\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "class Data_Transformer(object):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        self.mean_weight = new_df[\"Weight\"].mean() # obtain mean weight\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase weekday\n",
    "        self.majority_month = new_df[\"Month\"].mode()[0] # obtain majority purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        self.majority_weekday = new_df[\"Weekday\"].mode()[0] # obtain majority purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df[\"Ingredient Number\"] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        self.mean_ingredient_number = new_df[\"Ingredient Number\"].mean() # obtain mean ingredient number\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with median ingredient number\n",
    "        self.pl_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Level\"] = pd.Series(self.pl_le.fit_transform(X[\"product_level\"])) # fit and transform product level with label-encoder\n",
    "        self.majority_product_level = new_df[\"Product Level\"].mode()[0] # obtain majority product level code\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        self.pt_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Type\"] = pd.Series(self.pt_le.fit_transform(X[\"product_type\"])) # fit and transform product type with label-encoder\n",
    "        self.majority_product_type = new_df[\"Product Type\"].mode()[0] # obtain majority product type code\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        self.cost_imputer = XGBRegressor() # create a XGBoost imputer for cost\n",
    "        df_for_imputing_cost = new_df.dropna() # create training data for cost imputer by dropping missing data\n",
    "        self.cost_imputer.fit(df_for_imputing_cost[[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]], df_for_imputing_cost[\"Cost\"]) # fit cost imputer\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df['Ingredient Number'] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with mean ingredient number\n",
    "        new_df[\"Product Level\"] = self.pl_le.transform(X[\"product_level\"]) # transform product level with label-encoder\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        new_df[\"Product Type\"] = self.pt_le.transform(X[\"product_type\"]) # transform product type with label-encoder\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        imputed_cost = pd.Series(self.cost_imputer.predict(new_df[new_df[\"Cost\"].isnull()][[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]])) # obtain imputed cost\n",
    "        imputed_cost.index = new_df[new_df[\"Cost\"].isnull()][\"Cost\"].index # set index of imputed cost\n",
    "        new_df[\"Cost\"].fillna(imputed_cost,inplace=True) # fill in missing cost with imputed cost\n",
    "        return new_df # return new_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def weight2num(self, x): # function to convert weight to number\n",
    "        if type(x) == str:\n",
    "            x = x.strip('Kg').split(' Ton ')\n",
    "            return float(x[0])*1000+float(x[1])\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def get_numbers(self, x): # function to get number of ingredients in recipe\n",
    "        if type(x) == str:\n",
    "            return len(x.split(','))\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = Data_Transformer()\n",
    "X_train = np.array(dft.fit_transform(X_train))\n",
    "X_test = np.array(dft.transform(X_test))\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = nn.Sequential(nn.Linear(7, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "batch_size = 500\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSELoss(reduction='mean')\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train_loss 83174440960.0, Validation_loss 79925362688.0, Seconds 0.03100895881652832\n",
      "Epoch 1: Train_loss 82815746048.0, Validation_loss 79580372992.0, Seconds 0.027512550354003906\n",
      "Epoch 2: Train_loss 82455093248.0, Validation_loss 79233458176.0, Seconds 0.02200484275817871\n",
      "Epoch 3: Train_loss 82082308096.0, Validation_loss 78874845184.0, Seconds 0.09351611137390137\n",
      "Epoch 4: Train_loss 81695694848.0, Validation_loss 78502912000.0, Seconds 0.0229949951171875\n",
      "Epoch 5: Train_loss 81300054016.0, Validation_loss 78122254336.0, Seconds 0.023994922637939453\n",
      "Epoch 6: Train_loss 80897671168.0, Validation_loss 77735051264.0, Seconds 0.023712635040283203\n",
      "Epoch 7: Train_loss 80480993280.0, Validation_loss 77334069248.0, Seconds 0.02092289924621582\n",
      "Epoch 8: Train_loss 80029548544.0, Validation_loss 76899549184.0, Seconds 0.017998695373535156\n",
      "Epoch 9: Train_loss 79575736320.0, Validation_loss 76462710784.0, Seconds 0.017006635665893555\n",
      "Epoch 10: Train_loss 79117574144.0, Validation_loss 76021612544.0, Seconds 0.01899409294128418\n",
      "Epoch 11: Train_loss 78650327040.0, Validation_loss 75571806208.0, Seconds 0.01800394058227539\n",
      "Epoch 12: Train_loss 78233714688.0, Validation_loss 75170562048.0, Seconds 0.01753520965576172\n",
      "Epoch 13: Train_loss 77826506752.0, Validation_loss 74778345472.0, Seconds 0.022998332977294922\n",
      "Epoch 14: Train_loss 77311877120.0, Validation_loss 74282647552.0, Seconds 0.02299952507019043\n",
      "Epoch 15: Train_loss 76719235072.0, Validation_loss 73711665152.0, Seconds 0.022001028060913086\n",
      "Epoch 16: Train_loss 76086304768.0, Validation_loss 73101729792.0, Seconds 0.020515918731689453\n",
      "Epoch 17: Train_loss 75423940608.0, Validation_loss 72463294464.0, Seconds 0.019004344940185547\n",
      "Epoch 18: Train_loss 74743504896.0, Validation_loss 71807246336.0, Seconds 0.02000117301940918\n",
      "Epoch 19: Train_loss 74051059712.0, Validation_loss 71139467264.0, Seconds 0.01799798011779785\n",
      "Epoch 20: Train_loss 73335808000.0, Validation_loss 70449528832.0, Seconds 0.01900029182434082\n",
      "Epoch 21: Train_loss 72575377408.0, Validation_loss 69715836928.0, Seconds 0.023018598556518555\n",
      "Epoch 22: Train_loss 71745683456.0, Validation_loss 68915060736.0, Seconds 0.021518945693969727\n",
      "Epoch 23: Train_loss 70875398144.0, Validation_loss 68074827776.0, Seconds 0.021990537643432617\n",
      "Epoch 24: Train_loss 69953552384.0, Validation_loss 67184467968.0, Seconds 0.01900172233581543\n",
      "Epoch 25: Train_loss 68899061760.0, Validation_loss 66165547008.0, Seconds 0.017998695373535156\n",
      "Epoch 26: Train_loss 67760160768.0, Validation_loss 65064574976.0, Seconds 0.01700448989868164\n",
      "Epoch 27: Train_loss 66563117056.0, Validation_loss 63906738176.0, Seconds 0.018517017364501953\n",
      "Epoch 28: Train_loss 65329676288.0, Validation_loss 62712971264.0, Seconds 0.01899099349975586\n",
      "Epoch 29: Train_loss 64067399680.0, Validation_loss 61490507776.0, Seconds 0.01900649070739746\n",
      "Epoch 30: Train_loss 62766428160.0, Validation_loss 60229713920.0, Seconds 0.021000146865844727\n",
      "Epoch 31: Train_loss 61440667648.0, Validation_loss 58943889408.0, Seconds 0.022997140884399414\n",
      "Epoch 32: Train_loss 60093440000.0, Validation_loss 57636134912.0, Seconds 0.017532825469970703\n",
      "Epoch 33: Train_loss 58716712960.0, Validation_loss 56298536960.0, Seconds 0.01801133155822754\n",
      "Epoch 34: Train_loss 57318502400.0, Validation_loss 54938685440.0, Seconds 0.01799464225769043\n",
      "Epoch 35: Train_loss 55911440384.0, Validation_loss 53568720896.0, Seconds 0.017994403839111328\n",
      "Epoch 36: Train_loss 54499389440.0, Validation_loss 52192219136.0, Seconds 0.020001888275146484\n",
      "Epoch 37: Train_loss 53088727040.0, Validation_loss 50815234048.0, Seconds 0.021509408950805664\n",
      "Epoch 38: Train_loss 51686203392.0, Validation_loss 49444192256.0, Seconds 0.01801443099975586\n",
      "Epoch 39: Train_loss 50298773504.0, Validation_loss 48085688320.0, Seconds 0.020986318588256836\n",
      "Epoch 40: Train_loss 48933494784.0, Validation_loss 46746492928.0, Seconds 0.020998716354370117\n",
      "Epoch 41: Train_loss 47597502464.0, Validation_loss 45433409536.0, Seconds 0.022005319595336914\n",
      "Epoch 42: Train_loss 46297845760.0, Validation_loss 44153245696.0, Seconds 0.01853489875793457\n",
      "Epoch 43: Train_loss 45041430528.0, Validation_loss 42912632832.0, Seconds 0.017998218536376953\n",
      "Epoch 44: Train_loss 43834806272.0, Validation_loss 41717927936.0, Seconds 0.021000146865844727\n",
      "Epoch 45: Train_loss 42684080128.0, Validation_loss 40575090688.0, Seconds 0.019998550415039062\n",
      "Epoch 46: Train_loss 41594777600.0, Validation_loss 39489548288.0, Seconds 0.018006086349487305\n",
      "Epoch 47: Train_loss 40571654144.0, Validation_loss 38466043904.0, Seconds 0.018519163131713867\n",
      "Epoch 48: Train_loss 39610929152.0, Validation_loss 37500846080.0, Seconds 0.020998239517211914\n",
      "Epoch 49: Train_loss 38691946496.0, Validation_loss 36572909568.0, Seconds 0.02099752426147461\n",
      "Epoch 50: Train_loss 37842386944.0, Validation_loss 35710013440.0, Seconds 0.018999576568603516\n",
      "Epoch 51: Train_loss 37066215424.0, Validation_loss 34916192256.0, Seconds 0.02200150489807129\n",
      "Epoch 52: Train_loss 36355022848.0, Validation_loss 34183032832.0, Seconds 0.02550673484802246\n",
      "Epoch 53: Train_loss 35725115392.0, Validation_loss 33527642112.0, Seconds 0.023998260498046875\n",
      "Epoch 54: Train_loss 35178627072.0, Validation_loss 32952950784.0, Seconds 0.022005319595336914\n",
      "Epoch 55: Train_loss 34713227264.0, Validation_loss 32457342976.0, Seconds 0.021994829177856445\n",
      "Epoch 56: Train_loss 34323935232.0, Validation_loss 32036399104.0, Seconds 0.019540071487426758\n",
      "Epoch 57: Train_loss 34003662848.0, Validation_loss 31683973120.0, Seconds 0.019991397857666016\n",
      "Epoch 58: Train_loss 33740726272.0, Validation_loss 31388577792.0, Seconds 0.022000551223754883\n",
      "Epoch 59: Train_loss 33526501376.0, Validation_loss 31140997120.0, Seconds 0.02200031280517578\n",
      "Epoch 60: Train_loss 33360605184.0, Validation_loss 30943027200.0, Seconds 0.02200484275817871\n",
      "Epoch 61: Train_loss 33236244480.0, Validation_loss 30788808704.0, Seconds 0.01828789710998535\n",
      "Epoch 62: Train_loss 33144956928.0, Validation_loss 30670555136.0, Seconds 0.017999887466430664\n",
      "Epoch 63: Train_loss 33078171648.0, Validation_loss 30579126272.0, Seconds 0.017000675201416016\n",
      "Epoch 64: Train_loss 33031790592.0, Validation_loss 30511425536.0, Seconds 0.017998695373535156\n",
      "Epoch 65: Train_loss 33000448000.0, Validation_loss 30462261248.0, Seconds 0.018001556396484375\n",
      "Epoch 66: Train_loss 32979693568.0, Validation_loss 30427099136.0, Seconds 0.018004894256591797\n",
      "Epoch 67: Train_loss 32966123520.0, Validation_loss 30402238464.0, Seconds 0.020663976669311523\n",
      "Epoch 68: Train_loss 32957306880.0, Validation_loss 30384846848.0, Seconds 0.019999265670776367\n",
      "Epoch 69: Train_loss 32951562240.0, Validation_loss 30372792320.0, Seconds 0.019001483917236328\n",
      "Epoch 70: Train_loss 32947806208.0, Validation_loss 30364526592.0, Seconds 0.08558917045593262\n",
      "Epoch 71: Train_loss 32945313792.0, Validation_loss 30358925312.0, Seconds 0.021999835968017578\n",
      "Epoch 72: Train_loss 32943652864.0, Validation_loss 30355200000.0, Seconds 0.019998788833618164\n",
      "Epoch 73: Train_loss 32942518272.0, Validation_loss 30352764928.0, Seconds 0.019508838653564453\n",
      "Epoch 74: Train_loss 32941731840.0, Validation_loss 30351218688.0, Seconds 0.01699972152709961\n",
      "Epoch 75: Train_loss 32941148160.0, Validation_loss 30350245888.0, Seconds 0.021000146865844727\n",
      "Epoch 76: Train_loss 32940443648.0, Validation_loss 30349381632.0, Seconds 0.017006874084472656\n",
      "Epoch 77: Train_loss 32939483136.0, Validation_loss 30347896832.0, Seconds 0.01699352264404297\n",
      "Epoch 78: Train_loss 32939202560.0, Validation_loss 30347755520.0, Seconds 0.022002696990966797\n",
      "Epoch 79: Train_loss 32938989568.0, Validation_loss 30347790336.0, Seconds 0.018512487411499023\n",
      "Epoch 80: Train_loss 32938741760.0, Validation_loss 30347821056.0, Seconds 0.020000457763671875\n",
      "Epoch 81: Train_loss 32938369024.0, Validation_loss 30347689984.0, Seconds 0.017993688583374023\n",
      "Epoch 82: Train_loss 32938379264.0, Validation_loss 30347982848.0, Seconds 0.01900172233581543\n",
      "Epoch 83: Train_loss 32938166272.0, Validation_loss 30347978752.0, Seconds 0.020000934600830078\n",
      "Epoch 84: Train_loss 32937916416.0, Validation_loss 30347892736.0, Seconds 0.020508527755737305\n",
      "Epoch 85: Train_loss 32937625600.0, Validation_loss 30347749376.0, Seconds 0.019006729125976562\n",
      "Epoch 86: Train_loss 32937306112.0, Validation_loss 30347540480.0, Seconds 0.017998933792114258\n",
      "Epoch 87: Train_loss 32936953856.0, Validation_loss 30347288576.0, Seconds 0.01799297332763672\n",
      "Epoch 88: Train_loss 32936556544.0, Validation_loss 30346975232.0, Seconds 0.022001981735229492\n",
      "Epoch 89: Train_loss 32936128512.0, Validation_loss 30346616832.0, Seconds 0.022536516189575195\n",
      "Epoch 90: Train_loss 32935632896.0, Validation_loss 30346209280.0, Seconds 0.020000219345092773\n",
      "Epoch 91: Train_loss 32935071744.0, Validation_loss 30345740288.0, Seconds 0.017999887466430664\n",
      "Epoch 92: Train_loss 32934189056.0, Validation_loss 30344931328.0, Seconds 0.018004655838012695\n",
      "Epoch 93: Train_loss 32933586944.0, Validation_loss 30344570880.0, Seconds 0.020997047424316406\n",
      "Epoch 94: Train_loss 32933240832.0, Validation_loss 30344278016.0, Seconds 0.02252340316772461\n",
      "Epoch 95: Train_loss 32932704256.0, Validation_loss 30343882752.0, Seconds 0.02099156379699707\n",
      "Epoch 96: Train_loss 32932341760.0, Validation_loss 30343636992.0, Seconds 0.02799367904663086\n",
      "Epoch 97: Train_loss 32931643392.0, Validation_loss 30343196672.0, Seconds 0.022999286651611328\n",
      "Epoch 98: Train_loss 32931264512.0, Validation_loss 30343008256.0, Seconds 0.017506837844848633\n",
      "Epoch 99: Train_loss 32930494464.0, Validation_loss 30342486016.0, Seconds 0.021001577377319336\n",
      "Epoch 100: Train_loss 32929751040.0, Validation_loss 30341582848.0, Seconds 0.022073984146118164\n",
      "Epoch 101: Train_loss 32929042432.0, Validation_loss 30340931584.0, Seconds 0.018924474716186523\n",
      "Epoch 102: Train_loss 32928315392.0, Validation_loss 30340345856.0, Seconds 0.021001338958740234\n",
      "Epoch 103: Train_loss 32927492096.0, Validation_loss 30339741696.0, Seconds 0.018744707107543945\n",
      "Epoch 104: Train_loss 32926504960.0, Validation_loss 30338840576.0, Seconds 0.017924785614013672\n",
      "Epoch 105: Train_loss 32925292544.0, Validation_loss 30337660928.0, Seconds 0.018001556396484375\n",
      "Epoch 106: Train_loss 32923856896.0, Validation_loss 30336057344.0, Seconds 0.025996923446655273\n",
      "Epoch 107: Train_loss 32921942016.0, Validation_loss 30334015488.0, Seconds 0.0220029354095459\n",
      "Epoch 108: Train_loss 32919492608.0, Validation_loss 30331815936.0, Seconds 0.021591663360595703\n",
      "Epoch 109: Train_loss 32916989952.0, Validation_loss 30329886720.0, Seconds 0.01800251007080078\n",
      "Epoch 110: Train_loss 32915568640.0, Validation_loss 30329241600.0, Seconds 0.01899862289428711\n",
      "Epoch 111: Train_loss 32914866176.0, Validation_loss 30329141248.0, Seconds 0.017079830169677734\n",
      "Epoch 112: Train_loss 32914221056.0, Validation_loss 30329311232.0, Seconds 0.016926050186157227\n",
      "Epoch 113: Train_loss 32913672192.0, Validation_loss 30329083904.0, Seconds 0.017014503479003906\n",
      "Epoch 114: Train_loss 32913158144.0, Validation_loss 30328709120.0, Seconds 0.019507646560668945\n",
      "Epoch 115: Train_loss 32912578560.0, Validation_loss 30328518656.0, Seconds 0.021001338958740234\n",
      "Epoch 116: Train_loss 32911843328.0, Validation_loss 30328092672.0, Seconds 0.0190732479095459\n",
      "Epoch 117: Train_loss 32911407104.0, Validation_loss 30327826432.0, Seconds 0.0219268798828125\n",
      "Epoch 118: Train_loss 32910854144.0, Validation_loss 30327277568.0, Seconds 0.020002126693725586\n",
      "Epoch 119: Train_loss 32910090240.0, Validation_loss 30326691840.0, Seconds 0.018505573272705078\n",
      "Epoch 120: Train_loss 32909168640.0, Validation_loss 30326132736.0, Seconds 0.019001245498657227\n",
      "Epoch 121: Train_loss 32908466176.0, Validation_loss 30325280768.0, Seconds 0.022003650665283203\n",
      "Epoch 122: Train_loss 32907261952.0, Validation_loss 30324025344.0, Seconds 0.021995067596435547\n",
      "Epoch 123: Train_loss 32906172416.0, Validation_loss 30322595840.0, Seconds 0.020499229431152344\n",
      "Epoch 124: Train_loss 32905388032.0, Validation_loss 30321987584.0, Seconds 0.024001121520996094\n",
      "Epoch 125: Train_loss 32904271872.0, Validation_loss 30320619520.0, Seconds 0.019000768661499023\n",
      "Epoch 126: Train_loss 32903360512.0, Validation_loss 30320078848.0, Seconds 0.021998167037963867\n",
      "Epoch 127: Train_loss 32902473728.0, Validation_loss 30319462400.0, Seconds 0.021002531051635742\n",
      "Epoch 128: Train_loss 32901470208.0, Validation_loss 30318678016.0, Seconds 0.0265347957611084\n",
      "Epoch 129: Train_loss 32900093952.0, Validation_loss 30317592576.0, Seconds 0.023006439208984375\n",
      "Epoch 130: Train_loss 32898236416.0, Validation_loss 30315900928.0, Seconds 0.02199244499206543\n",
      "Epoch 131: Train_loss 32895672320.0, Validation_loss 30313887744.0, Seconds 0.023001432418823242\n",
      "Epoch 132: Train_loss 32893927424.0, Validation_loss 30312994816.0, Seconds 0.021513938903808594\n",
      "Epoch 133: Train_loss 32893081600.0, Validation_loss 30312747008.0, Seconds 0.01799941062927246\n",
      "Epoch 134: Train_loss 32892315648.0, Validation_loss 30312513536.0, Seconds 0.019999027252197266\n",
      "Epoch 135: Train_loss 32891570176.0, Validation_loss 30311929856.0, Seconds 0.021003246307373047\n",
      "Epoch 136: Train_loss 32890793984.0, Validation_loss 30311550976.0, Seconds 0.022005319595336914\n",
      "Epoch 137: Train_loss 32889999360.0, Validation_loss 30311231488.0, Seconds 0.023135662078857422\n",
      "Epoch 138: Train_loss 32889260032.0, Validation_loss 30310492160.0, Seconds 0.01999807357788086\n",
      "Epoch 139: Train_loss 32888436736.0, Validation_loss 30310049792.0, Seconds 0.02400040626525879\n",
      "Epoch 140: Train_loss 32887678976.0, Validation_loss 30309339136.0, Seconds 0.02500295639038086\n",
      "Epoch 141: Train_loss 32886853632.0, Validation_loss 30308759552.0, Seconds 0.019011259078979492\n",
      "Epoch 142: Train_loss 32886063104.0, Validation_loss 30308079616.0, Seconds 0.017539024353027344\n",
      "Epoch 143: Train_loss 32885235712.0, Validation_loss 30307686400.0, Seconds 0.01899266242980957\n",
      "Epoch 144: Train_loss 32884482048.0, Validation_loss 30306998272.0, Seconds 0.01699972152709961\n",
      "Epoch 145: Train_loss 32883666944.0, Validation_loss 30306437120.0, Seconds 0.02300119400024414\n",
      "Epoch 146: Train_loss 32882944000.0, Validation_loss 30305894400.0, Seconds 0.019005537033081055\n",
      "Epoch 147: Train_loss 32882155520.0, Validation_loss 30305214464.0, Seconds 0.022503137588500977\n",
      "Epoch 148: Train_loss 32881375232.0, Validation_loss 30304694272.0, Seconds 0.017999887466430664\n",
      "Epoch 149: Train_loss 32880568320.0, Validation_loss 30303993856.0, Seconds 0.017999887466430664\n",
      "Epoch 150: Train_loss 32879826944.0, Validation_loss 30303102976.0, Seconds 0.01699995994567871\n",
      "Epoch 151: Train_loss 32878927872.0, Validation_loss 30302543872.0, Seconds 0.01900625228881836\n",
      "Epoch 152: Train_loss 32878086144.0, Validation_loss 30301825024.0, Seconds 0.020509958267211914\n",
      "Epoch 153: Train_loss 32877289472.0, Validation_loss 30300938240.0, Seconds 0.019001245498657227\n",
      "Epoch 154: Train_loss 32876427264.0, Validation_loss 30300391424.0, Seconds 0.02200484275817871\n",
      "Epoch 155: Train_loss 32875653120.0, Validation_loss 30299658240.0, Seconds 0.022993087768554688\n",
      "Epoch 156: Train_loss 32874815488.0, Validation_loss 30299199488.0, Seconds 0.022004127502441406\n",
      "Epoch 157: Train_loss 32874086400.0, Validation_loss 30298337280.0, Seconds 0.019524812698364258\n",
      "Epoch 158: Train_loss 32873318400.0, Validation_loss 30297853952.0, Seconds 0.020000219345092773\n",
      "Epoch 159: Train_loss 32872423424.0, Validation_loss 30297180160.0, Seconds 0.01899886131286621\n",
      "Epoch 160: Train_loss 32871583744.0, Validation_loss 30296479744.0, Seconds 0.017000436782836914\n",
      "Epoch 161: Train_loss 32870678528.0, Validation_loss 30295511040.0, Seconds 0.02000284194946289\n",
      "Epoch 162: Train_loss 32869654528.0, Validation_loss 30294843392.0, Seconds 0.0245358943939209\n",
      "Epoch 163: Train_loss 32868409344.0, Validation_loss 30293794816.0, Seconds 0.019001007080078125\n",
      "Epoch 164: Train_loss 32866142208.0, Validation_loss 30291535872.0, Seconds 0.020998239517211914\n",
      "Epoch 165: Train_loss 32865085440.0, Validation_loss 30290984960.0, Seconds 0.019001245498657227\n",
      "Epoch 166: Train_loss 32864288768.0, Validation_loss 30290388992.0, Seconds 0.017020463943481445\n",
      "Epoch 167: Train_loss 32863287296.0, Validation_loss 30289485824.0, Seconds 0.02250194549560547\n",
      "Epoch 168: Train_loss 32862291968.0, Validation_loss 30288861184.0, Seconds 0.022999286651611328\n",
      "Epoch 169: Train_loss 32861462528.0, Validation_loss 30288197632.0, Seconds 0.01799917221069336\n",
      "Epoch 170: Train_loss 32860508160.0, Validation_loss 30287454208.0, Seconds 0.021001815795898438\n",
      "Epoch 171: Train_loss 32859547648.0, Validation_loss 30286721024.0, Seconds 0.0240020751953125\n",
      "Epoch 172: Train_loss 32858576896.0, Validation_loss 30285905920.0, Seconds 0.01950812339782715\n",
      "Epoch 173: Train_loss 32857634816.0, Validation_loss 30285221888.0, Seconds 0.017999887466430664\n",
      "Epoch 174: Train_loss 32856709120.0, Validation_loss 30284423168.0, Seconds 0.017001867294311523\n",
      "Epoch 175: Train_loss 32855764992.0, Validation_loss 30283753472.0, Seconds 0.020998716354370117\n",
      "Epoch 176: Train_loss 32854816768.0, Validation_loss 30282936320.0, Seconds 0.024020910263061523\n",
      "Epoch 177: Train_loss 32853868544.0, Validation_loss 30282262528.0, Seconds 0.022519350051879883\n",
      "Epoch 178: Train_loss 32852942848.0, Validation_loss 30281553920.0, Seconds 0.022075414657592773\n",
      "Epoch 179: Train_loss 32852006912.0, Validation_loss 30280833024.0, Seconds 0.027925968170166016\n",
      "Epoch 180: Train_loss 32851073024.0, Validation_loss 30279874560.0, Seconds 0.019001483917236328\n",
      "Epoch 181: Train_loss 32850120704.0, Validation_loss 30279159808.0, Seconds 0.023667335510253906\n",
      "Epoch 182: Train_loss 32849170432.0, Validation_loss 30278533120.0, Seconds 0.020999908447265625\n",
      "Epoch 183: Train_loss 32848228352.0, Validation_loss 30277752832.0, Seconds 0.019999980926513672\n",
      "Epoch 184: Train_loss 32847269888.0, Validation_loss 30277017600.0, Seconds 0.01900029182434082\n",
      "Epoch 185: Train_loss 32846325760.0, Validation_loss 30276261888.0, Seconds 0.02108478546142578\n",
      "Epoch 186: Train_loss 32845373440.0, Validation_loss 30275665920.0, Seconds 0.02050328254699707\n",
      "Epoch 187: Train_loss 32844429312.0, Validation_loss 30274867200.0, Seconds 0.018007278442382812\n",
      "Epoch 188: Train_loss 32843481088.0, Validation_loss 30274029568.0, Seconds 0.019992589950561523\n",
      "Epoch 189: Train_loss 32842522624.0, Validation_loss 30273404928.0, Seconds 0.022007226943969727\n",
      "Epoch 190: Train_loss 32841568256.0, Validation_loss 30272677888.0, Seconds 0.018999099731445312\n",
      "Epoch 191: Train_loss 32840609792.0, Validation_loss 30271909888.0, Seconds 0.023502826690673828\n",
      "Epoch 192: Train_loss 32839651328.0, Validation_loss 30271041536.0, Seconds 0.02200627326965332\n",
      "Epoch 193: Train_loss 32838670336.0, Validation_loss 30270496768.0, Seconds 0.021993398666381836\n",
      "Epoch 194: Train_loss 32837713920.0, Validation_loss 30269679616.0, Seconds 0.022000789642333984\n",
      "Epoch 195: Train_loss 32836757504.0, Validation_loss 30268895232.0, Seconds 0.019524574279785156\n",
      "Epoch 196: Train_loss 32835776512.0, Validation_loss 30267983872.0, Seconds 0.021007776260375977\n",
      "Epoch 197: Train_loss 32834768896.0, Validation_loss 30267402240.0, Seconds 0.018999814987182617\n",
      "Epoch 198: Train_loss 32833804288.0, Validation_loss 30266652672.0, Seconds 0.01905202865600586\n",
      "Epoch 199: Train_loss 32832831488.0, Validation_loss 30265827328.0, Seconds 0.020941972732543945\n",
      "Epoch 200: Train_loss 32831846400.0, Validation_loss 30265065472.0, Seconds 0.021507978439331055\n",
      "Epoch 201: Train_loss 32830816256.0, Validation_loss 30264162304.0, Seconds 0.019999980926513672\n",
      "Epoch 202: Train_loss 32829792256.0, Validation_loss 30263201792.0, Seconds 0.09150886535644531\n",
      "Epoch 203: Train_loss 32828764160.0, Validation_loss 30262480896.0, Seconds 0.017075777053833008\n",
      "Epoch 204: Train_loss 32827738112.0, Validation_loss 30261663744.0, Seconds 0.02093219757080078\n",
      "Epoch 205: Train_loss 32826697728.0, Validation_loss 30260848640.0, Seconds 0.017992258071899414\n",
      "Epoch 206: Train_loss 32825716736.0, Validation_loss 30260224000.0, Seconds 0.02700519561767578\n",
      "Epoch 207: Train_loss 32824719360.0, Validation_loss 30259187712.0, Seconds 0.018505573272705078\n",
      "Epoch 208: Train_loss 32823654400.0, Validation_loss 30258323456.0, Seconds 0.021000146865844727\n",
      "Epoch 209: Train_loss 32822624256.0, Validation_loss 30257623040.0, Seconds 0.0260012149810791\n",
      "Epoch 210: Train_loss 32821610496.0, Validation_loss 30256683008.0, Seconds 0.02314448356628418\n",
      "Epoch 211: Train_loss 32820584448.0, Validation_loss 30255941632.0, Seconds 0.02345728874206543\n",
      "Epoch 212: Train_loss 32819517440.0, Validation_loss 30255269888.0, Seconds 0.01999974250793457\n",
      "Epoch 213: Train_loss 32818515968.0, Validation_loss 30254465024.0, Seconds 0.01799607276916504\n",
      "Epoch 214: Train_loss 32817455104.0, Validation_loss 30253309952.0, Seconds 0.02000260353088379\n",
      "Epoch 215: Train_loss 32816412672.0, Validation_loss 30252531712.0, Seconds 0.020000934600830078\n",
      "Epoch 216: Train_loss 32815411200.0, Validation_loss 30251937792.0, Seconds 0.022511959075927734\n",
      "Epoch 217: Train_loss 32814295040.0, Validation_loss 30251206656.0, Seconds 0.01899886131286621\n",
      "Epoch 218: Train_loss 32813193216.0, Validation_loss 30250194944.0, Seconds 0.019005775451660156\n",
      "Epoch 219: Train_loss 32812087296.0, Validation_loss 30249162752.0, Seconds 0.021989107131958008\n",
      "Epoch 220: Train_loss 32810936320.0, Validation_loss 30248189952.0, Seconds 0.02200460433959961\n",
      "Epoch 221: Train_loss 32809834496.0, Validation_loss 30247473152.0, Seconds 0.019535064697265625\n",
      "Epoch 222: Train_loss 32808679424.0, Validation_loss 30246494208.0, Seconds 0.02199864387512207\n",
      "Epoch 223: Train_loss 32807542784.0, Validation_loss 30245218304.0, Seconds 0.0200808048248291\n",
      "Epoch 224: Train_loss 32806365184.0, Validation_loss 30244087808.0, Seconds 0.01891779899597168\n",
      "Epoch 225: Train_loss 32805156864.0, Validation_loss 30243192832.0, Seconds 0.02408432960510254\n",
      "Epoch 226: Train_loss 32803944448.0, Validation_loss 30242164736.0, Seconds 0.018509387969970703\n",
      "Epoch 227: Train_loss 32802723840.0, Validation_loss 30241093632.0, Seconds 0.021073579788208008\n",
      "Epoch 228: Train_loss 32801495040.0, Validation_loss 30239830016.0, Seconds 0.02292609214782715\n",
      "Epoch 229: Train_loss 32800243712.0, Validation_loss 30238824448.0, Seconds 0.02300429344177246\n",
      "Epoch 230: Train_loss 32798984192.0, Validation_loss 30237894656.0, Seconds 0.0195462703704834\n",
      "Epoch 231: Train_loss 32797679616.0, Validation_loss 30236917760.0, Seconds 0.020992040634155273\n",
      "Epoch 232: Train_loss 32796256256.0, Validation_loss 30235662336.0, Seconds 0.02500772476196289\n",
      "Epoch 233: Train_loss 32794730496.0, Validation_loss 30234091520.0, Seconds 0.02299189567565918\n",
      "Epoch 234: Train_loss 32793036800.0, Validation_loss 30232619008.0, Seconds 0.024005651473999023\n",
      "Epoch 235: Train_loss 32791117824.0, Validation_loss 30231107584.0, Seconds 0.019509315490722656\n",
      "Epoch 236: Train_loss 32788744192.0, Validation_loss 30228785152.0, Seconds 0.01999807357788086\n",
      "Epoch 237: Train_loss 32785623040.0, Validation_loss 30225397760.0, Seconds 0.020081281661987305\n",
      "Epoch 238: Train_loss 32781553664.0, Validation_loss 30221705216.0, Seconds 0.018918514251708984\n",
      "Epoch 239: Train_loss 32779429888.0, Validation_loss 30220689408.0, Seconds 0.022002458572387695\n",
      "Epoch 240: Train_loss 32778307584.0, Validation_loss 30220580864.0, Seconds 0.02050495147705078\n",
      "Epoch 241: Train_loss 32776747008.0, Validation_loss 30219540480.0, Seconds 0.02300238609313965\n",
      "Epoch 242: Train_loss 32775460864.0, Validation_loss 30218080256.0, Seconds 0.023998737335205078\n",
      "Epoch 243: Train_loss 32773994496.0, Validation_loss 30217195520.0, Seconds 0.019999980926513672\n",
      "Epoch 244: Train_loss 32772536320.0, Validation_loss 30216499200.0, Seconds 0.018543004989624023\n",
      "Epoch 245: Train_loss 32771182592.0, Validation_loss 30215462912.0, Seconds 0.020000219345092773\n",
      "Epoch 246: Train_loss 32769767424.0, Validation_loss 30214105088.0, Seconds 0.02099442481994629\n",
      "Epoch 247: Train_loss 32768307200.0, Validation_loss 30213136384.0, Seconds 0.01999807357788086\n",
      "Epoch 248: Train_loss 32766861312.0, Validation_loss 30212087808.0, Seconds 0.01699995994567871\n",
      "Epoch 249: Train_loss 32765454336.0, Validation_loss 30210871296.0, Seconds 0.018011093139648438\n",
      "Epoch 250: Train_loss 32764039168.0, Validation_loss 30209636352.0, Seconds 0.01952195167541504\n",
      "Epoch 251: Train_loss 32762591232.0, Validation_loss 30208630784.0, Seconds 0.0169985294342041\n",
      "Epoch 252: Train_loss 32761167872.0, Validation_loss 30207594496.0, Seconds 0.018999338150024414\n",
      "Epoch 253: Train_loss 32759752704.0, Validation_loss 30206318592.0, Seconds 0.019000768661499023\n",
      "Epoch 254: Train_loss 32758321152.0, Validation_loss 30205007872.0, Seconds 0.019004344940185547\n",
      "Epoch 255: Train_loss 32756889600.0, Validation_loss 30204067840.0, Seconds 0.01850748062133789\n",
      "Epoch 256: Train_loss 32755482624.0, Validation_loss 30203170816.0, Seconds 0.02099895477294922\n",
      "Epoch 257: Train_loss 32754089984.0, Validation_loss 30201890816.0, Seconds 0.021076440811157227\n",
      "Epoch 258: Train_loss 32752668672.0, Validation_loss 30200623104.0, Seconds 0.021957874298095703\n",
      "Epoch 259: Train_loss 32751251456.0, Validation_loss 30199777280.0, Seconds 0.023015737533569336\n",
      "Epoch 260: Train_loss 32749846528.0, Validation_loss 30198528000.0, Seconds 0.020511388778686523\n",
      "Epoch 261: Train_loss 32748388352.0, Validation_loss 30197221376.0, Seconds 0.01900005340576172\n",
      "Epoch 262: Train_loss 32746958848.0, Validation_loss 30196293632.0, Seconds 0.017999649047851562\n",
      "Epoch 263: Train_loss 32745560064.0, Validation_loss 30195197952.0, Seconds 0.01800394058227539\n",
      "Epoch 264: Train_loss 32744124416.0, Validation_loss 30193833984.0, Seconds 0.019077301025390625\n",
      "Epoch 265: Train_loss 32742676480.0, Validation_loss 30192801792.0, Seconds 0.01846003532409668\n",
      "Epoch 266: Train_loss 32741253120.0, Validation_loss 30191669248.0, Seconds 0.0189974308013916\n",
      "Epoch 267: Train_loss 32739817472.0, Validation_loss 30190329856.0, Seconds 0.016999483108520508\n",
      "Epoch 268: Train_loss 32738385920.0, Validation_loss 30189465600.0, Seconds 0.021999597549438477\n",
      "Epoch 269: Train_loss 32736970752.0, Validation_loss 30188240896.0, Seconds 0.023005962371826172\n",
      "Epoch 270: Train_loss 32735492096.0, Validation_loss 30186792960.0, Seconds 0.08650565147399902\n",
      "Epoch 271: Train_loss 32734056448.0, Validation_loss 30185959424.0, Seconds 0.01807713508605957\n",
      "Epoch 272: Train_loss 32732661760.0, Validation_loss 30184949760.0, Seconds 0.017603635787963867\n",
      "Epoch 273: Train_loss 32731244544.0, Validation_loss 30183641088.0, Seconds 0.019073009490966797\n",
      "Epoch 274: Train_loss 32729796608.0, Validation_loss 30182549504.0, Seconds 0.019925355911254883\n",
      "Epoch 275: Train_loss 32728293376.0, Validation_loss 30181044224.0, Seconds 0.016999483108520508\n",
      "Epoch 276: Train_loss 32726794240.0, Validation_loss 30179909632.0, Seconds 0.024015426635742188\n",
      "Epoch 277: Train_loss 32725346304.0, Validation_loss 30178924544.0, Seconds 0.020536184310913086\n",
      "Epoch 278: Train_loss 32723900416.0, Validation_loss 30177796096.0, Seconds 0.019993305206298828\n",
      "Epoch 279: Train_loss 32722462720.0, Validation_loss 30176675840.0, Seconds 0.01900029182434082\n",
      "Epoch 280: Train_loss 32721010688.0, Validation_loss 30175453184.0, Seconds 0.017001628875732422\n",
      "Epoch 281: Train_loss 32719544320.0, Validation_loss 30174226432.0, Seconds 0.01800227165222168\n",
      "Epoch 282: Train_loss 32718090240.0, Validation_loss 30173247488.0, Seconds 0.02150440216064453\n",
      "Epoch 283: Train_loss 32716656640.0, Validation_loss 30172252160.0, Seconds 0.023000001907348633\n",
      "Epoch 284: Train_loss 32715208704.0, Validation_loss 30170996736.0, Seconds 0.018999814987182617\n",
      "Epoch 285: Train_loss 32713740288.0, Validation_loss 30169911296.0, Seconds 0.024002552032470703\n",
      "Epoch 286: Train_loss 32712282112.0, Validation_loss 30168672256.0, Seconds 0.023668766021728516\n",
      "Epoch 287: Train_loss 32710817792.0, Validation_loss 30167451648.0, Seconds 0.021016359329223633\n",
      "Epoch 288: Train_loss 32709355520.0, Validation_loss 30166427648.0, Seconds 0.022078514099121094\n",
      "Epoch 289: Train_loss 32707887104.0, Validation_loss 30165303296.0, Seconds 0.02292156219482422\n",
      "Epoch 290: Train_loss 32706359296.0, Validation_loss 30163830784.0, Seconds 0.018999576568603516\n",
      "Epoch 291: Train_loss 32704897024.0, Validation_loss 30162749440.0, Seconds 0.0201568603515625\n",
      "Epoch 292: Train_loss 32703428608.0, Validation_loss 30161735680.0, Seconds 0.025000810623168945\n",
      "Epoch 293: Train_loss 32701970432.0, Validation_loss 30160621568.0, Seconds 0.020072221755981445\n",
      "Epoch 294: Train_loss 32700467200.0, Validation_loss 30159323136.0, Seconds 0.01791977882385254\n",
      "Epoch 295: Train_loss 32698988544.0, Validation_loss 30158315520.0, Seconds 0.018002986907958984\n",
      "Epoch 296: Train_loss 32697513984.0, Validation_loss 30157182976.0, Seconds 0.021108388900756836\n",
      "Epoch 297: Train_loss 32696008704.0, Validation_loss 30155649024.0, Seconds 0.018997907638549805\n",
      "Epoch 298: Train_loss 32694517760.0, Validation_loss 30154496000.0, Seconds 0.01999950408935547\n",
      "Epoch 299: Train_loss 32693006336.0, Validation_loss 30153367552.0, Seconds 0.019999980926513672\n",
      "Epoch 300: Train_loss 32691505152.0, Validation_loss 30152181760.0, Seconds 0.02000141143798828\n",
      "Epoch 301: Train_loss 32689977344.0, Validation_loss 30150750208.0, Seconds 0.022547483444213867\n",
      "Epoch 302: Train_loss 32688463872.0, Validation_loss 30149644288.0, Seconds 0.02299976348876953\n",
      "Epoch 303: Train_loss 32686954496.0, Validation_loss 30148503552.0, Seconds 0.023000240325927734\n",
      "Epoch 304: Train_loss 32685447168.0, Validation_loss 30147141632.0, Seconds 0.023007869720458984\n",
      "Epoch 305: Train_loss 32683902976.0, Validation_loss 30145740800.0, Seconds 0.018996477127075195\n",
      "Epoch 306: Train_loss 32682389504.0, Validation_loss 30144667648.0, Seconds 0.018509864807128906\n",
      "Epoch 307: Train_loss 32680890368.0, Validation_loss 30143561728.0, Seconds 0.018997907638549805\n",
      "Epoch 308: Train_loss 32679393280.0, Validation_loss 30142251008.0, Seconds 0.020999908447265625\n",
      "Epoch 309: Train_loss 32677881856.0, Validation_loss 30141028352.0, Seconds 0.02300095558166504\n",
      "Epoch 310: Train_loss 32676347904.0, Validation_loss 30139840512.0, Seconds 0.021003246307373047\n",
      "Epoch 311: Train_loss 32674824192.0, Validation_loss 30138667008.0, Seconds 0.019506216049194336\n",
      "Epoch 312: Train_loss 32673312768.0, Validation_loss 30137497600.0, Seconds 0.020000696182250977\n",
      "Epoch 313: Train_loss 32671770624.0, Validation_loss 30136160256.0, Seconds 0.016999483108520508\n",
      "Epoch 314: Train_loss 32670253056.0, Validation_loss 30135015424.0, Seconds 0.018002033233642578\n",
      "Epoch 315: Train_loss 32668708864.0, Validation_loss 30133667840.0, Seconds 0.019077301025390625\n",
      "Epoch 316: Train_loss 32667195392.0, Validation_loss 30132617216.0, Seconds 0.021507978439331055\n",
      "Epoch 317: Train_loss 32665679872.0, Validation_loss 30131460096.0, Seconds 0.022923707962036133\n",
      "Epoch 318: Train_loss 32664135680.0, Validation_loss 30129995776.0, Seconds 0.024003028869628906\n",
      "Epoch 319: Train_loss 32662577152.0, Validation_loss 30128697344.0, Seconds 0.020998477935791016\n",
      "Epoch 320: Train_loss 32661039104.0, Validation_loss 30127702016.0, Seconds 0.01967334747314453\n",
      "Epoch 321: Train_loss 32659531776.0, Validation_loss 30126686208.0, Seconds 0.021006345748901367\n",
      "Epoch 322: Train_loss 32658003968.0, Validation_loss 30125318144.0, Seconds 0.025989532470703125\n",
      "Epoch 323: Train_loss 32656449536.0, Validation_loss 30123931648.0, Seconds 0.021081209182739258\n",
      "Epoch 324: Train_loss 32654868480.0, Validation_loss 30122622976.0, Seconds 0.022922992706298828\n",
      "Epoch 325: Train_loss 32653316096.0, Validation_loss 30121506816.0, Seconds 0.01950669288635254\n",
      "Epoch 326: Train_loss 32651761664.0, Validation_loss 30120280064.0, Seconds 0.020998477935791016\n",
      "Epoch 327: Train_loss 32650227712.0, Validation_loss 30119106560.0, Seconds 0.017999887466430664\n",
      "Epoch 328: Train_loss 32648675328.0, Validation_loss 30117754880.0, Seconds 0.021001100540161133\n",
      "Epoch 329: Train_loss 32647075840.0, Validation_loss 30116220928.0, Seconds 0.01900339126586914\n",
      "Epoch 330: Train_loss 32645496832.0, Validation_loss 30115096576.0, Seconds 0.022504329681396484\n",
      "Epoch 331: Train_loss 32643928064.0, Validation_loss 30113890304.0, Seconds 0.022007226943969727\n",
      "Epoch 332: Train_loss 32642367488.0, Validation_loss 30112565248.0, Seconds 0.01999378204345703\n",
      "Epoch 333: Train_loss 32640806912.0, Validation_loss 30111395840.0, Seconds 0.019999265670776367\n",
      "Epoch 334: Train_loss 32639223808.0, Validation_loss 30110093312.0, Seconds 0.020003557205200195\n",
      "Epoch 335: Train_loss 32637644800.0, Validation_loss 30108739584.0, Seconds 0.020506858825683594\n",
      "Epoch 336: Train_loss 32636047360.0, Validation_loss 30107359232.0, Seconds 0.017999649047851562\n",
      "Epoch 337: Train_loss 32634466304.0, Validation_loss 30106142720.0, Seconds 0.02100825309753418\n",
      "Epoch 338: Train_loss 32632913920.0, Validation_loss 30105047040.0, Seconds 0.02099299430847168\n",
      "Epoch 339: Train_loss 32631392256.0, Validation_loss 30104104960.0, Seconds 0.02200460433959961\n",
      "Epoch 340: Train_loss 32629831680.0, Validation_loss 30102654976.0, Seconds 0.023031949996948242\n",
      "Epoch 341: Train_loss 32628221952.0, Validation_loss 30100901888.0, Seconds 0.020000219345092773\n",
      "Epoch 342: Train_loss 32626591744.0, Validation_loss 30099570688.0, Seconds 0.020999908447265625\n",
      "Epoch 343: Train_loss 32624994304.0, Validation_loss 30098538496.0, Seconds 0.021007299423217773\n",
      "Epoch 344: Train_loss 32623376384.0, Validation_loss 30097096704.0, Seconds 0.01854872703552246\n",
      "Epoch 345: Train_loss 32621735936.0, Validation_loss 30095669248.0, Seconds 0.017998456954956055\n",
      "Epoch 346: Train_loss 32620113920.0, Validation_loss 30094594048.0, Seconds 0.02099466323852539\n",
      "Epoch 347: Train_loss 32618469376.0, Validation_loss 30093201408.0, Seconds 0.023998498916625977\n",
      "Epoch 348: Train_loss 32616808448.0, Validation_loss 30091730944.0, Seconds 0.024006128311157227\n",
      "Epoch 349: Train_loss 32615188480.0, Validation_loss 30090680320.0, Seconds 0.019509077072143555\n",
      "Epoch 350: Train_loss 32613568512.0, Validation_loss 30089486336.0, Seconds 0.0230100154876709\n",
      "Epoch 351: Train_loss 32611921920.0, Validation_loss 30088050688.0, Seconds 0.021989107131958008\n",
      "Epoch 352: Train_loss 32610312192.0, Validation_loss 30086936576.0, Seconds 0.019000768661499023\n",
      "Epoch 353: Train_loss 32608688128.0, Validation_loss 30085697536.0, Seconds 0.017003297805786133\n",
      "Epoch 354: Train_loss 32607055872.0, Validation_loss 30084347904.0, Seconds 0.01753854751586914\n",
      "Epoch 355: Train_loss 32605380608.0, Validation_loss 30082744320.0, Seconds 0.017005443572998047\n",
      "Epoch 356: Train_loss 32603664384.0, Validation_loss 30081185792.0, Seconds 0.01799941062927246\n",
      "Epoch 357: Train_loss 32601989120.0, Validation_loss 30080112640.0, Seconds 0.01807403564453125\n",
      "Epoch 358: Train_loss 32600332288.0, Validation_loss 30078773248.0, Seconds 0.017927885055541992\n",
      "Epoch 359: Train_loss 32598671360.0, Validation_loss 30077347840.0, Seconds 0.018013715744018555\n",
      "Epoch 360: Train_loss 32596971520.0, Validation_loss 30076078080.0, Seconds 0.020520687103271484\n",
      "Epoch 361: Train_loss 32595253248.0, Validation_loss 30074695680.0, Seconds 0.024001359939575195\n",
      "Epoch 362: Train_loss 32593508352.0, Validation_loss 30073262080.0, Seconds 0.022997617721557617\n",
      "Epoch 363: Train_loss 32591757312.0, Validation_loss 30071824384.0, Seconds 0.021155834197998047\n",
      "Epoch 364: Train_loss 32589979648.0, Validation_loss 30070372352.0, Seconds 0.022429704666137695\n",
      "Epoch 365: Train_loss 32588177408.0, Validation_loss 30068889600.0, Seconds 0.024999618530273438\n",
      "Epoch 366: Train_loss 32586364928.0, Validation_loss 30067412992.0, Seconds 0.027010440826416016\n",
      "Epoch 367: Train_loss 32584534016.0, Validation_loss 30065940480.0, Seconds 0.018990039825439453\n",
      "Epoch 368: Train_loss 32582680576.0, Validation_loss 30064433152.0, Seconds 0.02252984046936035\n",
      "Epoch 369: Train_loss 32580794368.0, Validation_loss 30062809088.0, Seconds 0.024994850158691406\n",
      "Epoch 370: Train_loss 32578844672.0, Validation_loss 30061213696.0, Seconds 0.021003007888793945\n",
      "Epoch 371: Train_loss 32576827392.0, Validation_loss 30059599872.0, Seconds 0.019997119903564453\n",
      "Epoch 372: Train_loss 32574748672.0, Validation_loss 30057842688.0, Seconds 0.021014690399169922\n",
      "Epoch 373: Train_loss 32572602368.0, Validation_loss 30055942144.0, Seconds 0.022514820098876953\n",
      "Epoch 374: Train_loss 32570390528.0, Validation_loss 30053959680.0, Seconds 0.0189971923828125\n",
      "Epoch 375: Train_loss 32568086528.0, Validation_loss 30051751936.0, Seconds 0.022999286651611328\n",
      "Epoch 376: Train_loss 32565682176.0, Validation_loss 30049519616.0, Seconds 0.02200603485107422\n",
      "Epoch 377: Train_loss 32563161088.0, Validation_loss 30047326208.0, Seconds 0.026515722274780273\n",
      "Epoch 378: Train_loss 32560437248.0, Validation_loss 30044934144.0, Seconds 0.01999950408935547\n",
      "Epoch 379: Train_loss 32557369344.0, Validation_loss 30041784320.0, Seconds 0.0240023136138916\n",
      "Epoch 380: Train_loss 32554053632.0, Validation_loss 30038411264.0, Seconds 0.020997285842895508\n",
      "Epoch 381: Train_loss 32550420480.0, Validation_loss 30034300928.0, Seconds 0.02100682258605957\n",
      "Epoch 382: Train_loss 32546172928.0, Validation_loss 30029563904.0, Seconds 0.025078535079956055\n",
      "Epoch 383: Train_loss 32541235200.0, Validation_loss 30025289728.0, Seconds 0.018999338150024414\n",
      "Epoch 384: Train_loss 32536750080.0, Validation_loss 30021933056.0, Seconds 0.019000530242919922\n",
      "Epoch 385: Train_loss 32534087680.0, Validation_loss 30021351424.0, Seconds 0.022001266479492188\n",
      "Epoch 386: Train_loss 32532273152.0, Validation_loss 30020132864.0, Seconds 0.020005226135253906\n",
      "Epoch 387: Train_loss 32530446336.0, Validation_loss 30018926592.0, Seconds 0.018506288528442383\n",
      "Epoch 388: Train_loss 32528414720.0, Validation_loss 30017486848.0, Seconds 0.02200007438659668\n",
      "Epoch 389: Train_loss 32526313472.0, Validation_loss 30015891456.0, Seconds 0.02402520179748535\n",
      "Epoch 390: Train_loss 32524199936.0, Validation_loss 30014285824.0, Seconds 0.025975704193115234\n",
      "Epoch 391: Train_loss 32521875456.0, Validation_loss 30012454912.0, Seconds 0.020514488220214844\n",
      "Epoch 392: Train_loss 32519555072.0, Validation_loss 30010646528.0, Seconds 0.016998291015625\n",
      "Epoch 393: Train_loss 32517134336.0, Validation_loss 30008664064.0, Seconds 0.021999835968017578\n",
      "Epoch 394: Train_loss 32514656256.0, Validation_loss 30006431744.0, Seconds 0.02100658416748047\n",
      "Epoch 395: Train_loss 32512141312.0, Validation_loss 30003963904.0, Seconds 0.022995471954345703\n",
      "Epoch 396: Train_loss 32509507584.0, Validation_loss 30001328128.0, Seconds 0.02350783348083496\n",
      "Epoch 397: Train_loss 32506791936.0, Validation_loss 29998852096.0, Seconds 0.017998218536376953\n",
      "Epoch 398: Train_loss 32503980032.0, Validation_loss 29996189696.0, Seconds 0.024007558822631836\n",
      "Epoch 399: Train_loss 32501026816.0, Validation_loss 29993746432.0, Seconds 0.02699446678161621\n",
      "Epoch 400: Train_loss 32497723392.0, Validation_loss 29990500352.0, Seconds 0.02252960205078125\n",
      "Epoch 401: Train_loss 32494047232.0, Validation_loss 29986580480.0, Seconds 0.022998571395874023\n",
      "Epoch 402: Train_loss 32490135552.0, Validation_loss 29981923328.0, Seconds 0.09067916870117188\n",
      "Epoch 403: Train_loss 32485480448.0, Validation_loss 29976207360.0, Seconds 0.019993066787719727\n",
      "Epoch 404: Train_loss 32480278528.0, Validation_loss 29970577408.0, Seconds 0.024076223373413086\n",
      "Epoch 405: Train_loss 32474570752.0, Validation_loss 29966217216.0, Seconds 0.020923376083374023\n",
      "Epoch 406: Train_loss 32470972416.0, Validation_loss 29964716032.0, Seconds 0.0205080509185791\n",
      "Epoch 407: Train_loss 32469147648.0, Validation_loss 29967052800.0, Seconds 0.020011425018310547\n",
      "Epoch 408: Train_loss 32467472384.0, Validation_loss 29965303808.0, Seconds 0.024989604949951172\n",
      "Epoch 409: Train_loss 32465973248.0, Validation_loss 29962194944.0, Seconds 0.02300095558166504\n",
      "Epoch 410: Train_loss 32464185344.0, Validation_loss 29961764864.0, Seconds 0.024001359939575195\n",
      "Epoch 411: Train_loss 32462280704.0, Validation_loss 29960413184.0, Seconds 0.02250528335571289\n",
      "Epoch 412: Train_loss 32460423168.0, Validation_loss 29958936576.0, Seconds 0.021002531051635742\n",
      "Epoch 413: Train_loss 32458657792.0, Validation_loss 29959153664.0, Seconds 0.022998571395874023\n",
      "Epoch 414: Train_loss 32456787968.0, Validation_loss 29956087808.0, Seconds 0.025002479553222656\n",
      "Epoch 415: Train_loss 32454879232.0, Validation_loss 29954199552.0, Seconds 0.025510549545288086\n",
      "Epoch 416: Train_loss 32453038080.0, Validation_loss 29954164736.0, Seconds 0.022999048233032227\n",
      "Epoch 417: Train_loss 32451241984.0, Validation_loss 29951498240.0, Seconds 0.024002790451049805\n",
      "Epoch 418: Train_loss 32449521664.0, Validation_loss 29950269440.0, Seconds 0.022999286651611328\n",
      "Epoch 419: Train_loss 32447735808.0, Validation_loss 29949274112.0, Seconds 0.02051091194152832\n",
      "Epoch 420: Train_loss 32445939712.0, Validation_loss 29946298368.0, Seconds 0.023000717163085938\n",
      "Epoch 421: Train_loss 32444205056.0, Validation_loss 29945907200.0, Seconds 0.02599954605102539\n",
      "Epoch 422: Train_loss 32442425344.0, Validation_loss 29945153536.0, Seconds 0.020006656646728516\n",
      "Epoch 423: Train_loss 32440729600.0, Validation_loss 29943375872.0, Seconds 0.018015146255493164\n",
      "Epoch 424: Train_loss 32439044096.0, Validation_loss 29941800960.0, Seconds 0.022501707077026367\n",
      "Epoch 425: Train_loss 32437409792.0, Validation_loss 29939718144.0, Seconds 0.01900005340576172\n",
      "Epoch 426: Train_loss 32435789824.0, Validation_loss 29939339264.0, Seconds 0.025002241134643555\n",
      "Epoch 427: Train_loss 32434167808.0, Validation_loss 29939079168.0, Seconds 0.020997285842895508\n",
      "Epoch 428: Train_loss 32432449536.0, Validation_loss 29936470016.0, Seconds 0.02000260353088379\n",
      "Epoch 429: Train_loss 32430776320.0, Validation_loss 29934895104.0, Seconds 0.020505666732788086\n",
      "Epoch 430: Train_loss 32429205504.0, Validation_loss 29934751744.0, Seconds 0.02300286293029785\n",
      "Epoch 431: Train_loss 32427610112.0, Validation_loss 29933080576.0, Seconds 0.021997928619384766\n",
      "Epoch 432: Train_loss 32426029056.0, Validation_loss 29930760192.0, Seconds 0.02200913429260254\n",
      "Epoch 433: Train_loss 32424423424.0, Validation_loss 29929639936.0, Seconds 0.023497819900512695\n",
      "Epoch 434: Train_loss 32422881280.0, Validation_loss 29929814016.0, Seconds 0.02400040626525879\n",
      "Epoch 435: Train_loss 32421177344.0, Validation_loss 29927319552.0, Seconds 0.018999338150024414\n",
      "Epoch 436: Train_loss 32419565568.0, Validation_loss 29926195200.0, Seconds 0.02900099754333496\n",
      "Epoch 437: Train_loss 32417953792.0, Validation_loss 29924087808.0, Seconds 0.0180056095123291\n",
      "Epoch 438: Train_loss 32416454656.0, Validation_loss 29923565568.0, Seconds 0.017507553100585938\n",
      "Epoch 439: Train_loss 32414945280.0, Validation_loss 29922795520.0, Seconds 0.020004749298095703\n",
      "Epoch 440: Train_loss 32413585408.0, Validation_loss 29922566144.0, Seconds 0.02599191665649414\n",
      "Epoch 441: Train_loss 32411987968.0, Validation_loss 29920169984.0, Seconds 0.022002220153808594\n",
      "Epoch 442: Train_loss 32410531840.0, Validation_loss 29918138368.0, Seconds 0.018523693084716797\n",
      "Epoch 443: Train_loss 32409116672.0, Validation_loss 29918066688.0, Seconds 0.021994590759277344\n",
      "Epoch 444: Train_loss 32407730176.0, Validation_loss 29918042112.0, Seconds 0.023007869720458984\n",
      "Epoch 445: Train_loss 32406151168.0, Validation_loss 29915994112.0, Seconds 0.020992279052734375\n",
      "Epoch 446: Train_loss 32404688896.0, Validation_loss 29914972160.0, Seconds 0.018006086349487305\n",
      "Epoch 447: Train_loss 32403214336.0, Validation_loss 29913743360.0, Seconds 0.023509502410888672\n",
      "Epoch 448: Train_loss 32401795072.0, Validation_loss 29912760320.0, Seconds 0.018999338150024414\n",
      "Epoch 449: Train_loss 32400343040.0, Validation_loss 29911140352.0, Seconds 0.01700115203857422\n",
      "Epoch 450: Train_loss 32398897152.0, Validation_loss 29909604352.0, Seconds 0.02100205421447754\n",
      "Epoch 451: Train_loss 32397455360.0, Validation_loss 29908387840.0, Seconds 0.02001953125\n",
      "Epoch 452: Train_loss 32396089344.0, Validation_loss 29908097024.0, Seconds 0.02149796485900879\n",
      "Epoch 453: Train_loss 32394762240.0, Validation_loss 29907435520.0, Seconds 0.019005537033081055\n",
      "Epoch 454: Train_loss 32393261056.0, Validation_loss 29904674816.0, Seconds 0.01802229881286621\n",
      "Epoch 455: Train_loss 32391931904.0, Validation_loss 29904377856.0, Seconds 0.019971609115600586\n",
      "Epoch 456: Train_loss 32390725632.0, Validation_loss 29905072128.0, Seconds 0.018000364303588867\n",
      "Epoch 457: Train_loss 32389132288.0, Validation_loss 29901172736.0, Seconds 0.02054309844970703\n",
      "Epoch 458: Train_loss 32387710976.0, Validation_loss 29899741184.0, Seconds 0.02200031280517578\n",
      "Epoch 459: Train_loss 32386473984.0, Validation_loss 29900507136.0, Seconds 0.020000457763671875\n",
      "Epoch 460: Train_loss 32385294336.0, Validation_loss 29900972032.0, Seconds 0.01700615882873535\n",
      "Epoch 461: Train_loss 32383711232.0, Validation_loss 29897107456.0, Seconds 0.021999835968017578\n",
      "Epoch 462: Train_loss 32382357504.0, Validation_loss 29895798784.0, Seconds 0.02067255973815918\n",
      "Epoch 463: Train_loss 32381143040.0, Validation_loss 29896022016.0, Seconds 0.018992900848388672\n",
      "Epoch 464: Train_loss 32379934720.0, Validation_loss 29895772160.0, Seconds 0.020999670028686523\n",
      "Epoch 465: Train_loss 32378611712.0, Validation_loss 29894096896.0, Seconds 0.018999814987182617\n",
      "Epoch 466: Train_loss 32377262080.0, Validation_loss 29892163584.0, Seconds 0.018047332763671875\n",
      "Epoch 467: Train_loss 32376070144.0, Validation_loss 29891969024.0, Seconds 0.02253866195678711\n",
      "Epoch 468: Train_loss 32374913024.0, Validation_loss 29891801088.0, Seconds 0.019004106521606445\n",
      "Epoch 469: Train_loss 32373772288.0, Validation_loss 29891739648.0, Seconds 0.09550881385803223\n",
      "Epoch 470: Train_loss 32372559872.0, Validation_loss 29890820096.0, Seconds 0.017074108123779297\n",
      "Epoch 471: Train_loss 32371085312.0, Validation_loss 29887913984.0, Seconds 0.021925687789916992\n",
      "Epoch 472: Train_loss 32369741824.0, Validation_loss 29886648320.0, Seconds 0.018001079559326172\n",
      "Epoch 473: Train_loss 32368510976.0, Validation_loss 29886273536.0, Seconds 0.01700425148010254\n",
      "Epoch 474: Train_loss 32367265792.0, Validation_loss 29885579264.0, Seconds 0.016577482223510742\n",
      "Epoch 475: Train_loss 32366055424.0, Validation_loss 29884872704.0, Seconds 0.017936229705810547\n",
      "Epoch 476: Train_loss 32364773376.0, Validation_loss 29883420672.0, Seconds 0.02300119400024414\n",
      "Epoch 477: Train_loss 32363423744.0, Validation_loss 29881391104.0, Seconds 0.021995067596435547\n",
      "Epoch 478: Train_loss 32361998336.0, Validation_loss 29879195648.0, Seconds 0.018002033233642578\n",
      "Epoch 479: Train_loss 32360671232.0, Validation_loss 29877417984.0, Seconds 0.021526098251342773\n",
      "Epoch 480: Train_loss 32359510016.0, Validation_loss 29876148224.0, Seconds 0.01901102066040039\n",
      "Epoch 481: Train_loss 32358377472.0, Validation_loss 29875288064.0, Seconds 0.019988536834716797\n",
      "Epoch 482: Train_loss 32357234688.0, Validation_loss 29874239488.0, Seconds 0.02400040626525879\n",
      "Epoch 483: Train_loss 32355905536.0, Validation_loss 29872070656.0, Seconds 0.020003557205200195\n",
      "Epoch 484: Train_loss 32354488320.0, Validation_loss 29869959168.0, Seconds 0.01851034164428711\n",
      "Epoch 485: Train_loss 32353071104.0, Validation_loss 29867724800.0, Seconds 0.020999670028686523\n",
      "Epoch 486: Train_loss 32351809536.0, Validation_loss 29866057728.0, Seconds 0.02399921417236328\n",
      "Epoch 487: Train_loss 32350568448.0, Validation_loss 29864585216.0, Seconds 0.023006916046142578\n",
      "Epoch 488: Train_loss 32349186048.0, Validation_loss 29861951488.0, Seconds 0.021534442901611328\n",
      "Epoch 489: Train_loss 32347836416.0, Validation_loss 29860435968.0, Seconds 0.02200031280517578\n",
      "Epoch 490: Train_loss 32346400768.0, Validation_loss 29858637824.0, Seconds 0.02399921417236328\n",
      "Epoch 491: Train_loss 32345116672.0, Validation_loss 29857028096.0, Seconds 0.026002168655395508\n",
      "Epoch 492: Train_loss 32343881728.0, Validation_loss 29855348736.0, Seconds 0.024506568908691406\n",
      "Epoch 493: Train_loss 32342591488.0, Validation_loss 29853208576.0, Seconds 0.02300572395324707\n",
      "Epoch 494: Train_loss 32341389312.0, Validation_loss 29851936768.0, Seconds 0.022001266479492188\n",
      "Epoch 495: Train_loss 32340203520.0, Validation_loss 29851099136.0, Seconds 0.020997285842895508\n",
      "Epoch 496: Train_loss 32339027968.0, Validation_loss 29850349568.0, Seconds 0.02101588249206543\n",
      "Epoch 497: Train_loss 32337741824.0, Validation_loss 29848846336.0, Seconds 0.022499799728393555\n",
      "Epoch 498: Train_loss 32336513024.0, Validation_loss 29847906304.0, Seconds 0.022000551223754883\n",
      "Epoch 499: Train_loss 32335374336.0, Validation_loss 29847203840.0, Seconds 0.020999431610107422\n",
      "Epoch 500: Train_loss 32334301184.0, Validation_loss 29846732800.0, Seconds 0.02200150489807129\n",
      "Epoch 501: Train_loss 32333254656.0, Validation_loss 29846102016.0, Seconds 0.023015499114990234\n",
      "Epoch 502: Train_loss 32332230656.0, Validation_loss 29845174272.0, Seconds 0.018512964248657227\n",
      "Epoch 503: Train_loss 32331167744.0, Validation_loss 29844207616.0, Seconds 0.022993087768554688\n",
      "Epoch 504: Train_loss 32330070016.0, Validation_loss 29843212288.0, Seconds 0.02300739288330078\n",
      "Epoch 505: Train_loss 32328919040.0, Validation_loss 29841950720.0, Seconds 0.01899266242980957\n",
      "Epoch 506: Train_loss 32327786496.0, Validation_loss 29841039360.0, Seconds 0.02153325080871582\n",
      "Epoch 507: Train_loss 32326686720.0, Validation_loss 29840330752.0, Seconds 0.020003080368041992\n",
      "Epoch 508: Train_loss 32325646336.0, Validation_loss 29839777792.0, Seconds 0.022035598754882812\n",
      "Epoch 509: Train_loss 32324595712.0, Validation_loss 29838755840.0, Seconds 0.019970417022705078\n",
      "Epoch 510: Train_loss 32323545088.0, Validation_loss 29837473792.0, Seconds 0.01799178123474121\n",
      "Epoch 511: Train_loss 32322541568.0, Validation_loss 29836576768.0, Seconds 0.023546457290649414\n",
      "Epoch 512: Train_loss 32321570816.0, Validation_loss 29835855872.0, Seconds 0.01900959014892578\n",
      "Epoch 513: Train_loss 32320608256.0, Validation_loss 29835143168.0, Seconds 0.020987749099731445\n",
      "Epoch 514: Train_loss 32319598592.0, Validation_loss 29834143744.0, Seconds 0.022001981735229492\n",
      "Epoch 515: Train_loss 32318531584.0, Validation_loss 29833150464.0, Seconds 0.019009828567504883\n",
      "Epoch 516: Train_loss 32317405184.0, Validation_loss 29832382464.0, Seconds 0.01951313018798828\n",
      "Epoch 517: Train_loss 32316379136.0, Validation_loss 29831303168.0, Seconds 0.018997907638549805\n",
      "Epoch 518: Train_loss 32315422720.0, Validation_loss 29830584320.0, Seconds 0.01900458335876465\n",
      "Epoch 519: Train_loss 32314468352.0, Validation_loss 29830162432.0, Seconds 0.018995285034179688\n",
      "Epoch 520: Train_loss 32313481216.0, Validation_loss 29829429248.0, Seconds 0.021001100540161133\n",
      "Epoch 521: Train_loss 32312463360.0, Validation_loss 29828368384.0, Seconds 0.023509979248046875\n",
      "Epoch 522: Train_loss 32311384064.0, Validation_loss 29827174400.0, Seconds 0.020999908447265625\n",
      "Epoch 523: Train_loss 32310263808.0, Validation_loss 29826205696.0, Seconds 0.020999670028686523\n",
      "Epoch 524: Train_loss 32309141504.0, Validation_loss 29824976896.0, Seconds 0.023003578186035156\n",
      "Epoch 525: Train_loss 32307841024.0, Validation_loss 29823029248.0, Seconds 0.022000789642333984\n",
      "Epoch 526: Train_loss 32306606080.0, Validation_loss 29821093888.0, Seconds 0.021506071090698242\n",
      "Epoch 527: Train_loss 32305352704.0, Validation_loss 29819217920.0, Seconds 0.017007112503051758\n",
      "Epoch 528: Train_loss 32304222208.0, Validation_loss 29817436160.0, Seconds 0.018992900848388672\n",
      "Epoch 529: Train_loss 32303056896.0, Validation_loss 29815824384.0, Seconds 0.02200484275817871\n",
      "Epoch 530: Train_loss 32301783040.0, Validation_loss 29814165504.0, Seconds 0.02100992202758789\n",
      "Epoch 531: Train_loss 32300509184.0, Validation_loss 29812600832.0, Seconds 0.01750969886779785\n",
      "Epoch 532: Train_loss 32299333632.0, Validation_loss 29811075072.0, Seconds 0.020000934600830078\n",
      "Epoch 533: Train_loss 32298098688.0, Validation_loss 29809864704.0, Seconds 0.02000904083251953\n",
      "Epoch 534: Train_loss 32296960000.0, Validation_loss 29808631808.0, Seconds 0.02698969841003418\n",
      "Epoch 535: Train_loss 32295929856.0, Validation_loss 29807413248.0, Seconds 0.018003463745117188\n",
      "Epoch 536: Train_loss 32294836224.0, Validation_loss 29806469120.0, Seconds 0.01950836181640625\n",
      "Epoch 537: Train_loss 32293789696.0, Validation_loss 29805611008.0, Seconds 0.017004728317260742\n",
      "Epoch 538: Train_loss 32292911104.0, Validation_loss 29804662784.0, Seconds 0.026999950408935547\n",
      "Epoch 539: Train_loss 32291985408.0, Validation_loss 29803829248.0, Seconds 0.022999048233032227\n",
      "Epoch 540: Train_loss 32290992128.0, Validation_loss 29803120640.0, Seconds 0.023515939712524414\n",
      "Epoch 541: Train_loss 32290037760.0, Validation_loss 29802366976.0, Seconds 0.01907658576965332\n",
      "Epoch 542: Train_loss 32289183744.0, Validation_loss 29801457664.0, Seconds 0.020928621292114258\n",
      "Epoch 543: Train_loss 32288249856.0, Validation_loss 29800665088.0, Seconds 0.017998695373535156\n",
      "Epoch 544: Train_loss 32287297536.0, Validation_loss 29799901184.0, Seconds 0.01900792121887207\n",
      "Epoch 545: Train_loss 32286423040.0, Validation_loss 29799053312.0, Seconds 0.025532245635986328\n",
      "Epoch 546: Train_loss 32285523968.0, Validation_loss 29798162432.0, Seconds 0.022992610931396484\n",
      "Epoch 547: Train_loss 32284538880.0, Validation_loss 29797292032.0, Seconds 0.01900005340576172\n",
      "Epoch 548: Train_loss 32283541504.0, Validation_loss 29796407296.0, Seconds 0.021000385284423828\n",
      "Epoch 549: Train_loss 32282570752.0, Validation_loss 29795516416.0, Seconds 0.018016576766967773\n",
      "Epoch 550: Train_loss 32281634816.0, Validation_loss 29794639872.0, Seconds 0.018650293350219727\n",
      "Epoch 551: Train_loss 32280735744.0, Validation_loss 29793767424.0, Seconds 0.020009756088256836\n",
      "Epoch 552: Train_loss 32279846912.0, Validation_loss 29792968704.0, Seconds 0.018030166625976562\n",
      "Epoch 553: Train_loss 32278972416.0, Validation_loss 29792206848.0, Seconds 0.0199587345123291\n",
      "Epoch 554: Train_loss 32278122496.0, Validation_loss 29791455232.0, Seconds 0.021008014678955078\n",
      "Epoch 555: Train_loss 32277288960.0, Validation_loss 29790722048.0, Seconds 0.01751399040222168\n",
      "Epoch 556: Train_loss 32276459520.0, Validation_loss 29790017536.0, Seconds 0.017999887466430664\n",
      "Epoch 557: Train_loss 32275640320.0, Validation_loss 29789317120.0, Seconds 0.020000696182250977\n",
      "Epoch 558: Train_loss 32274839552.0, Validation_loss 29788643328.0, Seconds 0.022073984146118164\n",
      "Epoch 559: Train_loss 32274063360.0, Validation_loss 29787924480.0, Seconds 0.024940967559814453\n",
      "Epoch 560: Train_loss 32273262592.0, Validation_loss 29787035648.0, Seconds 0.021509885787963867\n",
      "Epoch 561: Train_loss 32272384000.0, Validation_loss 29785796608.0, Seconds 0.0169985294342041\n",
      "Epoch 562: Train_loss 32271591424.0, Validation_loss 29784279040.0, Seconds 0.02100086212158203\n",
      "Epoch 563: Train_loss 32270843904.0, Validation_loss 29782904832.0, Seconds 0.021999359130859375\n",
      "Epoch 564: Train_loss 32269983744.0, Validation_loss 29781585920.0, Seconds 0.02100372314453125\n",
      "Epoch 565: Train_loss 32269017088.0, Validation_loss 29780291584.0, Seconds 0.018584251403808594\n",
      "Epoch 566: Train_loss 32268038144.0, Validation_loss 29779134464.0, Seconds 0.019932270050048828\n",
      "Epoch 567: Train_loss 32267120640.0, Validation_loss 29778139136.0, Seconds 0.021993160247802734\n",
      "Epoch 568: Train_loss 32266283008.0, Validation_loss 29777274880.0, Seconds 0.02108931541442871\n",
      "Epoch 569: Train_loss 32265502720.0, Validation_loss 29776504832.0, Seconds 0.022010087966918945\n",
      "Epoch 570: Train_loss 32264749056.0, Validation_loss 29775783936.0, Seconds 0.023526668548583984\n",
      "Epoch 571: Train_loss 32264022016.0, Validation_loss 29775075328.0, Seconds 0.020000696182250977\n",
      "Epoch 572: Train_loss 32263280640.0, Validation_loss 29774348288.0, Seconds 0.01900649070739746\n",
      "Epoch 573: Train_loss 32262514688.0, Validation_loss 29773608960.0, Seconds 0.023070335388183594\n",
      "Epoch 574: Train_loss 32261726208.0, Validation_loss 29772865536.0, Seconds 0.02459239959716797\n",
      "Epoch 575: Train_loss 32260945920.0, Validation_loss 29772142592.0, Seconds 0.01899552345275879\n",
      "Epoch 576: Train_loss 32260182016.0, Validation_loss 29771442176.0, Seconds 0.020076751708984375\n",
      "Epoch 577: Train_loss 32259442688.0, Validation_loss 29770782720.0, Seconds 0.020931482315063477\n",
      "Epoch 578: Train_loss 32258717696.0, Validation_loss 29770170368.0, Seconds 0.02600884437561035\n",
      "Epoch 579: Train_loss 32258007040.0, Validation_loss 29769588736.0, Seconds 0.02109050750732422\n",
      "Epoch 580: Train_loss 32257318912.0, Validation_loss 29769007104.0, Seconds 0.019989728927612305\n",
      "Epoch 581: Train_loss 32256643072.0, Validation_loss 29768431616.0, Seconds 0.0240020751953125\n",
      "Epoch 582: Train_loss 32255975424.0, Validation_loss 29767856128.0, Seconds 0.020074844360351562\n",
      "Epoch 583: Train_loss 32255301632.0, Validation_loss 29767270400.0, Seconds 0.021446704864501953\n",
      "Epoch 584: Train_loss 32254621696.0, Validation_loss 29766703104.0, Seconds 0.02000141143798828\n",
      "Epoch 585: Train_loss 32253947904.0, Validation_loss 29766150144.0, Seconds 0.020999431610107422\n",
      "Epoch 586: Train_loss 32253270016.0, Validation_loss 29765611520.0, Seconds 0.017998456954956055\n",
      "Epoch 587: Train_loss 32252588032.0, Validation_loss 29765083136.0, Seconds 0.020000934600830078\n",
      "Epoch 588: Train_loss 32251922432.0, Validation_loss 29764567040.0, Seconds 0.02054142951965332\n",
      "Epoch 589: Train_loss 32251271168.0, Validation_loss 29764050944.0, Seconds 0.023000717163085938\n",
      "Epoch 590: Train_loss 32250636288.0, Validation_loss 29763518464.0, Seconds 0.021999597549438477\n",
      "Epoch 591: Train_loss 32250003456.0, Validation_loss 29762985984.0, Seconds 0.02299356460571289\n",
      "Epoch 592: Train_loss 32249380864.0, Validation_loss 29762455552.0, Seconds 0.025004148483276367\n",
      "Epoch 593: Train_loss 32248772608.0, Validation_loss 29761939456.0, Seconds 0.019504308700561523\n",
      "Epoch 594: Train_loss 32248178688.0, Validation_loss 29761384448.0, Seconds 0.022004365921020508\n",
      "Epoch 595: Train_loss 32247607296.0, Validation_loss 29760782336.0, Seconds 0.01999974250793457\n",
      "Epoch 596: Train_loss 32247050240.0, Validation_loss 29760129024.0, Seconds 0.020996570587158203\n",
      "Epoch 597: Train_loss 32246487040.0, Validation_loss 29759451136.0, Seconds 0.019003629684448242\n",
      "Epoch 598: Train_loss 32245905408.0, Validation_loss 29758797824.0, Seconds 0.018582820892333984\n",
      "Epoch 599: Train_loss 32245202944.0, Validation_loss 29758314496.0, Seconds 0.017925024032592773\n",
      "Epoch 600: Train_loss 32244488192.0, Validation_loss 29757902848.0, Seconds 0.021006345748901367\n",
      "Epoch 601: Train_loss 32243867648.0, Validation_loss 29757417472.0, Seconds 0.08550620079040527\n",
      "Epoch 602: Train_loss 32243304448.0, Validation_loss 29756858368.0, Seconds 0.02200031280517578\n",
      "Epoch 603: Train_loss 32242708480.0, Validation_loss 29756338176.0, Seconds 0.019998550415039062\n",
      "Epoch 604: Train_loss 32242112512.0, Validation_loss 29755795456.0, Seconds 0.02251720428466797\n",
      "Epoch 605: Train_loss 32241451008.0, Validation_loss 29755396096.0, Seconds 0.018001794815063477\n",
      "Epoch 606: Train_loss 32240840704.0, Validation_loss 29754912768.0, Seconds 0.019008398056030273\n",
      "Epoch 607: Train_loss 32240304128.0, Validation_loss 29754306560.0, Seconds 0.019006013870239258\n",
      "Epoch 608: Train_loss 32239689728.0, Validation_loss 29753839616.0, Seconds 0.021991252899169922\n",
      "Epoch 609: Train_loss 32239067136.0, Validation_loss 29753356288.0, Seconds 0.021513700485229492\n",
      "Epoch 610: Train_loss 32238448640.0, Validation_loss 29752913920.0, Seconds 0.021008014678955078\n",
      "Epoch 611: Train_loss 32237815808.0, Validation_loss 29752479744.0, Seconds 0.019991397857666016\n",
      "Epoch 612: Train_loss 32237189120.0, Validation_loss 29752049664.0, Seconds 0.02000141143798828\n",
      "Epoch 613: Train_loss 32236597248.0, Validation_loss 29751535616.0, Seconds 0.02300572395324707\n",
      "Epoch 614: Train_loss 32236007424.0, Validation_loss 29751066624.0, Seconds 0.023582935333251953\n",
      "Epoch 615: Train_loss 32235409408.0, Validation_loss 29750618112.0, Seconds 0.020926713943481445\n",
      "Epoch 616: Train_loss 32234797056.0, Validation_loss 29750142976.0, Seconds 0.02099776268005371\n",
      "Epoch 617: Train_loss 32234153984.0, Validation_loss 29749612544.0, Seconds 0.018002033233642578\n",
      "Epoch 618: Train_loss 32233506816.0, Validation_loss 29748879360.0, Seconds 0.02000284194946289\n",
      "Epoch 619: Train_loss 32232845312.0, Validation_loss 29747939328.0, Seconds 0.021506309509277344\n",
      "Epoch 620: Train_loss 32232206336.0, Validation_loss 29746915328.0, Seconds 0.01900005340576172\n",
      "Epoch 621: Train_loss 32231569408.0, Validation_loss 29745698816.0, Seconds 0.02400374412536621\n",
      "Epoch 622: Train_loss 32230881280.0, Validation_loss 29743886336.0, Seconds 0.021997928619384766\n",
      "Epoch 623: Train_loss 32230121472.0, Validation_loss 29741895680.0, Seconds 0.02001023292541504\n",
      "Epoch 624: Train_loss 32229363712.0, Validation_loss 29739757568.0, Seconds 0.019518375396728516\n",
      "Epoch 625: Train_loss 32228458496.0, Validation_loss 29737543680.0, Seconds 0.01800227165222168\n",
      "Epoch 626: Train_loss 32227383296.0, Validation_loss 29735772160.0, Seconds 0.018998146057128906\n",
      "Epoch 627: Train_loss 32226680832.0, Validation_loss 29734514688.0, Seconds 0.02500009536743164\n",
      "Epoch 628: Train_loss 32226078720.0, Validation_loss 29733533696.0, Seconds 0.017003774642944336\n",
      "Epoch 629: Train_loss 32225476608.0, Validation_loss 29732839424.0, Seconds 0.01851201057434082\n",
      "Epoch 630: Train_loss 32224876544.0, Validation_loss 29732409344.0, Seconds 0.0189971923828125\n",
      "Epoch 631: Train_loss 32224290816.0, Validation_loss 29732122624.0, Seconds 0.01800084114074707\n",
      "Epoch 632: Train_loss 32223737856.0, Validation_loss 29731819520.0, Seconds 0.01701068878173828\n",
      "Epoch 633: Train_loss 32223207424.0, Validation_loss 29731475456.0, Seconds 0.017991065979003906\n",
      "Epoch 634: Train_loss 32222676992.0, Validation_loss 29731074048.0, Seconds 0.021671056747436523\n",
      "Epoch 635: Train_loss 32222134272.0, Validation_loss 29730646016.0, Seconds 0.01899862289428711\n",
      "Epoch 636: Train_loss 32221581312.0, Validation_loss 29730193408.0, Seconds 0.01900005340576172\n",
      "Epoch 637: Train_loss 32221016064.0, Validation_loss 29729687552.0, Seconds 0.01900196075439453\n",
      "Epoch 638: Train_loss 32220446720.0, Validation_loss 29729140736.0, Seconds 0.018000125885009766\n",
      "Epoch 639: Train_loss 32219885568.0, Validation_loss 29728559104.0, Seconds 0.017507553100585938\n",
      "Epoch 640: Train_loss 32219332608.0, Validation_loss 29727950848.0, Seconds 0.017999649047851562\n",
      "Epoch 641: Train_loss 32218779648.0, Validation_loss 29727336448.0, Seconds 0.019002199172973633\n",
      "Epoch 642: Train_loss 32218226688.0, Validation_loss 29726715904.0, Seconds 0.021007299423217773\n",
      "Epoch 643: Train_loss 32217690112.0, Validation_loss 29726109696.0, Seconds 0.020991802215576172\n",
      "Epoch 644: Train_loss 32217159680.0, Validation_loss 29725536256.0, Seconds 0.018004655838012695\n",
      "Epoch 645: Train_loss 32216637440.0, Validation_loss 29724962816.0, Seconds 0.02250981330871582\n",
      "Epoch 646: Train_loss 32216119296.0, Validation_loss 29724401664.0, Seconds 0.0240018367767334\n",
      "Epoch 647: Train_loss 32215623680.0, Validation_loss 29723879424.0, Seconds 0.019002914428710938\n",
      "Epoch 648: Train_loss 32215126016.0, Validation_loss 29723371520.0, Seconds 0.016996383666992188\n",
      "Epoch 649: Train_loss 32214644736.0, Validation_loss 29722880000.0, Seconds 0.019527435302734375\n",
      "Epoch 650: Train_loss 32214155264.0, Validation_loss 29722415104.0, Seconds 0.017015457153320312\n",
      "Epoch 651: Train_loss 32213667840.0, Validation_loss 29721978880.0, Seconds 0.02199268341064453\n",
      "Epoch 652: Train_loss 32213170176.0, Validation_loss 29721550848.0, Seconds 0.019001007080078125\n",
      "Epoch 653: Train_loss 32212692992.0, Validation_loss 29721159680.0, Seconds 0.01807403564453125\n",
      "Epoch 654: Train_loss 32212244480.0, Validation_loss 29720784896.0, Seconds 0.019082307815551758\n",
      "Epoch 655: Train_loss 32211789824.0, Validation_loss 29720391680.0, Seconds 0.017584800720214844\n",
      "Epoch 656: Train_loss 32211335168.0, Validation_loss 29719996416.0, Seconds 0.018001794815063477\n",
      "Epoch 657: Train_loss 32210882560.0, Validation_loss 29719621632.0, Seconds 0.02100062370300293\n",
      "Epoch 658: Train_loss 32210421760.0, Validation_loss 29719263232.0, Seconds 0.023000001907348633\n",
      "Epoch 659: Train_loss 32209950720.0, Validation_loss 29718902784.0, Seconds 0.018079042434692383\n",
      "Epoch 660: Train_loss 32209463296.0, Validation_loss 29718577152.0, Seconds 0.01746511459350586\n",
      "Epoch 661: Train_loss 32208969728.0, Validation_loss 29718235136.0, Seconds 0.016998767852783203\n",
      "Epoch 662: Train_loss 32208451584.0, Validation_loss 29717909504.0, Seconds 0.020992517471313477\n",
      "Epoch 663: Train_loss 32207962112.0, Validation_loss 29717594112.0, Seconds 0.022004365921020508\n",
      "Epoch 664: Train_loss 32207460352.0, Validation_loss 29717284864.0, Seconds 0.02208542823791504\n",
      "Epoch 665: Train_loss 32206966784.0, Validation_loss 29716979712.0, Seconds 0.02252984046936035\n",
      "Epoch 666: Train_loss 32206487552.0, Validation_loss 29716606976.0, Seconds 0.019994735717773438\n",
      "Epoch 667: Train_loss 32206016512.0, Validation_loss 29716219904.0, Seconds 0.020000696182250977\n",
      "Epoch 668: Train_loss 32205541376.0, Validation_loss 29715802112.0, Seconds 0.021004199981689453\n",
      "Epoch 669: Train_loss 32205078528.0, Validation_loss 29715361792.0, Seconds 0.0825192928314209\n",
      "Epoch 670: Train_loss 32204619776.0, Validation_loss 29714900992.0, Seconds 0.01800251007080078\n",
      "Epoch 671: Train_loss 32204173312.0, Validation_loss 29714409472.0, Seconds 0.019076108932495117\n",
      "Epoch 672: Train_loss 32203708416.0, Validation_loss 29713866752.0, Seconds 0.022509098052978516\n",
      "Epoch 673: Train_loss 32203286528.0, Validation_loss 29713350656.0, Seconds 0.01899886131286621\n",
      "Epoch 674: Train_loss 32202885120.0, Validation_loss 29712910336.0, Seconds 0.022998571395874023\n",
      "Epoch 675: Train_loss 32202479616.0, Validation_loss 29712494592.0, Seconds 0.02006983757019043\n",
      "Epoch 676: Train_loss 32202084352.0, Validation_loss 29712087040.0, Seconds 0.024443864822387695\n",
      "Epoch 677: Train_loss 32201703424.0, Validation_loss 29711693824.0, Seconds 0.022999286651611328\n",
      "Epoch 678: Train_loss 32201347072.0, Validation_loss 29711314944.0, Seconds 0.017999649047851562\n",
      "Epoch 679: Train_loss 32201005056.0, Validation_loss 29710966784.0, Seconds 0.018998384475708008\n",
      "Epoch 680: Train_loss 32200669184.0, Validation_loss 29710628864.0, Seconds 0.020022153854370117\n",
      "Epoch 681: Train_loss 32200349696.0, Validation_loss 29710264320.0, Seconds 0.017496824264526367\n",
      "Epoch 682: Train_loss 32200046592.0, Validation_loss 29709881344.0, Seconds 0.01800251007080078\n",
      "Epoch 683: Train_loss 32199753728.0, Validation_loss 29709490176.0, Seconds 0.022997379302978516\n",
      "Epoch 684: Train_loss 32199460864.0, Validation_loss 29709109248.0, Seconds 0.018001794815063477\n",
      "Epoch 685: Train_loss 32199145472.0, Validation_loss 29708775424.0, Seconds 0.019999027252197266\n",
      "Epoch 686: Train_loss 32198815744.0, Validation_loss 29708460032.0, Seconds 0.018509626388549805\n",
      "Epoch 687: Train_loss 32198494208.0, Validation_loss 29708167168.0, Seconds 0.01900506019592285\n",
      "Epoch 688: Train_loss 32198182912.0, Validation_loss 29707900928.0, Seconds 0.018999338150024414\n",
      "Epoch 689: Train_loss 32197890048.0, Validation_loss 29707651072.0, Seconds 0.024000167846679688\n",
      "Epoch 690: Train_loss 32197603328.0, Validation_loss 29707403264.0, Seconds 0.017999887466430664\n",
      "Epoch 691: Train_loss 32197318656.0, Validation_loss 29707153408.0, Seconds 0.021744489669799805\n",
      "Epoch 692: Train_loss 32197033984.0, Validation_loss 29706903552.0, Seconds 0.022925615310668945\n",
      "Epoch 693: Train_loss 32196757504.0, Validation_loss 29706641408.0, Seconds 0.021999835968017578\n",
      "Epoch 694: Train_loss 32196485120.0, Validation_loss 29706385408.0, Seconds 0.02100062370300293\n",
      "Epoch 695: Train_loss 32196202496.0, Validation_loss 29706121216.0, Seconds 0.018002033233642578\n",
      "Epoch 696: Train_loss 32195917824.0, Validation_loss 29705846784.0, Seconds 0.01751089096069336\n",
      "Epoch 697: Train_loss 32195645440.0, Validation_loss 29705588736.0, Seconds 0.020039796829223633\n",
      "Epoch 698: Train_loss 32195375104.0, Validation_loss 29705336832.0, Seconds 0.022958993911743164\n",
      "Epoch 699: Train_loss 32195108864.0, Validation_loss 29705082880.0, Seconds 0.01999950408935547\n",
      "Epoch 700: Train_loss 32194854912.0, Validation_loss 29704814592.0, Seconds 0.02300429344177246\n",
      "Epoch 701: Train_loss 32194609152.0, Validation_loss 29704554496.0, Seconds 0.022673845291137695\n",
      "Epoch 702: Train_loss 32194357248.0, Validation_loss 29704294400.0, Seconds 0.022997617721557617\n",
      "Epoch 703: Train_loss 32194088960.0, Validation_loss 29704054784.0, Seconds 0.02099299430847168\n",
      "Epoch 704: Train_loss 32193814528.0, Validation_loss 29703823360.0, Seconds 0.018999814987182617\n",
      "Epoch 705: Train_loss 32193536000.0, Validation_loss 29703600128.0, Seconds 0.020003557205200195\n",
      "Epoch 706: Train_loss 32193251328.0, Validation_loss 29703360512.0, Seconds 0.017505884170532227\n",
      "Epoch 707: Train_loss 32192989184.0, Validation_loss 29703157760.0, Seconds 0.020002126693725586\n",
      "Epoch 708: Train_loss 32192741376.0, Validation_loss 29702952960.0, Seconds 0.02303791046142578\n",
      "Epoch 709: Train_loss 32192512000.0, Validation_loss 29702701056.0, Seconds 0.02296161651611328\n",
      "Epoch 710: Train_loss 32192264192.0, Validation_loss 29702400000.0, Seconds 0.01900339126586914\n",
      "Epoch 711: Train_loss 32192024576.0, Validation_loss 29701969920.0, Seconds 0.022511959075927734\n",
      "Epoch 712: Train_loss 32191766528.0, Validation_loss 29701474304.0, Seconds 0.018997907638549805\n",
      "Epoch 713: Train_loss 32191506432.0, Validation_loss 29701019648.0, Seconds 0.024997472763061523\n",
      "Epoch 714: Train_loss 32191260672.0, Validation_loss 29700675584.0, Seconds 0.0220029354095459\n",
      "Epoch 715: Train_loss 32191012864.0, Validation_loss 29700372480.0, Seconds 0.02654552459716797\n",
      "Epoch 716: Train_loss 32190775296.0, Validation_loss 29700077568.0, Seconds 0.01906561851501465\n",
      "Epoch 717: Train_loss 32190556160.0, Validation_loss 29699821568.0, Seconds 0.019925594329833984\n",
      "Epoch 718: Train_loss 32190355456.0, Validation_loss 29699588096.0, Seconds 0.02200150489807129\n",
      "Epoch 719: Train_loss 32190154752.0, Validation_loss 29699389440.0, Seconds 0.026507139205932617\n",
      "Epoch 720: Train_loss 32189954048.0, Validation_loss 29699182592.0, Seconds 0.023000240325927734\n",
      "Epoch 721: Train_loss 32189755392.0, Validation_loss 29698998272.0, Seconds 0.02299976348876953\n",
      "Epoch 722: Train_loss 32189558784.0, Validation_loss 29698813952.0, Seconds 0.021999835968017578\n",
      "Epoch 723: Train_loss 32189360128.0, Validation_loss 29698637824.0, Seconds 0.02400517463684082\n",
      "Epoch 724: Train_loss 32189165568.0, Validation_loss 29698437120.0, Seconds 0.02350759506225586\n",
      "Epoch 725: Train_loss 32188973056.0, Validation_loss 29698248704.0, Seconds 0.02300119400024414\n",
      "Epoch 726: Train_loss 32188778496.0, Validation_loss 29698045952.0, Seconds 0.025007963180541992\n",
      "Epoch 727: Train_loss 32188594176.0, Validation_loss 29697824768.0, Seconds 0.023995637893676758\n",
      "Epoch 728: Train_loss 32188409856.0, Validation_loss 29697607680.0, Seconds 0.02250528335571289\n",
      "Epoch 729: Train_loss 32188209152.0, Validation_loss 29697388544.0, Seconds 0.02199864387512207\n",
      "Epoch 730: Train_loss 32188020736.0, Validation_loss 29697150976.0, Seconds 0.023007631301879883\n",
      "Epoch 731: Train_loss 32187840512.0, Validation_loss 29696907264.0, Seconds 0.020993709564208984\n",
      "Epoch 732: Train_loss 32187654144.0, Validation_loss 29696671744.0, Seconds 0.023509502410888672\n",
      "Epoch 733: Train_loss 32187463680.0, Validation_loss 29696444416.0, Seconds 0.02200484275817871\n",
      "Epoch 734: Train_loss 32187279360.0, Validation_loss 29696215040.0, Seconds 0.017009496688842773\n",
      "Epoch 735: Train_loss 32187105280.0, Validation_loss 29695975424.0, Seconds 0.020996809005737305\n",
      "Epoch 736: Train_loss 32186937344.0, Validation_loss 29695731712.0, Seconds 0.022994518280029297\n",
      "Epoch 737: Train_loss 32186765312.0, Validation_loss 29695498240.0, Seconds 0.02352309226989746\n",
      "Epoch 738: Train_loss 32186568704.0, Validation_loss 29695275008.0, Seconds 0.019991159439086914\n",
      "Epoch 739: Train_loss 32186378240.0, Validation_loss 29695037440.0, Seconds 0.024999618530273438\n",
      "Epoch 740: Train_loss 32186200064.0, Validation_loss 29694810112.0, Seconds 0.022998332977294922\n",
      "Epoch 741: Train_loss 32186015744.0, Validation_loss 29694547968.0, Seconds 0.01909041404724121\n",
      "Epoch 742: Train_loss 32185800704.0, Validation_loss 29694212096.0, Seconds 0.024318456649780273\n",
      "Epoch 743: Train_loss 32185548800.0, Validation_loss 29693818880.0, Seconds 0.024993896484375\n",
      "Epoch 744: Train_loss 32185272320.0, Validation_loss 29693388800.0, Seconds 0.020998477935791016\n",
      "Epoch 745: Train_loss 32184952832.0, Validation_loss 29692917760.0, Seconds 0.019008398056030273\n",
      "Epoch 746: Train_loss 32184526848.0, Validation_loss 29692305408.0, Seconds 0.021512508392333984\n",
      "Epoch 747: Train_loss 32183941120.0, Validation_loss 29691498496.0, Seconds 0.021006345748901367\n",
      "Epoch 748: Train_loss 32183148544.0, Validation_loss 29690458112.0, Seconds 0.019992589950561523\n",
      "Epoch 749: Train_loss 32182183936.0, Validation_loss 29689102336.0, Seconds 0.021001100540161133\n",
      "Epoch 750: Train_loss 32181028864.0, Validation_loss 29687371776.0, Seconds 0.024002552032470703\n",
      "Epoch 751: Train_loss 32179752960.0, Validation_loss 29685657600.0, Seconds 0.01950526237487793\n",
      "Epoch 752: Train_loss 32178489344.0, Validation_loss 29683927040.0, Seconds 0.02100682258605957\n",
      "Epoch 753: Train_loss 32177231872.0, Validation_loss 29681711104.0, Seconds 0.019994258880615234\n",
      "Epoch 754: Train_loss 32175962112.0, Validation_loss 29679644672.0, Seconds 0.02001047134399414\n",
      "Epoch 755: Train_loss 32174706688.0, Validation_loss 29677807616.0, Seconds 0.018001794815063477\n",
      "Epoch 756: Train_loss 32173412352.0, Validation_loss 29675845632.0, Seconds 0.02451801300048828\n",
      "Epoch 757: Train_loss 32172195840.0, Validation_loss 29673988096.0, Seconds 0.01900649070739746\n",
      "Epoch 758: Train_loss 32170995712.0, Validation_loss 29672341504.0, Seconds 0.02199268341064453\n",
      "Epoch 759: Train_loss 32169857024.0, Validation_loss 29670793216.0, Seconds 0.02107977867126465\n",
      "Epoch 760: Train_loss 32168810496.0, Validation_loss 29669261312.0, Seconds 0.019930124282836914\n",
      "Epoch 761: Train_loss 32167884800.0, Validation_loss 29667485696.0, Seconds 0.020507335662841797\n",
      "Epoch 762: Train_loss 32167137280.0, Validation_loss 29665878016.0, Seconds 0.0189974308013916\n",
      "Epoch 763: Train_loss 32166535168.0, Validation_loss 29664569344.0, Seconds 0.022000789642333984\n",
      "Epoch 764: Train_loss 32166062080.0, Validation_loss 29663662080.0, Seconds 0.01801013946533203\n",
      "Epoch 765: Train_loss 32165683200.0, Validation_loss 29663008768.0, Seconds 0.016994714736938477\n",
      "Epoch 766: Train_loss 32165343232.0, Validation_loss 29662443520.0, Seconds 0.01758289337158203\n",
      "Epoch 767: Train_loss 32165060608.0, Validation_loss 29661880320.0, Seconds 0.018918991088867188\n",
      "Epoch 768: Train_loss 32164800512.0, Validation_loss 29661358080.0, Seconds 0.018000364303588867\n",
      "Epoch 769: Train_loss 32164550656.0, Validation_loss 29660872704.0, Seconds 0.018000364303588867\n",
      "Epoch 770: Train_loss 32164280320.0, Validation_loss 29660418048.0, Seconds 0.01807880401611328\n",
      "Epoch 771: Train_loss 32163991552.0, Validation_loss 29659912192.0, Seconds 0.02051520347595215\n",
      "Epoch 772: Train_loss 32163721216.0, Validation_loss 29659451392.0, Seconds 0.017070531845092773\n",
      "Epoch 773: Train_loss 32163483648.0, Validation_loss 29659021312.0, Seconds 0.019974946975708008\n",
      "Epoch 774: Train_loss 32163256320.0, Validation_loss 29658613760.0, Seconds 0.0339508056640625\n",
      "Epoch 775: Train_loss 32163039232.0, Validation_loss 29658222592.0, Seconds 0.020004749298095703\n",
      "Epoch 776: Train_loss 32162824192.0, Validation_loss 29657880576.0, Seconds 0.018508195877075195\n",
      "Epoch 777: Train_loss 32162621440.0, Validation_loss 29657569280.0, Seconds 0.024001121520996094\n",
      "Epoch 778: Train_loss 32162422784.0, Validation_loss 29657253888.0, Seconds 0.024001598358154297\n",
      "Epoch 779: Train_loss 32162232320.0, Validation_loss 29656977408.0, Seconds 0.01899886131286621\n",
      "Epoch 780: Train_loss 32162058240.0, Validation_loss 29656750080.0, Seconds 0.022547483444213867\n",
      "Epoch 781: Train_loss 32161896448.0, Validation_loss 29656532992.0, Seconds 0.02198934555053711\n",
      "Epoch 782: Train_loss 32161734656.0, Validation_loss 29656305664.0, Seconds 0.018008947372436523\n",
      "Epoch 783: Train_loss 32161564672.0, Validation_loss 29656076288.0, Seconds 0.01999044418334961\n",
      "Epoch 784: Train_loss 32161409024.0, Validation_loss 29655859200.0, Seconds 0.024013280868530273\n",
      "Epoch 785: Train_loss 32161251328.0, Validation_loss 29655642112.0, Seconds 0.019588470458984375\n",
      "Epoch 786: Train_loss 32161089536.0, Validation_loss 29655451648.0, Seconds 0.01892685890197754\n",
      "Epoch 787: Train_loss 32160931840.0, Validation_loss 29655244800.0, Seconds 0.023003578186035156\n",
      "Epoch 788: Train_loss 32160778240.0, Validation_loss 29655005184.0, Seconds 0.019991636276245117\n",
      "Epoch 789: Train_loss 32160616448.0, Validation_loss 29654761472.0, Seconds 0.020003557205200195\n",
      "Epoch 790: Train_loss 32160458752.0, Validation_loss 29654556672.0, Seconds 0.017589330673217773\n",
      "Epoch 791: Train_loss 32160303104.0, Validation_loss 29654347776.0, Seconds 0.01792144775390625\n",
      "Epoch 792: Train_loss 32160165888.0, Validation_loss 29654140928.0, Seconds 0.01807403564453125\n",
      "Epoch 793: Train_loss 32160020480.0, Validation_loss 29653909504.0, Seconds 0.017924070358276367\n",
      "Epoch 794: Train_loss 32159885312.0, Validation_loss 29653684224.0, Seconds 0.01807689666748047\n",
      "Epoch 795: Train_loss 32159756288.0, Validation_loss 29653491712.0, Seconds 0.021538496017456055\n",
      "Epoch 796: Train_loss 32159625216.0, Validation_loss 29653344256.0, Seconds 0.018995046615600586\n",
      "Epoch 797: Train_loss 32159500288.0, Validation_loss 29653170176.0, Seconds 0.01807713508605957\n",
      "Epoch 798: Train_loss 32159375360.0, Validation_loss 29652992000.0, Seconds 0.02192234992980957\n",
      "Epoch 799: Train_loss 32159252480.0, Validation_loss 29652858880.0, Seconds 0.019999027252197266\n",
      "Epoch 800: Train_loss 32159141888.0, Validation_loss 29652703232.0, Seconds 0.019504547119140625\n",
      "Epoch 801: Train_loss 32159025152.0, Validation_loss 29652516864.0, Seconds 0.0830843448638916\n",
      "Epoch 802: Train_loss 32158904320.0, Validation_loss 29652344832.0, Seconds 0.022535324096679688\n",
      "Epoch 803: Train_loss 32158795776.0, Validation_loss 29652201472.0, Seconds 0.023074626922607422\n",
      "Epoch 804: Train_loss 32158672896.0, Validation_loss 29652039680.0, Seconds 0.019927978515625\n",
      "Epoch 805: Train_loss 32158552064.0, Validation_loss 29651853312.0, Seconds 0.0189971923828125\n",
      "Epoch 806: Train_loss 32158437376.0, Validation_loss 29651681280.0, Seconds 0.025014400482177734\n",
      "Epoch 807: Train_loss 32158328832.0, Validation_loss 29651550208.0, Seconds 0.019509315490722656\n",
      "Epoch 808: Train_loss 32158216192.0, Validation_loss 29651382272.0, Seconds 0.023001670837402344\n",
      "Epoch 809: Train_loss 32158097408.0, Validation_loss 29651191808.0, Seconds 0.024013519287109375\n",
      "Epoch 810: Train_loss 32157984768.0, Validation_loss 29651003392.0, Seconds 0.0229952335357666\n",
      "Epoch 811: Train_loss 32157863936.0, Validation_loss 29650821120.0, Seconds 0.018517017364501953\n",
      "Epoch 812: Train_loss 32157751296.0, Validation_loss 29650638848.0, Seconds 0.020997285842895508\n",
      "Epoch 813: Train_loss 32157616128.0, Validation_loss 29650462720.0, Seconds 0.02001047134399414\n",
      "Epoch 814: Train_loss 32157478912.0, Validation_loss 29650272256.0, Seconds 0.01699066162109375\n",
      "Epoch 815: Train_loss 32157366272.0, Validation_loss 29650089984.0, Seconds 0.019998788833618164\n",
      "Epoch 816: Train_loss 32157251584.0, Validation_loss 29649915904.0, Seconds 0.020003318786621094\n",
      "Epoch 817: Train_loss 32157128704.0, Validation_loss 29649739776.0, Seconds 0.01751565933227539\n",
      "Epoch 818: Train_loss 32157003776.0, Validation_loss 29649561600.0, Seconds 0.02599930763244629\n",
      "Epoch 819: Train_loss 32156872704.0, Validation_loss 29649403904.0, Seconds 0.0229947566986084\n",
      "Epoch 820: Train_loss 32156753920.0, Validation_loss 29649248256.0, Seconds 0.022000789642333984\n",
      "Epoch 821: Train_loss 32156639232.0, Validation_loss 29649082368.0, Seconds 0.02252030372619629\n",
      "Epoch 822: Train_loss 32156526592.0, Validation_loss 29648914432.0, Seconds 0.018997907638549805\n",
      "Epoch 823: Train_loss 32156391424.0, Validation_loss 29648730112.0, Seconds 0.01701045036315918\n",
      "Epoch 824: Train_loss 32156276736.0, Validation_loss 29648545792.0, Seconds 0.023989200592041016\n",
      "Epoch 825: Train_loss 32156178432.0, Validation_loss 29648373760.0, Seconds 0.021003007888793945\n",
      "Epoch 826: Train_loss 32156080128.0, Validation_loss 29648216064.0, Seconds 0.021585941314697266\n",
      "Epoch 827: Train_loss 32155971584.0, Validation_loss 29648056320.0, Seconds 0.0209197998046875\n",
      "Epoch 828: Train_loss 32155865088.0, Validation_loss 29647908864.0, Seconds 0.017075538635253906\n",
      "Epoch 829: Train_loss 32155760640.0, Validation_loss 29647747072.0, Seconds 0.018926143646240234\n",
      "Epoch 830: Train_loss 32155643904.0, Validation_loss 29647599616.0, Seconds 0.025155067443847656\n",
      "Epoch 831: Train_loss 32155555840.0, Validation_loss 29647460352.0, Seconds 0.022590160369873047\n",
      "Epoch 832: Train_loss 32155459584.0, Validation_loss 29647316992.0, Seconds 0.021998882293701172\n",
      "Epoch 833: Train_loss 32155359232.0, Validation_loss 29647183872.0, Seconds 0.023996829986572266\n",
      "Epoch 834: Train_loss 32155252736.0, Validation_loss 29647046656.0, Seconds 0.01900029182434082\n",
      "Epoch 835: Train_loss 32155158528.0, Validation_loss 29646915584.0, Seconds 0.02267765998840332\n",
      "Epoch 836: Train_loss 32155058176.0, Validation_loss 29646774272.0, Seconds 0.019006729125976562\n",
      "Epoch 837: Train_loss 32154959872.0, Validation_loss 29646649344.0, Seconds 0.019992351531982422\n",
      "Epoch 838: Train_loss 32154863616.0, Validation_loss 29646526464.0, Seconds 0.02107548713684082\n",
      "Epoch 839: Train_loss 32154765312.0, Validation_loss 29646393344.0, Seconds 0.021005868911743164\n",
      "Epoch 840: Train_loss 32154671104.0, Validation_loss 29646260224.0, Seconds 0.022449731826782227\n",
      "Epoch 841: Train_loss 32154585088.0, Validation_loss 29646149632.0, Seconds 0.023000240325927734\n",
      "Epoch 842: Train_loss 32154488832.0, Validation_loss 29646020608.0, Seconds 0.018997907638549805\n",
      "Epoch 843: Train_loss 32154386432.0, Validation_loss 29645883392.0, Seconds 0.01700568199157715\n",
      "Epoch 844: Train_loss 32154292224.0, Validation_loss 29645754368.0, Seconds 0.02300858497619629\n",
      "Epoch 845: Train_loss 32154200064.0, Validation_loss 29645633536.0, Seconds 0.020505189895629883\n",
      "Epoch 846: Train_loss 32154103808.0, Validation_loss 29645508608.0, Seconds 0.021996259689331055\n",
      "Epoch 847: Train_loss 32154021888.0, Validation_loss 29645389824.0, Seconds 0.022001266479492188\n",
      "Epoch 848: Train_loss 32153933824.0, Validation_loss 29645254656.0, Seconds 0.020003318786621094\n",
      "Epoch 849: Train_loss 32153843712.0, Validation_loss 29645113344.0, Seconds 0.018007516860961914\n",
      "Epoch 850: Train_loss 32153757696.0, Validation_loss 29644976128.0, Seconds 0.01851201057434082\n",
      "Epoch 851: Train_loss 32153669632.0, Validation_loss 29644847104.0, Seconds 0.01899886131286621\n",
      "Epoch 852: Train_loss 32153577472.0, Validation_loss 29644716032.0, Seconds 0.023006439208984375\n",
      "Epoch 853: Train_loss 32153487360.0, Validation_loss 29644568576.0, Seconds 0.018993139266967773\n",
      "Epoch 854: Train_loss 32153395200.0, Validation_loss 29644429312.0, Seconds 0.018001556396484375\n",
      "Epoch 855: Train_loss 32153296896.0, Validation_loss 29644302336.0, Seconds 0.01950669288635254\n",
      "Epoch 856: Train_loss 32153204736.0, Validation_loss 29644183552.0, Seconds 0.020000457763671875\n",
      "Epoch 857: Train_loss 32153116672.0, Validation_loss 29644038144.0, Seconds 0.01700115203857422\n",
      "Epoch 858: Train_loss 32153020416.0, Validation_loss 29643900928.0, Seconds 0.016925573348999023\n",
      "Epoch 859: Train_loss 32152934400.0, Validation_loss 29643786240.0, Seconds 0.01900506019592285\n",
      "Epoch 860: Train_loss 32152850432.0, Validation_loss 29643677696.0, Seconds 0.02050614356994629\n",
      "Epoch 861: Train_loss 32152748032.0, Validation_loss 29643536384.0, Seconds 0.0200040340423584\n",
      "Epoch 862: Train_loss 32152657920.0, Validation_loss 29643405312.0, Seconds 0.019993305206298828\n",
      "Epoch 863: Train_loss 32152569856.0, Validation_loss 29643282432.0, Seconds 0.01900792121887207\n",
      "Epoch 864: Train_loss 32152483840.0, Validation_loss 29643171840.0, Seconds 0.01699233055114746\n",
      "Epoch 865: Train_loss 32152389632.0, Validation_loss 29643038720.0, Seconds 0.019536256790161133\n",
      "Epoch 866: Train_loss 32152303616.0, Validation_loss 29642921984.0, Seconds 0.02202296257019043\n",
      "Epoch 867: Train_loss 32152223744.0, Validation_loss 29642799104.0, Seconds 0.01997685432434082\n",
      "Epoch 868: Train_loss 32152131584.0, Validation_loss 29642668032.0, Seconds 0.08251523971557617\n",
      "Epoch 869: Train_loss 32152039424.0, Validation_loss 29642536960.0, Seconds 0.020999908447265625\n",
      "Epoch 870: Train_loss 32151953408.0, Validation_loss 29642416128.0, Seconds 0.01799321174621582\n",
      "Epoch 871: Train_loss 32151869440.0, Validation_loss 29642270720.0, Seconds 0.023005008697509766\n",
      "Epoch 872: Train_loss 32151779328.0, Validation_loss 29642139648.0, Seconds 0.022511720657348633\n",
      "Epoch 873: Train_loss 32151693312.0, Validation_loss 29642014720.0, Seconds 0.017992019653320312\n",
      "Epoch 874: Train_loss 32151605248.0, Validation_loss 29641908224.0, Seconds 0.021999835968017578\n",
      "Epoch 875: Train_loss 32151508992.0, Validation_loss 29641787392.0, Seconds 0.01800704002380371\n",
      "Epoch 876: Train_loss 32151420928.0, Validation_loss 29641668608.0, Seconds 0.0250093936920166\n",
      "Epoch 877: Train_loss 32151328768.0, Validation_loss 29641553920.0, Seconds 0.02351236343383789\n",
      "Epoch 878: Train_loss 32151232512.0, Validation_loss 29641439232.0, Seconds 0.022993087768554688\n",
      "Epoch 879: Train_loss 32151144448.0, Validation_loss 29641304064.0, Seconds 0.02300262451171875\n",
      "Epoch 880: Train_loss 32151062528.0, Validation_loss 29641191424.0, Seconds 0.020997047424316406\n",
      "Epoch 881: Train_loss 32150982656.0, Validation_loss 29641060352.0, Seconds 0.021588563919067383\n",
      "Epoch 882: Train_loss 32150896640.0, Validation_loss 29640916992.0, Seconds 0.020933151245117188\n",
      "Epoch 883: Train_loss 32150814720.0, Validation_loss 29640783872.0, Seconds 0.019999265670776367\n",
      "Epoch 884: Train_loss 32150728704.0, Validation_loss 29640652800.0, Seconds 0.022993087768554688\n",
      "Epoch 885: Train_loss 32150640640.0, Validation_loss 29640515584.0, Seconds 0.021090984344482422\n",
      "Epoch 886: Train_loss 32150560768.0, Validation_loss 29640400896.0, Seconds 0.019502639770507812\n",
      "Epoch 887: Train_loss 32150482944.0, Validation_loss 29640271872.0, Seconds 0.02200627326965332\n",
      "Epoch 888: Train_loss 32150396928.0, Validation_loss 29640124416.0, Seconds 0.022993087768554688\n",
      "Epoch 889: Train_loss 32150308864.0, Validation_loss 29639989248.0, Seconds 0.018007278442382812\n",
      "Epoch 890: Train_loss 32150233088.0, Validation_loss 29639864320.0, Seconds 0.0189971923828125\n",
      "Epoch 891: Train_loss 32150149120.0, Validation_loss 29639749632.0, Seconds 0.02151012420654297\n",
      "Epoch 892: Train_loss 32150067200.0, Validation_loss 29639604224.0, Seconds 0.02107524871826172\n",
      "Epoch 893: Train_loss 32149981184.0, Validation_loss 29639456768.0, Seconds 0.018927335739135742\n",
      "Epoch 894: Train_loss 32149897216.0, Validation_loss 29639335936.0, Seconds 0.023070096969604492\n",
      "Epoch 895: Train_loss 32149813248.0, Validation_loss 29639217152.0, Seconds 0.023448467254638672\n",
      "Epoch 896: Train_loss 32149735424.0, Validation_loss 29639086080.0, Seconds 0.025008440017700195\n",
      "Epoch 897: Train_loss 32149653504.0, Validation_loss 29638952960.0, Seconds 0.019070148468017578\n",
      "Epoch 898: Train_loss 32149571584.0, Validation_loss 29638821888.0, Seconds 0.019936561584472656\n",
      "Epoch 899: Train_loss 32149491712.0, Validation_loss 29638696960.0, Seconds 0.018000364303588867\n",
      "Epoch 900: Train_loss 32149411840.0, Validation_loss 29638565888.0, Seconds 0.017998456954956055\n",
      "Epoch 901: Train_loss 32149329920.0, Validation_loss 29638436864.0, Seconds 0.02208089828491211\n",
      "Epoch 902: Train_loss 32149252096.0, Validation_loss 29638311936.0, Seconds 0.02100825309753418\n",
      "Epoch 903: Train_loss 32149168128.0, Validation_loss 29638187008.0, Seconds 0.018997907638549805\n",
      "Epoch 904: Train_loss 32149090304.0, Validation_loss 29638039552.0, Seconds 0.023997068405151367\n",
      "Epoch 905: Train_loss 32149008384.0, Validation_loss 29637898240.0, Seconds 0.020513057708740234\n",
      "Epoch 906: Train_loss 32148922368.0, Validation_loss 29637746688.0, Seconds 0.01900315284729004\n",
      "Epoch 907: Train_loss 32148832256.0, Validation_loss 29637613568.0, Seconds 0.01699995994567871\n",
      "Epoch 908: Train_loss 32148754432.0, Validation_loss 29637478400.0, Seconds 0.020000219345092773\n",
      "Epoch 909: Train_loss 32148668416.0, Validation_loss 29637337088.0, Seconds 0.01900005340576172\n",
      "Epoch 910: Train_loss 32148586496.0, Validation_loss 29637212160.0, Seconds 0.01700592041015625\n",
      "Epoch 911: Train_loss 32148506624.0, Validation_loss 29637089280.0, Seconds 0.01950526237487793\n",
      "Epoch 912: Train_loss 32148424704.0, Validation_loss 29636941824.0, Seconds 0.02307605743408203\n",
      "Epoch 913: Train_loss 32148342784.0, Validation_loss 29636798464.0, Seconds 0.019924640655517578\n",
      "Epoch 914: Train_loss 32148256768.0, Validation_loss 29636669440.0, Seconds 0.020001888275146484\n",
      "Epoch 915: Train_loss 32148170752.0, Validation_loss 29636540416.0, Seconds 0.02367544174194336\n",
      "Epoch 916: Train_loss 32148088832.0, Validation_loss 29636413440.0, Seconds 0.022006750106811523\n",
      "Epoch 917: Train_loss 32148011008.0, Validation_loss 29636278272.0, Seconds 0.022992849349975586\n",
      "Epoch 918: Train_loss 32147924992.0, Validation_loss 29636149248.0, Seconds 0.02100062370300293\n",
      "Epoch 919: Train_loss 32147845120.0, Validation_loss 29636016128.0, Seconds 0.022002220153808594\n",
      "Epoch 920: Train_loss 32147757056.0, Validation_loss 29635870720.0, Seconds 0.021506786346435547\n",
      "Epoch 921: Train_loss 32147675136.0, Validation_loss 29635739648.0, Seconds 0.01900649070739746\n",
      "Epoch 922: Train_loss 32147595264.0, Validation_loss 29635614720.0, Seconds 0.023000478744506836\n",
      "Epoch 923: Train_loss 32147509248.0, Validation_loss 29635489792.0, Seconds 0.02099299430847168\n",
      "Epoch 924: Train_loss 32147431424.0, Validation_loss 29635354624.0, Seconds 0.02200627326965332\n",
      "Epoch 925: Train_loss 32147339264.0, Validation_loss 29635217408.0, Seconds 0.02158331871032715\n",
      "Epoch 926: Train_loss 32147249152.0, Validation_loss 29635078144.0, Seconds 0.022931575775146484\n",
      "Epoch 927: Train_loss 32147171328.0, Validation_loss 29634940928.0, Seconds 0.025992870330810547\n",
      "Epoch 928: Train_loss 32147085312.0, Validation_loss 29634828288.0, Seconds 0.025012731552124023\n",
      "Epoch 929: Train_loss 32147003392.0, Validation_loss 29634703360.0, Seconds 0.018508434295654297\n",
      "Epoch 930: Train_loss 32146923520.0, Validation_loss 29634562048.0, Seconds 0.022000551223754883\n",
      "Epoch 931: Train_loss 32146841600.0, Validation_loss 29634435072.0, Seconds 0.01800394058227539\n",
      "Epoch 932: Train_loss 32146751488.0, Validation_loss 29634306048.0, Seconds 0.01807403564453125\n",
      "Epoch 933: Train_loss 32146673664.0, Validation_loss 29634177024.0, Seconds 0.020941495895385742\n",
      "Epoch 934: Train_loss 32146587648.0, Validation_loss 29634043904.0, Seconds 0.019215106964111328\n",
      "Epoch 935: Train_loss 32146509824.0, Validation_loss 29633908736.0, Seconds 0.01999497413635254\n",
      "Epoch 936: Train_loss 32146425856.0, Validation_loss 29633757184.0, Seconds 0.023005008697509766\n",
      "Epoch 937: Train_loss 32146341888.0, Validation_loss 29633636352.0, Seconds 0.02299976348876953\n",
      "Epoch 938: Train_loss 32146257920.0, Validation_loss 29633513472.0, Seconds 0.01999521255493164\n",
      "Epoch 939: Train_loss 32146176000.0, Validation_loss 29633382400.0, Seconds 0.02251124382019043\n",
      "Epoch 940: Train_loss 32146094080.0, Validation_loss 29633245184.0, Seconds 0.017995119094848633\n",
      "Epoch 941: Train_loss 32146014208.0, Validation_loss 29633110016.0, Seconds 0.02100205421447754\n",
      "Epoch 942: Train_loss 32145926144.0, Validation_loss 29632970752.0, Seconds 0.022073745727539062\n",
      "Epoch 943: Train_loss 32145838080.0, Validation_loss 29632837632.0, Seconds 0.019436359405517578\n",
      "Epoch 944: Train_loss 32145758208.0, Validation_loss 29632704512.0, Seconds 0.023027896881103516\n",
      "Epoch 945: Train_loss 32145672192.0, Validation_loss 29632579584.0, Seconds 0.022975444793701172\n",
      "Epoch 946: Train_loss 32145586176.0, Validation_loss 29632448512.0, Seconds 0.019000768661499023\n",
      "Epoch 947: Train_loss 32145504256.0, Validation_loss 29632317440.0, Seconds 0.01900005340576172\n",
      "Epoch 948: Train_loss 32145422336.0, Validation_loss 29632186368.0, Seconds 0.022408723831176758\n",
      "Epoch 949: Train_loss 32145340416.0, Validation_loss 29632057344.0, Seconds 0.018001079559326172\n",
      "Epoch 950: Train_loss 32145258496.0, Validation_loss 29631926272.0, Seconds 0.019073486328125\n",
      "Epoch 951: Train_loss 32145174528.0, Validation_loss 29631784960.0, Seconds 0.01792740821838379\n",
      "Epoch 952: Train_loss 32145090560.0, Validation_loss 29631655936.0, Seconds 0.018004179000854492\n",
      "Epoch 953: Train_loss 32145006592.0, Validation_loss 29631531008.0, Seconds 0.023610591888427734\n",
      "Epoch 954: Train_loss 32144924672.0, Validation_loss 29631397888.0, Seconds 0.016999006271362305\n",
      "Epoch 955: Train_loss 32144842752.0, Validation_loss 29631258624.0, Seconds 0.017998695373535156\n",
      "Epoch 956: Train_loss 32144756736.0, Validation_loss 29631123456.0, Seconds 0.017999649047851562\n",
      "Epoch 957: Train_loss 32144668672.0, Validation_loss 29630986240.0, Seconds 0.01804375648498535\n",
      "Epoch 958: Train_loss 32144586752.0, Validation_loss 29630855168.0, Seconds 0.02305150032043457\n",
      "Epoch 959: Train_loss 32144504832.0, Validation_loss 29630726144.0, Seconds 0.022075414657592773\n",
      "Epoch 960: Train_loss 32144418816.0, Validation_loss 29630601216.0, Seconds 0.020999431610107422\n",
      "Epoch 961: Train_loss 32144332800.0, Validation_loss 29630474240.0, Seconds 0.02007889747619629\n",
      "Epoch 962: Train_loss 32144244736.0, Validation_loss 29630349312.0, Seconds 0.020926952362060547\n",
      "Epoch 963: Train_loss 32144154624.0, Validation_loss 29630216192.0, Seconds 0.023511648178100586\n",
      "Epoch 964: Train_loss 32144062464.0, Validation_loss 29630095360.0, Seconds 0.023001432418823242\n",
      "Epoch 965: Train_loss 32143968256.0, Validation_loss 29629974528.0, Seconds 0.017998695373535156\n",
      "Epoch 966: Train_loss 32143874048.0, Validation_loss 29629851648.0, Seconds 0.017999887466430664\n",
      "Epoch 967: Train_loss 32143779840.0, Validation_loss 29629732864.0, Seconds 0.0169980525970459\n",
      "Epoch 968: Train_loss 32143687680.0, Validation_loss 29629601792.0, Seconds 0.018010854721069336\n",
      "Epoch 969: Train_loss 32143591424.0, Validation_loss 29629466624.0, Seconds 0.01852130889892578\n",
      "Epoch 970: Train_loss 32143503360.0, Validation_loss 29629329408.0, Seconds 0.01900196075439453\n",
      "Epoch 971: Train_loss 32143417344.0, Validation_loss 29629188096.0, Seconds 0.017997264862060547\n",
      "Epoch 972: Train_loss 32143329280.0, Validation_loss 29629057024.0, Seconds 0.019079923629760742\n",
      "Epoch 973: Train_loss 32143245312.0, Validation_loss 29628921856.0, Seconds 0.021932125091552734\n",
      "Epoch 974: Train_loss 32143153152.0, Validation_loss 29628770304.0, Seconds 0.021506309509277344\n",
      "Epoch 975: Train_loss 32143065088.0, Validation_loss 29628618752.0, Seconds 0.019002199172973633\n",
      "Epoch 976: Train_loss 32142979072.0, Validation_loss 29628491776.0, Seconds 0.021997451782226562\n",
      "Epoch 977: Train_loss 32142891008.0, Validation_loss 29628368896.0, Seconds 0.023000717163085938\n",
      "Epoch 978: Train_loss 32142798848.0, Validation_loss 29628258304.0, Seconds 0.020542383193969727\n",
      "Epoch 979: Train_loss 32142702592.0, Validation_loss 29628135424.0, Seconds 0.01699972152709961\n",
      "Epoch 980: Train_loss 32142608384.0, Validation_loss 29628030976.0, Seconds 0.02300715446472168\n",
      "Epoch 981: Train_loss 32142512128.0, Validation_loss 29627910144.0, Seconds 0.02199387550354004\n",
      "Epoch 982: Train_loss 32142415872.0, Validation_loss 29627770880.0, Seconds 0.02600407600402832\n",
      "Epoch 983: Train_loss 32142321664.0, Validation_loss 29627639808.0, Seconds 0.018532991409301758\n",
      "Epoch 984: Train_loss 32142225408.0, Validation_loss 29627521024.0, Seconds 0.01999831199645996\n",
      "Epoch 985: Train_loss 32142133248.0, Validation_loss 29627389952.0, Seconds 0.02200174331665039\n",
      "Epoch 986: Train_loss 32142045184.0, Validation_loss 29627260928.0, Seconds 0.02200031280517578\n",
      "Epoch 987: Train_loss 32141955072.0, Validation_loss 29627136000.0, Seconds 0.017000436782836914\n",
      "Epoch 988: Train_loss 32141860864.0, Validation_loss 29627019264.0, Seconds 0.018514633178710938\n",
      "Epoch 989: Train_loss 32141754368.0, Validation_loss 29626851328.0, Seconds 0.01999187469482422\n",
      "Epoch 990: Train_loss 32141649920.0, Validation_loss 29626703872.0, Seconds 0.017073392868041992\n",
      "Epoch 991: Train_loss 32141551616.0, Validation_loss 29626546176.0, Seconds 0.017931222915649414\n",
      "Epoch 992: Train_loss 32141451264.0, Validation_loss 29626361856.0, Seconds 0.01699995994567871\n",
      "Epoch 993: Train_loss 32141340672.0, Validation_loss 29626179584.0, Seconds 0.01700735092163086\n",
      "Epoch 994: Train_loss 32141221888.0, Validation_loss 29625982976.0, Seconds 0.018511533737182617\n",
      "Epoch 995: Train_loss 32141107200.0, Validation_loss 29625798656.0, Seconds 0.01800084114074707\n",
      "Epoch 996: Train_loss 32141000704.0, Validation_loss 29625608192.0, Seconds 0.020000219345092773\n",
      "Epoch 997: Train_loss 32140892160.0, Validation_loss 29625444352.0, Seconds 0.021001577377319336\n",
      "Epoch 998: Train_loss 32140793856.0, Validation_loss 29625270272.0, Seconds 0.01805710792541504\n",
      "Epoch 999: Train_loss 32140695552.0, Validation_loss 29625118720.0, Seconds 0.016452789306640625\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).view(-1, 1)\n",
    "        output = net(data)\n",
    "        L = loss(output, target)\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    y_train_pred = net(X_train)\n",
    "    training_loss = loss(y_train_pred, y_train.view(-1, 1)).item()\n",
    "    y_test_pred = net(X_test)\n",
    "    test_loss = loss(y_test_pred, y_test.view(-1, 1)).item()\n",
    "    \n",
    "    train_losses.append(training_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Epoch {}: Train_loss {}, Validation_loss {}, Seconds {}\".format(epoch, training_loss, test_loss, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ecd838e2d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(test_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss values\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = net(X_train)\n",
    "y_test_pred = net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.14e+05\n",
      "train MSE: 3.21e+10\n",
      "train R2: 0.344\n"
     ]
    }
   ],
   "source": [
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred.detach().numpy())))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred.detach().numpy())))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 1.10e+05\n",
      "test MSE: 2.96e+10\n",
      "test R2: 0.370\n"
     ]
    }
   ],
   "source": [
    "print('test MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred.detach().numpy())))\n",
    "print('test MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred.detach().numpy())))\n",
    "print('test R2: {0:.3f}'.format(r2_score(y_test, y_test_pred.detach().numpy())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
