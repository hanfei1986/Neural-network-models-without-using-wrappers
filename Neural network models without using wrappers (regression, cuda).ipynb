{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2.csv')\n",
    "df.dropna(subset=['price'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "target = 'price'\n",
    "features.remove(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target].str.strip(\"$\").str.replace(\",\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "class Data_Transformer(object):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        self.mean_weight = new_df[\"Weight\"].mean() # obtain mean weight\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase weekday\n",
    "        self.majority_month = new_df[\"Month\"].mode()[0] # obtain majority purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        self.majority_weekday = new_df[\"Weekday\"].mode()[0] # obtain majority purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df[\"Ingredient Number\"] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        self.mean_ingredient_number = new_df[\"Ingredient Number\"].mean() # obtain mean ingredient number\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with median ingredient number\n",
    "        self.pl_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Level\"] = pd.Series(self.pl_le.fit_transform(X[\"product_level\"])) # fit and transform product level with label-encoder\n",
    "        self.majority_product_level = new_df[\"Product Level\"].mode()[0] # obtain majority product level code\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        self.pt_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Type\"] = pd.Series(self.pt_le.fit_transform(X[\"product_type\"])) # fit and transform product type with label-encoder\n",
    "        self.majority_product_type = new_df[\"Product Type\"].mode()[0] # obtain majority product type code\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        self.cost_imputer = XGBRegressor() # create a XGBoost imputer for cost\n",
    "        df_for_imputing_cost = new_df.dropna() # create training data for cost imputer by dropping missing data\n",
    "        self.cost_imputer.fit(df_for_imputing_cost[[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]], df_for_imputing_cost[\"Cost\"]) # fit cost imputer\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df['Ingredient Number'] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with mean ingredient number\n",
    "        new_df[\"Product Level\"] = self.pl_le.transform(X[\"product_level\"]) # transform product level with label-encoder\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        new_df[\"Product Type\"] = self.pt_le.transform(X[\"product_type\"]) # transform product type with label-encoder\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        imputed_cost = pd.Series(self.cost_imputer.predict(new_df[new_df[\"Cost\"].isnull()][[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]])) # obtain imputed cost\n",
    "        imputed_cost.index = new_df[new_df[\"Cost\"].isnull()][\"Cost\"].index # set index of imputed cost\n",
    "        new_df[\"Cost\"].fillna(imputed_cost,inplace=True) # fill in missing cost with imputed cost\n",
    "        return new_df # return new_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def weight2num(self, x): # function to convert weight to number\n",
    "        if type(x) == str:\n",
    "            x = x.strip('Kg').split(' Ton ')\n",
    "            return float(x[0])*1000+float(x[1])\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def get_numbers(self, x): # function to get number of ingredients in recipe\n",
    "        if type(x) == str:\n",
    "            return len(x.split(','))\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('dtf', Data_Transformer()),\n",
    "        ('scaler', MinMaxScaler())]\n",
    "preproc = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc.fit_transform(X_train)\n",
    "X_test = preproc.transform(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = nn.Sequential(nn.Linear(7, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "batch_size = 200\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSELoss(reduction='mean')\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train_loss 80528424960.0, Validation_loss 87072890880.0, Seconds 1.2260339260101318\n",
      "Epoch 1: Train_loss 80385376256.0, Validation_loss 86924328960.0, Seconds 0.03337240219116211\n",
      "Epoch 2: Train_loss 79545524224.0, Validation_loss 86050217984.0, Seconds 0.03604936599731445\n",
      "Epoch 3: Train_loss 76399493120.0, Validation_loss 82770198528.0, Seconds 0.034689903259277344\n",
      "Epoch 4: Train_loss 68215517184.0, Validation_loss 74207076352.0, Seconds 0.03524589538574219\n",
      "Epoch 5: Train_loss 54648594432.0, Validation_loss 59842895872.0, Seconds 0.035953521728515625\n",
      "Epoch 6: Train_loss 47301103616.0, Validation_loss 51484762112.0, Seconds 0.03769946098327637\n",
      "Epoch 7: Train_loss 46843142144.0, Validation_loss 50864091136.0, Seconds 0.04118490219116211\n",
      "Epoch 8: Train_loss 45898461184.0, Validation_loss 50138230784.0, Seconds 0.04015970230102539\n",
      "Epoch 9: Train_loss 45141229568.0, Validation_loss 49314312192.0, Seconds 0.036699533462524414\n",
      "Epoch 10: Train_loss 44379365376.0, Validation_loss 48447111168.0, Seconds 0.031963348388671875\n",
      "Epoch 11: Train_loss 43622428672.0, Validation_loss 47665819648.0, Seconds 0.03634214401245117\n",
      "Epoch 12: Train_loss 42831101952.0, Validation_loss 46835994624.0, Seconds 0.03297615051269531\n",
      "Epoch 13: Train_loss 41980104704.0, Validation_loss 45917396992.0, Seconds 0.03790616989135742\n",
      "Epoch 14: Train_loss 41065529344.0, Validation_loss 44932091904.0, Seconds 0.036185264587402344\n",
      "Epoch 15: Train_loss 40072458240.0, Validation_loss 43856990208.0, Seconds 0.029825925827026367\n",
      "Epoch 16: Train_loss 38988292096.0, Validation_loss 42668167168.0, Seconds 0.03304266929626465\n",
      "Epoch 17: Train_loss 37811638272.0, Validation_loss 41361502208.0, Seconds 0.034857988357543945\n",
      "Epoch 18: Train_loss 36557529088.0, Validation_loss 39944900608.0, Seconds 0.03331136703491211\n",
      "Epoch 19: Train_loss 35269865472.0, Validation_loss 38452482048.0, Seconds 0.03462409973144531\n",
      "Epoch 20: Train_loss 34031837184.0, Validation_loss 36961325056.0, Seconds 0.040909767150878906\n",
      "Epoch 21: Train_loss 32947128320.0, Validation_loss 35578019840.0, Seconds 0.0391845703125\n",
      "Epoch 22: Train_loss 32088678400.0, Validation_loss 34396291072.0, Seconds 0.03722715377807617\n",
      "Epoch 23: Train_loss 31453892608.0, Validation_loss 33443690496.0, Seconds 0.03976559638977051\n",
      "Epoch 24: Train_loss 30979176448.0, Validation_loss 32684402688.0, Seconds 0.03442692756652832\n",
      "Epoch 25: Train_loss 30596892672.0, Validation_loss 32056709120.0, Seconds 0.03586697578430176\n",
      "Epoch 26: Train_loss 30261495808.0, Validation_loss 31519987712.0, Seconds 0.03896808624267578\n",
      "Epoch 27: Train_loss 29954541568.0, Validation_loss 31039031296.0, Seconds 0.043042898178100586\n",
      "Epoch 28: Train_loss 29681840128.0, Validation_loss 30597742592.0, Seconds 0.03654956817626953\n",
      "Epoch 29: Train_loss 29446430720.0, Validation_loss 30205992960.0, Seconds 0.03899860382080078\n",
      "Epoch 30: Train_loss 29250721792.0, Validation_loss 29866618880.0, Seconds 0.03838300704956055\n",
      "Epoch 31: Train_loss 29085009920.0, Validation_loss 29570170880.0, Seconds 0.04002714157104492\n",
      "Epoch 32: Train_loss 28944652288.0, Validation_loss 29307494400.0, Seconds 0.041821956634521484\n",
      "Epoch 33: Train_loss 28824903680.0, Validation_loss 29078720512.0, Seconds 0.04076266288757324\n",
      "Epoch 34: Train_loss 28724889600.0, Validation_loss 28875382784.0, Seconds 0.03795194625854492\n",
      "Epoch 35: Train_loss 28641703936.0, Validation_loss 28701634560.0, Seconds 0.04442739486694336\n",
      "Epoch 36: Train_loss 28572913664.0, Validation_loss 28554213376.0, Seconds 0.042545318603515625\n",
      "Epoch 37: Train_loss 28516270080.0, Validation_loss 28432979968.0, Seconds 0.03966045379638672\n",
      "Epoch 38: Train_loss 28470695936.0, Validation_loss 28329080832.0, Seconds 0.03657102584838867\n",
      "Epoch 39: Train_loss 28434161664.0, Validation_loss 28240922624.0, Seconds 0.030934810638427734\n",
      "Epoch 40: Train_loss 28403478528.0, Validation_loss 28167626752.0, Seconds 0.035874128341674805\n",
      "Epoch 41: Train_loss 28377251840.0, Validation_loss 28103186432.0, Seconds 0.043276071548461914\n",
      "Epoch 42: Train_loss 28354904064.0, Validation_loss 28048926720.0, Seconds 0.0337677001953125\n",
      "Epoch 43: Train_loss 28335368192.0, Validation_loss 28001429504.0, Seconds 0.034943342208862305\n",
      "Epoch 44: Train_loss 28317224960.0, Validation_loss 27958992896.0, Seconds 0.05037093162536621\n",
      "Epoch 45: Train_loss 28301228032.0, Validation_loss 27921592320.0, Seconds 0.04079008102416992\n",
      "Epoch 46: Train_loss 28287479808.0, Validation_loss 27888939008.0, Seconds 0.042008161544799805\n",
      "Epoch 47: Train_loss 28275759104.0, Validation_loss 27860817920.0, Seconds 0.03704023361206055\n",
      "Epoch 48: Train_loss 28265574400.0, Validation_loss 27836428288.0, Seconds 0.034002065658569336\n",
      "Epoch 49: Train_loss 28256104448.0, Validation_loss 27816570880.0, Seconds 0.035086870193481445\n",
      "Epoch 50: Train_loss 28247558144.0, Validation_loss 27798659072.0, Seconds 0.03824901580810547\n",
      "Epoch 51: Train_loss 28240056320.0, Validation_loss 27782369280.0, Seconds 0.036691904067993164\n",
      "Epoch 52: Train_loss 28233289728.0, Validation_loss 27768489984.0, Seconds 0.037091970443725586\n",
      "Epoch 53: Train_loss 28226576384.0, Validation_loss 27755714560.0, Seconds 0.03553032875061035\n",
      "Epoch 54: Train_loss 28219789312.0, Validation_loss 27742894080.0, Seconds 0.03326416015625\n",
      "Epoch 55: Train_loss 28213581824.0, Validation_loss 27730407424.0, Seconds 0.03223061561584473\n",
      "Epoch 56: Train_loss 28208058368.0, Validation_loss 27719372800.0, Seconds 0.03593778610229492\n",
      "Epoch 57: Train_loss 28202579968.0, Validation_loss 27709020160.0, Seconds 0.04382157325744629\n",
      "Epoch 58: Train_loss 28196911104.0, Validation_loss 27699091456.0, Seconds 0.052617549896240234\n",
      "Epoch 59: Train_loss 28191141888.0, Validation_loss 27690610688.0, Seconds 0.03673052787780762\n",
      "Epoch 60: Train_loss 28185466880.0, Validation_loss 27682064384.0, Seconds 0.03399968147277832\n",
      "Epoch 61: Train_loss 28179902464.0, Validation_loss 27672655872.0, Seconds 0.035800933837890625\n",
      "Epoch 62: Train_loss 28175144960.0, Validation_loss 27663831040.0, Seconds 0.032953500747680664\n",
      "Epoch 63: Train_loss 28171026432.0, Validation_loss 27656833024.0, Seconds 0.03624224662780762\n",
      "Epoch 64: Train_loss 28167352320.0, Validation_loss 27651657728.0, Seconds 0.039836883544921875\n",
      "Epoch 65: Train_loss 28164007936.0, Validation_loss 27647195136.0, Seconds 0.038126468658447266\n",
      "Epoch 66: Train_loss 28161038336.0, Validation_loss 27643000832.0, Seconds 0.035805702209472656\n",
      "Epoch 67: Train_loss 28158173184.0, Validation_loss 27638900736.0, Seconds 0.03795909881591797\n",
      "Epoch 68: Train_loss 28155314176.0, Validation_loss 27634296832.0, Seconds 0.03303408622741699\n",
      "Epoch 69: Train_loss 28152528896.0, Validation_loss 27631226880.0, Seconds 0.031842947006225586\n",
      "Epoch 70: Train_loss 28149776384.0, Validation_loss 27628722176.0, Seconds 0.03630948066711426\n",
      "Epoch 71: Train_loss 28147144704.0, Validation_loss 27626625024.0, Seconds 0.033832550048828125\n",
      "Epoch 72: Train_loss 28144635904.0, Validation_loss 27624202240.0, Seconds 0.03579592704772949\n",
      "Epoch 73: Train_loss 28142153728.0, Validation_loss 27621634048.0, Seconds 0.03464698791503906\n",
      "Epoch 74: Train_loss 28139632640.0, Validation_loss 27619373056.0, Seconds 0.03565645217895508\n",
      "Epoch 75: Train_loss 28137177088.0, Validation_loss 27617443840.0, Seconds 0.03675556182861328\n",
      "Epoch 76: Train_loss 28134805504.0, Validation_loss 27615858688.0, Seconds 0.03434634208679199\n",
      "Epoch 77: Train_loss 28132376576.0, Validation_loss 27613689856.0, Seconds 0.03214073181152344\n",
      "Epoch 78: Train_loss 28129992704.0, Validation_loss 27611832320.0, Seconds 0.031836748123168945\n",
      "Epoch 79: Train_loss 28127496192.0, Validation_loss 27609978880.0, Seconds 0.033843040466308594\n",
      "Epoch 80: Train_loss 28125110272.0, Validation_loss 27608190976.0, Seconds 0.03335165977478027\n",
      "Epoch 81: Train_loss 28122748928.0, Validation_loss 27606269952.0, Seconds 0.03374934196472168\n",
      "Epoch 82: Train_loss 28120465408.0, Validation_loss 27604713472.0, Seconds 0.03470134735107422\n",
      "Epoch 83: Train_loss 28118278144.0, Validation_loss 27603443712.0, Seconds 0.032273292541503906\n",
      "Epoch 84: Train_loss 28116172800.0, Validation_loss 27601649664.0, Seconds 0.0330350399017334\n",
      "Epoch 85: Train_loss 28114130944.0, Validation_loss 27599568896.0, Seconds 0.03272438049316406\n",
      "Epoch 86: Train_loss 28112197632.0, Validation_loss 27598141440.0, Seconds 0.033097267150878906\n",
      "Epoch 87: Train_loss 28110180352.0, Validation_loss 27595397120.0, Seconds 0.0339200496673584\n",
      "Epoch 88: Train_loss 28108115968.0, Validation_loss 27592925184.0, Seconds 0.03404092788696289\n",
      "Epoch 89: Train_loss 28106147840.0, Validation_loss 27591473152.0, Seconds 0.03424835205078125\n",
      "Epoch 90: Train_loss 28103948288.0, Validation_loss 27588960256.0, Seconds 0.030635595321655273\n",
      "Epoch 91: Train_loss 28101715968.0, Validation_loss 27586238464.0, Seconds 0.0349884033203125\n",
      "Epoch 92: Train_loss 28099420160.0, Validation_loss 27584417792.0, Seconds 0.03303194046020508\n",
      "Epoch 93: Train_loss 28097222656.0, Validation_loss 27583580160.0, Seconds 0.0331878662109375\n",
      "Epoch 94: Train_loss 28094865408.0, Validation_loss 27582150656.0, Seconds 0.035050392150878906\n",
      "Epoch 95: Train_loss 28092428288.0, Validation_loss 27580512256.0, Seconds 0.0352482795715332\n",
      "Epoch 96: Train_loss 28089952256.0, Validation_loss 27578402816.0, Seconds 0.038763999938964844\n",
      "Epoch 97: Train_loss 28087275520.0, Validation_loss 27575463936.0, Seconds 0.03508901596069336\n",
      "Epoch 98: Train_loss 28084869120.0, Validation_loss 27571374080.0, Seconds 0.03464460372924805\n",
      "Epoch 99: Train_loss 28082663424.0, Validation_loss 27568048128.0, Seconds 0.03409385681152344\n",
      "Epoch 100: Train_loss 28080480256.0, Validation_loss 27565150208.0, Seconds 0.03357720375061035\n",
      "Epoch 101: Train_loss 28078524416.0, Validation_loss 27563327488.0, Seconds 0.03576302528381348\n",
      "Epoch 102: Train_loss 28076556288.0, Validation_loss 27560744960.0, Seconds 0.03574109077453613\n",
      "Epoch 103: Train_loss 28074801152.0, Validation_loss 27558582272.0, Seconds 0.03890490531921387\n",
      "Epoch 104: Train_loss 28073132032.0, Validation_loss 27557068800.0, Seconds 0.03920149803161621\n",
      "Epoch 105: Train_loss 28071436288.0, Validation_loss 27555063808.0, Seconds 0.033753395080566406\n",
      "Epoch 106: Train_loss 28069646336.0, Validation_loss 27552112640.0, Seconds 0.03496742248535156\n",
      "Epoch 107: Train_loss 28068016128.0, Validation_loss 27550660608.0, Seconds 0.03636813163757324\n",
      "Epoch 108: Train_loss 28066166784.0, Validation_loss 27547805696.0, Seconds 0.03624081611633301\n",
      "Epoch 109: Train_loss 28064141312.0, Validation_loss 27544336384.0, Seconds 0.03426408767700195\n",
      "Epoch 110: Train_loss 28062015488.0, Validation_loss 27541245952.0, Seconds 0.03334689140319824\n",
      "Epoch 111: Train_loss 28059920384.0, Validation_loss 27538601984.0, Seconds 0.03227376937866211\n",
      "Epoch 112: Train_loss 28057845760.0, Validation_loss 27535517696.0, Seconds 0.033879756927490234\n",
      "Epoch 113: Train_loss 28055871488.0, Validation_loss 27532402688.0, Seconds 0.03369784355163574\n",
      "Epoch 114: Train_loss 28053903360.0, Validation_loss 27528939520.0, Seconds 0.033242225646972656\n",
      "Epoch 115: Train_loss 28051986432.0, Validation_loss 27526285312.0, Seconds 0.03400468826293945\n",
      "Epoch 116: Train_loss 28049997824.0, Validation_loss 27522992128.0, Seconds 0.037795066833496094\n",
      "Epoch 117: Train_loss 28048111616.0, Validation_loss 27520206848.0, Seconds 0.0332493782043457\n",
      "Epoch 118: Train_loss 28046204928.0, Validation_loss 27517376512.0, Seconds 0.032842397689819336\n",
      "Epoch 119: Train_loss 28044269568.0, Validation_loss 27514478592.0, Seconds 0.03599238395690918\n",
      "Epoch 120: Train_loss 28042377216.0, Validation_loss 27512029184.0, Seconds 0.03347659111022949\n",
      "Epoch 121: Train_loss 28040499200.0, Validation_loss 27509643264.0, Seconds 0.030702590942382812\n",
      "Epoch 122: Train_loss 28038742016.0, Validation_loss 27507615744.0, Seconds 0.032671451568603516\n",
      "Epoch 123: Train_loss 28036866048.0, Validation_loss 27504709632.0, Seconds 0.03505825996398926\n",
      "Epoch 124: Train_loss 28035133440.0, Validation_loss 27502966784.0, Seconds 0.033272743225097656\n",
      "Epoch 125: Train_loss 28033409024.0, Validation_loss 27501129728.0, Seconds 0.03272676467895508\n",
      "Epoch 126: Train_loss 28031637504.0, Validation_loss 27499030528.0, Seconds 0.03593158721923828\n",
      "Epoch 127: Train_loss 28029964288.0, Validation_loss 27497230336.0, Seconds 0.03570723533630371\n",
      "Epoch 128: Train_loss 28028235776.0, Validation_loss 27495075840.0, Seconds 0.03439068794250488\n",
      "Epoch 129: Train_loss 28026458112.0, Validation_loss 27492610048.0, Seconds 0.03292655944824219\n",
      "Epoch 130: Train_loss 28024641536.0, Validation_loss 27489951744.0, Seconds 0.03620743751525879\n",
      "Epoch 131: Train_loss 28022913024.0, Validation_loss 27487721472.0, Seconds 0.031204700469970703\n",
      "Epoch 132: Train_loss 28021151744.0, Validation_loss 27484811264.0, Seconds 0.033527374267578125\n",
      "Epoch 133: Train_loss 28019400704.0, Validation_loss 27482542080.0, Seconds 0.03605175018310547\n",
      "Epoch 134: Train_loss 28017641472.0, Validation_loss 27479734272.0, Seconds 0.03522801399230957\n",
      "Epoch 135: Train_loss 28016005120.0, Validation_loss 27476854784.0, Seconds 0.03982949256896973\n",
      "Epoch 136: Train_loss 28014477312.0, Validation_loss 27474853888.0, Seconds 0.03987431526184082\n",
      "Epoch 137: Train_loss 28012855296.0, Validation_loss 27472240640.0, Seconds 0.04537367820739746\n",
      "Epoch 138: Train_loss 28011347968.0, Validation_loss 27470770176.0, Seconds 0.0628972053527832\n",
      "Epoch 139: Train_loss 28009746432.0, Validation_loss 27468785664.0, Seconds 0.06841850280761719\n",
      "Epoch 140: Train_loss 28008169472.0, Validation_loss 27467569152.0, Seconds 0.05836176872253418\n",
      "Epoch 141: Train_loss 28006600704.0, Validation_loss 27466184704.0, Seconds 0.04347491264343262\n",
      "Epoch 142: Train_loss 28005081088.0, Validation_loss 27464867840.0, Seconds 0.03965139389038086\n",
      "Epoch 143: Train_loss 28003584000.0, Validation_loss 27463573504.0, Seconds 0.04095959663391113\n",
      "Epoch 144: Train_loss 28001888256.0, Validation_loss 27461439488.0, Seconds 0.04024767875671387\n",
      "Epoch 145: Train_loss 28000337920.0, Validation_loss 27460270080.0, Seconds 0.04005146026611328\n",
      "Epoch 146: Train_loss 27998740480.0, Validation_loss 27458299904.0, Seconds 0.04168057441711426\n",
      "Epoch 147: Train_loss 27997085696.0, Validation_loss 27455735808.0, Seconds 0.03914213180541992\n",
      "Epoch 148: Train_loss 27995498496.0, Validation_loss 27453870080.0, Seconds 0.03906583786010742\n",
      "Epoch 149: Train_loss 27993851904.0, Validation_loss 27451879424.0, Seconds 0.03754878044128418\n",
      "Epoch 150: Train_loss 27992156160.0, Validation_loss 27449559040.0, Seconds 0.03665900230407715\n",
      "Epoch 151: Train_loss 27990460416.0, Validation_loss 27447531520.0, Seconds 0.038527727127075195\n",
      "Epoch 152: Train_loss 27988731904.0, Validation_loss 27445760000.0, Seconds 0.038413047790527344\n",
      "Epoch 153: Train_loss 27986987008.0, Validation_loss 27443922944.0, Seconds 0.03767728805541992\n",
      "Epoch 154: Train_loss 27985209344.0, Validation_loss 27441891328.0, Seconds 0.039025306701660156\n",
      "Epoch 155: Train_loss 27983355904.0, Validation_loss 27439800320.0, Seconds 0.03845977783203125\n",
      "Epoch 156: Train_loss 27981451264.0, Validation_loss 27437529088.0, Seconds 0.0364222526550293\n",
      "Epoch 157: Train_loss 27979474944.0, Validation_loss 27434878976.0, Seconds 0.04127097129821777\n",
      "Epoch 158: Train_loss 27977465856.0, Validation_loss 27432519680.0, Seconds 0.044814348220825195\n",
      "Epoch 159: Train_loss 27975356416.0, Validation_loss 27429943296.0, Seconds 0.04035067558288574\n",
      "Epoch 160: Train_loss 27973150720.0, Validation_loss 27426994176.0, Seconds 0.0405430793762207\n",
      "Epoch 161: Train_loss 27970998272.0, Validation_loss 27423696896.0, Seconds 0.03510308265686035\n",
      "Epoch 162: Train_loss 27969042432.0, Validation_loss 27420862464.0, Seconds 0.03908991813659668\n",
      "Epoch 163: Train_loss 27967076352.0, Validation_loss 27418490880.0, Seconds 0.04076838493347168\n",
      "Epoch 164: Train_loss 27965077504.0, Validation_loss 27417896960.0, Seconds 0.03542470932006836\n",
      "Epoch 165: Train_loss 27962697728.0, Validation_loss 27416096768.0, Seconds 0.04272890090942383\n",
      "Epoch 166: Train_loss 27960350720.0, Validation_loss 27415851008.0, Seconds 0.03585386276245117\n",
      "Epoch 167: Train_loss 27957653504.0, Validation_loss 27414130688.0, Seconds 0.03455972671508789\n",
      "Epoch 168: Train_loss 27954423808.0, Validation_loss 27411724288.0, Seconds 0.03575921058654785\n",
      "Epoch 169: Train_loss 27950796800.0, Validation_loss 27408676864.0, Seconds 0.03589582443237305\n",
      "Epoch 170: Train_loss 27947335680.0, Validation_loss 27405832192.0, Seconds 0.03986477851867676\n",
      "Epoch 171: Train_loss 27943895040.0, Validation_loss 27403077632.0, Seconds 0.15923166275024414\n",
      "Epoch 172: Train_loss 27940403200.0, Validation_loss 27399051264.0, Seconds 0.0315096378326416\n",
      "Epoch 173: Train_loss 27936995328.0, Validation_loss 27396325376.0, Seconds 0.032564401626586914\n",
      "Epoch 174: Train_loss 27933499392.0, Validation_loss 27392401408.0, Seconds 0.03697061538696289\n",
      "Epoch 175: Train_loss 27930171392.0, Validation_loss 27388491776.0, Seconds 0.039530277252197266\n",
      "Epoch 176: Train_loss 27926884352.0, Validation_loss 27385071616.0, Seconds 0.03565168380737305\n",
      "Epoch 177: Train_loss 27923177472.0, Validation_loss 27380836352.0, Seconds 0.03698563575744629\n",
      "Epoch 178: Train_loss 27919079424.0, Validation_loss 27377012736.0, Seconds 0.033568620681762695\n",
      "Epoch 179: Train_loss 27914805248.0, Validation_loss 27371685888.0, Seconds 0.03611278533935547\n",
      "Epoch 180: Train_loss 27910727680.0, Validation_loss 27367553024.0, Seconds 0.03387260437011719\n",
      "Epoch 181: Train_loss 27906725888.0, Validation_loss 27361914880.0, Seconds 0.03305697441101074\n",
      "Epoch 182: Train_loss 27902840832.0, Validation_loss 27357374464.0, Seconds 0.03303718566894531\n",
      "Epoch 183: Train_loss 27898914816.0, Validation_loss 27353020416.0, Seconds 0.03400611877441406\n",
      "Epoch 184: Train_loss 27894927360.0, Validation_loss 27348944896.0, Seconds 0.03606820106506348\n",
      "Epoch 185: Train_loss 27891005440.0, Validation_loss 27345704960.0, Seconds 0.03745865821838379\n",
      "Epoch 186: Train_loss 27887206400.0, Validation_loss 27341264896.0, Seconds 0.036562442779541016\n",
      "Epoch 187: Train_loss 27883440128.0, Validation_loss 27336474624.0, Seconds 0.03520464897155762\n",
      "Epoch 188: Train_loss 27879755776.0, Validation_loss 27332937728.0, Seconds 0.034986019134521484\n",
      "Epoch 189: Train_loss 27875688448.0, Validation_loss 27329122304.0, Seconds 0.03140878677368164\n",
      "Epoch 190: Train_loss 27871182848.0, Validation_loss 27323836416.0, Seconds 0.03737020492553711\n",
      "Epoch 191: Train_loss 27866802176.0, Validation_loss 27318437888.0, Seconds 0.03278398513793945\n",
      "Epoch 192: Train_loss 27862511616.0, Validation_loss 27312705536.0, Seconds 0.034412384033203125\n",
      "Epoch 193: Train_loss 27858100224.0, Validation_loss 27308034048.0, Seconds 0.03203439712524414\n",
      "Epoch 194: Train_loss 27853737984.0, Validation_loss 27303647232.0, Seconds 0.03422188758850098\n",
      "Epoch 195: Train_loss 27849310208.0, Validation_loss 27298764800.0, Seconds 0.038338422775268555\n",
      "Epoch 196: Train_loss 27844941824.0, Validation_loss 27294988288.0, Seconds 0.03730344772338867\n",
      "Epoch 197: Train_loss 27840606208.0, Validation_loss 27291705344.0, Seconds 0.038604736328125\n",
      "Epoch 198: Train_loss 27836286976.0, Validation_loss 27288758272.0, Seconds 0.03963828086853027\n",
      "Epoch 199: Train_loss 27831949312.0, Validation_loss 27285661696.0, Seconds 0.03854036331176758\n",
      "Epoch 200: Train_loss 27827578880.0, Validation_loss 27282606080.0, Seconds 0.03455328941345215\n",
      "Epoch 201: Train_loss 27823124480.0, Validation_loss 27278901248.0, Seconds 0.030617237091064453\n",
      "Epoch 202: Train_loss 27818721280.0, Validation_loss 27275638784.0, Seconds 0.032680511474609375\n",
      "Epoch 203: Train_loss 27814389760.0, Validation_loss 27273422848.0, Seconds 0.03559446334838867\n",
      "Epoch 204: Train_loss 27809914880.0, Validation_loss 27270019072.0, Seconds 0.03555941581726074\n",
      "Epoch 205: Train_loss 27805642752.0, Validation_loss 27267997696.0, Seconds 0.03588747978210449\n",
      "Epoch 206: Train_loss 27801460736.0, Validation_loss 27265677312.0, Seconds 0.03629136085510254\n",
      "Epoch 207: Train_loss 27797397504.0, Validation_loss 27263010816.0, Seconds 0.0339202880859375\n",
      "Epoch 208: Train_loss 27793223680.0, Validation_loss 27259148288.0, Seconds 0.03194904327392578\n",
      "Epoch 209: Train_loss 27789148160.0, Validation_loss 27257018368.0, Seconds 0.03515172004699707\n",
      "Epoch 210: Train_loss 27784906752.0, Validation_loss 27254497280.0, Seconds 0.03936648368835449\n",
      "Epoch 211: Train_loss 27780663296.0, Validation_loss 27252862976.0, Seconds 0.03953814506530762\n",
      "Epoch 212: Train_loss 27776137216.0, Validation_loss 27251425280.0, Seconds 0.03900933265686035\n",
      "Epoch 213: Train_loss 27771564032.0, Validation_loss 27248672768.0, Seconds 0.03207230567932129\n",
      "Epoch 214: Train_loss 27766888448.0, Validation_loss 27246518272.0, Seconds 0.03414630889892578\n",
      "Epoch 215: Train_loss 27761983488.0, Validation_loss 27243255808.0, Seconds 0.036055564880371094\n",
      "Epoch 216: Train_loss 27756857344.0, Validation_loss 27239473152.0, Seconds 0.035512685775756836\n",
      "Epoch 217: Train_loss 27751360512.0, Validation_loss 27236272128.0, Seconds 0.03610944747924805\n",
      "Epoch 218: Train_loss 27745427456.0, Validation_loss 27232593920.0, Seconds 0.038332462310791016\n",
      "Epoch 219: Train_loss 27739895808.0, Validation_loss 27228866560.0, Seconds 0.032581329345703125\n",
      "Epoch 220: Train_loss 27734382592.0, Validation_loss 27224834048.0, Seconds 0.03238868713378906\n",
      "Epoch 221: Train_loss 27728887808.0, Validation_loss 27221524480.0, Seconds 0.03707242012023926\n",
      "Epoch 222: Train_loss 27723649024.0, Validation_loss 27217752064.0, Seconds 0.03671884536743164\n",
      "Epoch 223: Train_loss 27718647808.0, Validation_loss 27214620672.0, Seconds 0.0372314453125\n",
      "Epoch 224: Train_loss 27713748992.0, Validation_loss 27211749376.0, Seconds 0.03988337516784668\n",
      "Epoch 225: Train_loss 27708686336.0, Validation_loss 27207852032.0, Seconds 0.03375864028930664\n",
      "Epoch 226: Train_loss 27703762944.0, Validation_loss 27204665344.0, Seconds 0.03660297393798828\n",
      "Epoch 227: Train_loss 27698763776.0, Validation_loss 27201781760.0, Seconds 0.039553165435791016\n",
      "Epoch 228: Train_loss 27693557760.0, Validation_loss 27198531584.0, Seconds 0.03385210037231445\n",
      "Epoch 229: Train_loss 27688269824.0, Validation_loss 27195469824.0, Seconds 0.038994789123535156\n",
      "Epoch 230: Train_loss 27683033088.0, Validation_loss 27192721408.0, Seconds 0.03501176834106445\n",
      "Epoch 231: Train_loss 27677825024.0, Validation_loss 27189243904.0, Seconds 0.03626108169555664\n",
      "Epoch 232: Train_loss 27672688640.0, Validation_loss 27186485248.0, Seconds 0.029528379440307617\n",
      "Epoch 233: Train_loss 27667474432.0, Validation_loss 27183650816.0, Seconds 0.03508877754211426\n",
      "Epoch 234: Train_loss 27662372864.0, Validation_loss 27181041664.0, Seconds 0.03157854080200195\n",
      "Epoch 235: Train_loss 27657115648.0, Validation_loss 27177261056.0, Seconds 0.0367584228515625\n",
      "Epoch 236: Train_loss 27651993600.0, Validation_loss 27173349376.0, Seconds 0.04501986503601074\n",
      "Epoch 237: Train_loss 27647080448.0, Validation_loss 27170457600.0, Seconds 0.03376340866088867\n",
      "Epoch 238: Train_loss 27642040320.0, Validation_loss 27167031296.0, Seconds 0.032196760177612305\n",
      "Epoch 239: Train_loss 27637207040.0, Validation_loss 27165085696.0, Seconds 0.03692150115966797\n",
      "Epoch 240: Train_loss 27632177152.0, Validation_loss 27161497600.0, Seconds 0.03584098815917969\n",
      "Epoch 241: Train_loss 27627309056.0, Validation_loss 27159328768.0, Seconds 0.036252498626708984\n",
      "Epoch 242: Train_loss 27622264832.0, Validation_loss 27156416512.0, Seconds 0.03771042823791504\n",
      "Epoch 243: Train_loss 27617226752.0, Validation_loss 27153532928.0, Seconds 0.036092281341552734\n",
      "Epoch 244: Train_loss 27612129280.0, Validation_loss 27150399488.0, Seconds 0.05149269104003906\n",
      "Epoch 245: Train_loss 27607140352.0, Validation_loss 27147716608.0, Seconds 0.03532719612121582\n",
      "Epoch 246: Train_loss 27602079744.0, Validation_loss 27144771584.0, Seconds 0.03529715538024902\n",
      "Epoch 247: Train_loss 27597111296.0, Validation_loss 27141816320.0, Seconds 0.03900766372680664\n",
      "Epoch 248: Train_loss 27592161280.0, Validation_loss 27139129344.0, Seconds 0.04271054267883301\n",
      "Epoch 249: Train_loss 27587262464.0, Validation_loss 27136968704.0, Seconds 0.032129764556884766\n",
      "Epoch 250: Train_loss 27582263296.0, Validation_loss 27133745152.0, Seconds 0.03513956069946289\n",
      "Epoch 251: Train_loss 27577266176.0, Validation_loss 27130486784.0, Seconds 0.03872823715209961\n",
      "Epoch 252: Train_loss 27572471808.0, Validation_loss 27129411584.0, Seconds 0.032082557678222656\n",
      "Epoch 253: Train_loss 27567564800.0, Validation_loss 27127697408.0, Seconds 0.03663921356201172\n",
      "Epoch 254: Train_loss 27562612736.0, Validation_loss 27125315584.0, Seconds 0.03925776481628418\n",
      "Epoch 255: Train_loss 27557625856.0, Validation_loss 27122685952.0, Seconds 0.03829216957092285\n",
      "Epoch 256: Train_loss 27552706560.0, Validation_loss 27120328704.0, Seconds 0.03766036033630371\n",
      "Epoch 257: Train_loss 27547869184.0, Validation_loss 27118481408.0, Seconds 0.03306078910827637\n",
      "Epoch 258: Train_loss 27542994944.0, Validation_loss 27116206080.0, Seconds 0.03157401084899902\n",
      "Epoch 259: Train_loss 27538173952.0, Validation_loss 27114610688.0, Seconds 0.035175323486328125\n",
      "Epoch 260: Train_loss 27533408256.0, Validation_loss 27113037824.0, Seconds 0.03657341003417969\n",
      "Epoch 261: Train_loss 27528749056.0, Validation_loss 27112101888.0, Seconds 0.033934593200683594\n",
      "Epoch 262: Train_loss 27524136960.0, Validation_loss 27110705152.0, Seconds 0.03194236755371094\n",
      "Epoch 263: Train_loss 27519490048.0, Validation_loss 27109273600.0, Seconds 0.03486442565917969\n",
      "Epoch 264: Train_loss 27514755072.0, Validation_loss 27107172352.0, Seconds 0.0329740047454834\n",
      "Epoch 265: Train_loss 27510102016.0, Validation_loss 27106643968.0, Seconds 0.035127878189086914\n",
      "Epoch 266: Train_loss 27505469440.0, Validation_loss 27106357248.0, Seconds 0.0372467041015625\n",
      "Epoch 267: Train_loss 27500791808.0, Validation_loss 27104849920.0, Seconds 0.038562774658203125\n",
      "Epoch 268: Train_loss 27496323072.0, Validation_loss 27104442368.0, Seconds 0.030137062072753906\n",
      "Epoch 269: Train_loss 27491733504.0, Validation_loss 27102527488.0, Seconds 0.03887009620666504\n",
      "Epoch 270: Train_loss 27487119360.0, Validation_loss 27100338176.0, Seconds 0.03314328193664551\n",
      "Epoch 271: Train_loss 27482624000.0, Validation_loss 27099080704.0, Seconds 0.03541922569274902\n",
      "Epoch 272: Train_loss 27478071296.0, Validation_loss 27096846336.0, Seconds 0.032616376876831055\n",
      "Epoch 273: Train_loss 27473479680.0, Validation_loss 27094247424.0, Seconds 0.03235316276550293\n",
      "Epoch 274: Train_loss 27468890112.0, Validation_loss 27092690944.0, Seconds 0.038779497146606445\n",
      "Epoch 275: Train_loss 27464337408.0, Validation_loss 27091574784.0, Seconds 0.0326998233795166\n",
      "Epoch 276: Train_loss 27459821568.0, Validation_loss 27090294784.0, Seconds 0.03222250938415527\n",
      "Epoch 277: Train_loss 27455469568.0, Validation_loss 27090624512.0, Seconds 0.03411078453063965\n",
      "Epoch 278: Train_loss 27450912768.0, Validation_loss 27088762880.0, Seconds 0.03492927551269531\n",
      "Epoch 279: Train_loss 27446511616.0, Validation_loss 27089043456.0, Seconds 0.03359174728393555\n",
      "Epoch 280: Train_loss 27441942528.0, Validation_loss 27088164864.0, Seconds 0.03277444839477539\n",
      "Epoch 281: Train_loss 27437516800.0, Validation_loss 27087435776.0, Seconds 0.04233980178833008\n",
      "Epoch 282: Train_loss 27433197568.0, Validation_loss 27086718976.0, Seconds 0.037079811096191406\n",
      "Epoch 283: Train_loss 27428935680.0, Validation_loss 27086788608.0, Seconds 0.03589510917663574\n",
      "Epoch 284: Train_loss 27424452608.0, Validation_loss 27087794176.0, Seconds 0.033098697662353516\n",
      "Epoch 285: Train_loss 27419863040.0, Validation_loss 27087063040.0, Seconds 0.031216859817504883\n",
      "Epoch 286: Train_loss 27415236608.0, Validation_loss 27086778368.0, Seconds 0.03770184516906738\n",
      "Epoch 287: Train_loss 27410642944.0, Validation_loss 27087192064.0, Seconds 0.03832125663757324\n",
      "Epoch 288: Train_loss 27406166016.0, Validation_loss 27087673344.0, Seconds 0.03374838829040527\n",
      "Epoch 289: Train_loss 27401654272.0, Validation_loss 27087855616.0, Seconds 0.03219151496887207\n",
      "Epoch 290: Train_loss 27397289984.0, Validation_loss 27089135616.0, Seconds 0.03381776809692383\n",
      "Epoch 291: Train_loss 27392614400.0, Validation_loss 27089135616.0, Seconds 0.034002065658569336\n",
      "Epoch 292: Train_loss 27387762688.0, Validation_loss 27087271936.0, Seconds 0.03735828399658203\n",
      "Epoch 293: Train_loss 27383177216.0, Validation_loss 27084601344.0, Seconds 0.0355372428894043\n",
      "Epoch 294: Train_loss 27378636800.0, Validation_loss 27081805824.0, Seconds 0.0342259407043457\n",
      "Epoch 295: Train_loss 27374157824.0, Validation_loss 27079692288.0, Seconds 0.031830787658691406\n",
      "Epoch 296: Train_loss 27369793536.0, Validation_loss 27078717440.0, Seconds 0.035104990005493164\n",
      "Epoch 297: Train_loss 27365378048.0, Validation_loss 27076775936.0, Seconds 0.034903764724731445\n",
      "Epoch 298: Train_loss 27361140736.0, Validation_loss 27076593664.0, Seconds 0.03535652160644531\n",
      "Epoch 299: Train_loss 27356796928.0, Validation_loss 27074723840.0, Seconds 0.034572601318359375\n",
      "Epoch 300: Train_loss 27352623104.0, Validation_loss 27074598912.0, Seconds 0.04112720489501953\n",
      "Epoch 301: Train_loss 27348346880.0, Validation_loss 27072884736.0, Seconds 0.03888225555419922\n",
      "Epoch 302: Train_loss 27344197632.0, Validation_loss 27071401984.0, Seconds 0.03905963897705078\n",
      "Epoch 303: Train_loss 27340236800.0, Validation_loss 27072055296.0, Seconds 0.035332679748535156\n",
      "Epoch 304: Train_loss 27335979008.0, Validation_loss 27069368320.0, Seconds 0.03869318962097168\n",
      "Epoch 305: Train_loss 27331981312.0, Validation_loss 27069222912.0, Seconds 0.033921241760253906\n",
      "Epoch 306: Train_loss 27327997952.0, Validation_loss 27069222912.0, Seconds 0.033054351806640625\n",
      "Epoch 307: Train_loss 27324004352.0, Validation_loss 27068528640.0, Seconds 0.03708291053771973\n",
      "Epoch 308: Train_loss 27320008704.0, Validation_loss 27067473920.0, Seconds 0.031195878982543945\n",
      "Epoch 309: Train_loss 27315941376.0, Validation_loss 27066060800.0, Seconds 0.03199505805969238\n",
      "Epoch 310: Train_loss 27311882240.0, Validation_loss 27065278464.0, Seconds 0.03291511535644531\n",
      "Epoch 311: Train_loss 27307825152.0, Validation_loss 27063863296.0, Seconds 0.035817861557006836\n",
      "Epoch 312: Train_loss 27303725056.0, Validation_loss 27062097920.0, Seconds 0.03298664093017578\n",
      "Epoch 313: Train_loss 27299641344.0, Validation_loss 27061018624.0, Seconds 0.03318452835083008\n",
      "Epoch 314: Train_loss 27295682560.0, Validation_loss 27060514816.0, Seconds 0.03802061080932617\n",
      "Epoch 315: Train_loss 27291748352.0, Validation_loss 27060226048.0, Seconds 0.0408627986907959\n",
      "Epoch 316: Train_loss 27287918592.0, Validation_loss 27060402176.0, Seconds 0.041409969329833984\n",
      "Epoch 317: Train_loss 27284078592.0, Validation_loss 27060054016.0, Seconds 0.043778181076049805\n",
      "Epoch 318: Train_loss 27280273408.0, Validation_loss 27059931136.0, Seconds 0.037719011306762695\n",
      "Epoch 319: Train_loss 27276527616.0, Validation_loss 27059841024.0, Seconds 0.0370020866394043\n",
      "Epoch 320: Train_loss 27272704000.0, Validation_loss 27060160512.0, Seconds 0.032181501388549805\n",
      "Epoch 321: Train_loss 27268907008.0, Validation_loss 27060295680.0, Seconds 0.03416109085083008\n",
      "Epoch 322: Train_loss 27265105920.0, Validation_loss 27059722240.0, Seconds 0.03393673896789551\n",
      "Epoch 323: Train_loss 27261411328.0, Validation_loss 27059486720.0, Seconds 0.040068864822387695\n",
      "Epoch 324: Train_loss 27257774080.0, Validation_loss 27059386368.0, Seconds 0.034644365310668945\n",
      "Epoch 325: Train_loss 27254108160.0, Validation_loss 27058941952.0, Seconds 0.036077260971069336\n",
      "Epoch 326: Train_loss 27250597888.0, Validation_loss 27059554304.0, Seconds 0.0390477180480957\n",
      "Epoch 327: Train_loss 27247063040.0, Validation_loss 27059853312.0, Seconds 0.03205156326293945\n",
      "Epoch 328: Train_loss 27243460608.0, Validation_loss 27059961856.0, Seconds 0.03317856788635254\n",
      "Epoch 329: Train_loss 27239931904.0, Validation_loss 27059902464.0, Seconds 0.034790754318237305\n",
      "Epoch 330: Train_loss 27236378624.0, Validation_loss 27059458048.0, Seconds 0.0342707633972168\n",
      "Epoch 331: Train_loss 27232960512.0, Validation_loss 27059685376.0, Seconds 0.03381919860839844\n",
      "Epoch 332: Train_loss 27229562880.0, Validation_loss 27058886656.0, Seconds 0.03387188911437988\n",
      "Epoch 333: Train_loss 27226314752.0, Validation_loss 27059527680.0, Seconds 0.03168845176696777\n",
      "Epoch 334: Train_loss 27222949888.0, Validation_loss 27058550784.0, Seconds 0.033693552017211914\n",
      "Epoch 335: Train_loss 27219810304.0, Validation_loss 27060514816.0, Seconds 0.03447318077087402\n",
      "Epoch 336: Train_loss 27216418816.0, Validation_loss 27059062784.0, Seconds 0.035109758377075195\n",
      "Epoch 337: Train_loss 27213062144.0, Validation_loss 27059351552.0, Seconds 0.032321929931640625\n",
      "Epoch 338: Train_loss 27209467904.0, Validation_loss 27059623936.0, Seconds 0.03724861145019531\n",
      "Epoch 339: Train_loss 27206008832.0, Validation_loss 27060662272.0, Seconds 0.03537273406982422\n",
      "Epoch 340: Train_loss 27202600960.0, Validation_loss 27060627456.0, Seconds 0.03466629981994629\n",
      "Epoch 341: Train_loss 27199338496.0, Validation_loss 27061282816.0, Seconds 0.033308982849121094\n",
      "Epoch 342: Train_loss 27196024832.0, Validation_loss 27062329344.0, Seconds 0.03810238838195801\n",
      "Epoch 343: Train_loss 27192643584.0, Validation_loss 27061954560.0, Seconds 0.03492474555969238\n",
      "Epoch 344: Train_loss 27189297152.0, Validation_loss 27060959232.0, Seconds 0.03534221649169922\n",
      "Epoch 345: Train_loss 27186171904.0, Validation_loss 27061499904.0, Seconds 0.0347132682800293\n",
      "Epoch 346: Train_loss 27183099904.0, Validation_loss 27061747712.0, Seconds 0.03829383850097656\n",
      "Epoch 347: Train_loss 27180029952.0, Validation_loss 27062466560.0, Seconds 0.03281283378601074\n",
      "Epoch 348: Train_loss 27177035776.0, Validation_loss 27063472128.0, Seconds 0.03422880172729492\n",
      "Epoch 349: Train_loss 27174094848.0, Validation_loss 27063631872.0, Seconds 0.03184318542480469\n",
      "Epoch 350: Train_loss 27171231744.0, Validation_loss 27063992320.0, Seconds 0.034197092056274414\n",
      "Epoch 351: Train_loss 27168409600.0, Validation_loss 27065370624.0, Seconds 0.03158378601074219\n",
      "Epoch 352: Train_loss 27165526016.0, Validation_loss 27065960448.0, Seconds 0.034224748611450195\n",
      "Epoch 353: Train_loss 27162738688.0, Validation_loss 27067463680.0, Seconds 0.03797316551208496\n",
      "Epoch 354: Train_loss 27159912448.0, Validation_loss 27068549120.0, Seconds 0.03392958641052246\n",
      "Epoch 355: Train_loss 27157147648.0, Validation_loss 27069681664.0, Seconds 0.032814979553222656\n",
      "Epoch 356: Train_loss 27154432000.0, Validation_loss 27071318016.0, Seconds 0.034069061279296875\n",
      "Epoch 357: Train_loss 27151599616.0, Validation_loss 27071662080.0, Seconds 0.032027244567871094\n",
      "Epoch 358: Train_loss 27148890112.0, Validation_loss 27072899072.0, Seconds 0.0333256721496582\n",
      "Epoch 359: Train_loss 27146055680.0, Validation_loss 27073034240.0, Seconds 0.03563714027404785\n",
      "Epoch 360: Train_loss 27143301120.0, Validation_loss 27074320384.0, Seconds 0.03449201583862305\n",
      "Epoch 361: Train_loss 27140548608.0, Validation_loss 27075330048.0, Seconds 0.029720067977905273\n",
      "Epoch 362: Train_loss 27137552384.0, Validation_loss 27076304896.0, Seconds 0.031147241592407227\n",
      "Epoch 363: Train_loss 27134578688.0, Validation_loss 27077048320.0, Seconds 0.034670352935791016\n",
      "Epoch 364: Train_loss 27131592704.0, Validation_loss 27077117952.0, Seconds 0.035202980041503906\n",
      "Epoch 365: Train_loss 27128766464.0, Validation_loss 27078209536.0, Seconds 0.03577780723571777\n",
      "Epoch 366: Train_loss 27125403648.0, Validation_loss 27078250496.0, Seconds 0.03258824348449707\n",
      "Epoch 367: Train_loss 27121965056.0, Validation_loss 27076728832.0, Seconds 0.033846139907836914\n",
      "Epoch 368: Train_loss 27118229504.0, Validation_loss 27073826816.0, Seconds 0.03367114067077637\n",
      "Epoch 369: Train_loss 27114846208.0, Validation_loss 27070552064.0, Seconds 0.032138824462890625\n",
      "Epoch 370: Train_loss 27111544832.0, Validation_loss 27067213824.0, Seconds 0.03212690353393555\n",
      "Epoch 371: Train_loss 27108298752.0, Validation_loss 27064281088.0, Seconds 0.03877067565917969\n",
      "Epoch 372: Train_loss 27104923648.0, Validation_loss 27061233664.0, Seconds 0.036780595779418945\n",
      "Epoch 373: Train_loss 27101749248.0, Validation_loss 27060967424.0, Seconds 0.035239219665527344\n",
      "Epoch 374: Train_loss 27098550272.0, Validation_loss 27057870848.0, Seconds 0.0352017879486084\n",
      "Epoch 375: Train_loss 27095705600.0, Validation_loss 27057713152.0, Seconds 0.03360486030578613\n",
      "Epoch 376: Train_loss 27092678656.0, Validation_loss 27056429056.0, Seconds 0.03133106231689453\n",
      "Epoch 377: Train_loss 27089833984.0, Validation_loss 27056191488.0, Seconds 0.03462624549865723\n",
      "Epoch 378: Train_loss 27087054848.0, Validation_loss 27056623616.0, Seconds 0.03448939323425293\n",
      "Epoch 379: Train_loss 27084271616.0, Validation_loss 27057475584.0, Seconds 0.03289341926574707\n",
      "Epoch 380: Train_loss 27081547776.0, Validation_loss 27057305600.0, Seconds 0.03298187255859375\n",
      "Epoch 381: Train_loss 27078828032.0, Validation_loss 27056984064.0, Seconds 0.03970050811767578\n",
      "Epoch 382: Train_loss 27075991552.0, Validation_loss 27056379904.0, Seconds 0.03401637077331543\n",
      "Epoch 383: Train_loss 27073363968.0, Validation_loss 27056691200.0, Seconds 0.03604722023010254\n",
      "Epoch 384: Train_loss 27070666752.0, Validation_loss 27057051648.0, Seconds 0.03315997123718262\n",
      "Epoch 385: Train_loss 27067990016.0, Validation_loss 27055347712.0, Seconds 0.031719207763671875\n",
      "Epoch 386: Train_loss 27065536512.0, Validation_loss 27055024128.0, Seconds 0.031995296478271484\n",
      "Epoch 387: Train_loss 27063070720.0, Validation_loss 27054102528.0, Seconds 0.034174442291259766\n",
      "Epoch 388: Train_loss 27060768768.0, Validation_loss 27054661632.0, Seconds 0.041048288345336914\n",
      "Epoch 389: Train_loss 27058413568.0, Validation_loss 27055370240.0, Seconds 0.14016127586364746\n",
      "Epoch 390: Train_loss 27056179200.0, Validation_loss 27056914432.0, Seconds 0.034811973571777344\n",
      "Epoch 391: Train_loss 27053795328.0, Validation_loss 27056930816.0, Seconds 0.03433632850646973\n",
      "Epoch 392: Train_loss 27051524096.0, Validation_loss 27057526784.0, Seconds 0.02922821044921875\n",
      "Epoch 393: Train_loss 27049287680.0, Validation_loss 27058368512.0, Seconds 0.03210186958312988\n",
      "Epoch 394: Train_loss 27047061504.0, Validation_loss 27059986432.0, Seconds 0.03180837631225586\n",
      "Epoch 395: Train_loss 27044874240.0, Validation_loss 27060576256.0, Seconds 0.03225374221801758\n",
      "Epoch 396: Train_loss 27042650112.0, Validation_loss 27060209664.0, Seconds 0.032622575759887695\n",
      "Epoch 397: Train_loss 27040505856.0, Validation_loss 27060314112.0, Seconds 0.035172462463378906\n",
      "Epoch 398: Train_loss 27038386176.0, Validation_loss 27060629504.0, Seconds 0.03196072578430176\n",
      "Epoch 399: Train_loss 27036319744.0, Validation_loss 27061143552.0, Seconds 0.03048253059387207\n",
      "Epoch 400: Train_loss 27034159104.0, Validation_loss 27061231616.0, Seconds 0.03455543518066406\n",
      "Epoch 401: Train_loss 27032158208.0, Validation_loss 27062484992.0, Seconds 0.03388476371765137\n",
      "Epoch 402: Train_loss 27030034432.0, Validation_loss 27063121920.0, Seconds 0.03397631645202637\n",
      "Epoch 403: Train_loss 27027830784.0, Validation_loss 27062507520.0, Seconds 0.038175106048583984\n",
      "Epoch 404: Train_loss 27025881088.0, Validation_loss 27064031232.0, Seconds 0.03509807586669922\n",
      "Epoch 405: Train_loss 27023941632.0, Validation_loss 27065270272.0, Seconds 0.03458356857299805\n",
      "Epoch 406: Train_loss 27021871104.0, Validation_loss 27066679296.0, Seconds 0.034117698669433594\n",
      "Epoch 407: Train_loss 27019874304.0, Validation_loss 27067588608.0, Seconds 0.029417991638183594\n",
      "Epoch 408: Train_loss 27017828352.0, Validation_loss 27068071936.0, Seconds 0.034577131271362305\n",
      "Epoch 409: Train_loss 27015796736.0, Validation_loss 27068129280.0, Seconds 0.04822731018066406\n",
      "Epoch 410: Train_loss 27013935104.0, Validation_loss 27069917184.0, Seconds 0.038084983825683594\n",
      "Epoch 411: Train_loss 27012014080.0, Validation_loss 27072206848.0, Seconds 0.035767316818237305\n",
      "Epoch 412: Train_loss 27010052096.0, Validation_loss 27071381504.0, Seconds 0.03491044044494629\n",
      "Epoch 413: Train_loss 27008348160.0, Validation_loss 27072921600.0, Seconds 0.03805208206176758\n",
      "Epoch 414: Train_loss 27006486528.0, Validation_loss 27074066432.0, Seconds 0.03316545486450195\n",
      "Epoch 415: Train_loss 27004631040.0, Validation_loss 27074119680.0, Seconds 0.03488302230834961\n",
      "Epoch 416: Train_loss 27002863616.0, Validation_loss 27074953216.0, Seconds 0.03846335411071777\n",
      "Epoch 417: Train_loss 27001042944.0, Validation_loss 27074678784.0, Seconds 0.03678488731384277\n",
      "Epoch 418: Train_loss 26999179264.0, Validation_loss 27074609152.0, Seconds 0.042736053466796875\n",
      "Epoch 419: Train_loss 26997401600.0, Validation_loss 27075106816.0, Seconds 0.045082807540893555\n",
      "Epoch 420: Train_loss 26995611648.0, Validation_loss 27075137536.0, Seconds 0.03199458122253418\n",
      "Epoch 421: Train_loss 26993977344.0, Validation_loss 27076753408.0, Seconds 0.028133153915405273\n",
      "Epoch 422: Train_loss 26992164864.0, Validation_loss 27076804608.0, Seconds 0.035149574279785156\n",
      "Epoch 423: Train_loss 26990430208.0, Validation_loss 27077883904.0, Seconds 0.03468489646911621\n",
      "Epoch 424: Train_loss 26988709888.0, Validation_loss 27079325696.0, Seconds 0.030181169509887695\n",
      "Epoch 425: Train_loss 26986981376.0, Validation_loss 27079657472.0, Seconds 0.032648563385009766\n",
      "Epoch 426: Train_loss 26985105408.0, Validation_loss 27080773632.0, Seconds 0.032118797302246094\n",
      "Epoch 427: Train_loss 26983278592.0, Validation_loss 27080288256.0, Seconds 0.0371088981628418\n",
      "Epoch 428: Train_loss 26981582848.0, Validation_loss 27080372224.0, Seconds 0.03732419013977051\n",
      "Epoch 429: Train_loss 26979573760.0, Validation_loss 27079165952.0, Seconds 0.03147292137145996\n",
      "Epoch 430: Train_loss 26977912832.0, Validation_loss 27080966144.0, Seconds 0.037236928939819336\n",
      "Epoch 431: Train_loss 26976108544.0, Validation_loss 27081207808.0, Seconds 0.03586316108703613\n",
      "Epoch 432: Train_loss 26974193664.0, Validation_loss 27081334784.0, Seconds 0.03596663475036621\n",
      "Epoch 433: Train_loss 26972575744.0, Validation_loss 27083487232.0, Seconds 0.034093379974365234\n",
      "Epoch 434: Train_loss 26970873856.0, Validation_loss 27084005376.0, Seconds 0.03612232208251953\n",
      "Epoch 435: Train_loss 26969044992.0, Validation_loss 27084451840.0, Seconds 0.03712749481201172\n",
      "Epoch 436: Train_loss 26967580672.0, Validation_loss 27087620096.0, Seconds 0.035825252532958984\n",
      "Epoch 437: Train_loss 26965790720.0, Validation_loss 27086772224.0, Seconds 0.038172245025634766\n",
      "Epoch 438: Train_loss 26964152320.0, Validation_loss 27088513024.0, Seconds 0.03365445137023926\n",
      "Epoch 439: Train_loss 26962622464.0, Validation_loss 27090436096.0, Seconds 0.035337209701538086\n",
      "Epoch 440: Train_loss 26960904192.0, Validation_loss 27091226624.0, Seconds 0.03249931335449219\n",
      "Epoch 441: Train_loss 26959126528.0, Validation_loss 27092279296.0, Seconds 0.03835463523864746\n",
      "Epoch 442: Train_loss 26957631488.0, Validation_loss 27095371776.0, Seconds 0.03619742393493652\n",
      "Epoch 443: Train_loss 26955933696.0, Validation_loss 27096258560.0, Seconds 0.03497505187988281\n",
      "Epoch 444: Train_loss 26954139648.0, Validation_loss 27097251840.0, Seconds 0.031586408615112305\n",
      "Epoch 445: Train_loss 26952390656.0, Validation_loss 27098560512.0, Seconds 0.03737068176269531\n",
      "Epoch 446: Train_loss 26950656000.0, Validation_loss 27099590656.0, Seconds 0.03683304786682129\n",
      "Epoch 447: Train_loss 26948911104.0, Validation_loss 27099932672.0, Seconds 0.03491616249084473\n",
      "Epoch 448: Train_loss 26947293184.0, Validation_loss 27101034496.0, Seconds 0.0470271110534668\n",
      "Epoch 449: Train_loss 26945628160.0, Validation_loss 27101878272.0, Seconds 0.036080121994018555\n",
      "Epoch 450: Train_loss 26944176128.0, Validation_loss 27104450560.0, Seconds 0.031063318252563477\n",
      "Epoch 451: Train_loss 26942437376.0, Validation_loss 27104927744.0, Seconds 0.03307628631591797\n",
      "Epoch 452: Train_loss 26941063168.0, Validation_loss 27107770368.0, Seconds 0.03370308876037598\n",
      "Epoch 453: Train_loss 26939451392.0, Validation_loss 27107897344.0, Seconds 0.032964468002319336\n",
      "Epoch 454: Train_loss 26938050560.0, Validation_loss 27110062080.0, Seconds 0.03222489356994629\n",
      "Epoch 455: Train_loss 26936569856.0, Validation_loss 27110791168.0, Seconds 0.0369105339050293\n",
      "Epoch 456: Train_loss 26935040000.0, Validation_loss 27111655424.0, Seconds 0.0335843563079834\n",
      "Epoch 457: Train_loss 26933663744.0, Validation_loss 27113377792.0, Seconds 0.03421950340270996\n",
      "Epoch 458: Train_loss 26932070400.0, Validation_loss 27113445376.0, Seconds 0.033182382583618164\n",
      "Epoch 459: Train_loss 26930780160.0, Validation_loss 27118071808.0, Seconds 0.03322720527648926\n",
      "Epoch 460: Train_loss 26929049600.0, Validation_loss 27117926400.0, Seconds 0.03399658203125\n",
      "Epoch 461: Train_loss 26927587328.0, Validation_loss 27119235072.0, Seconds 0.031968116760253906\n",
      "Epoch 462: Train_loss 26926264320.0, Validation_loss 27121025024.0, Seconds 0.03687262535095215\n",
      "Epoch 463: Train_loss 26924691456.0, Validation_loss 27121072128.0, Seconds 0.03418684005737305\n",
      "Epoch 464: Train_loss 26923196416.0, Validation_loss 27121573888.0, Seconds 0.03295254707336426\n",
      "Epoch 465: Train_loss 26921609216.0, Validation_loss 27120562176.0, Seconds 0.03606915473937988\n",
      "Epoch 466: Train_loss 26920239104.0, Validation_loss 27122436096.0, Seconds 0.030627965927124023\n",
      "Epoch 467: Train_loss 26918629376.0, Validation_loss 27122708480.0, Seconds 0.033316612243652344\n",
      "Epoch 468: Train_loss 26917068800.0, Validation_loss 27123136512.0, Seconds 0.04084324836730957\n",
      "Epoch 469: Train_loss 26915608576.0, Validation_loss 27124875264.0, Seconds 0.042336463928222656\n",
      "Epoch 470: Train_loss 26914244608.0, Validation_loss 27128651776.0, Seconds 0.033713579177856445\n",
      "Epoch 471: Train_loss 26912399360.0, Validation_loss 27127549952.0, Seconds 0.03669142723083496\n",
      "Epoch 472: Train_loss 26911016960.0, Validation_loss 27129815040.0, Seconds 0.03304147720336914\n",
      "Epoch 473: Train_loss 26909741056.0, Validation_loss 27132250112.0, Seconds 0.031247615814208984\n",
      "Epoch 474: Train_loss 26908237824.0, Validation_loss 27132686336.0, Seconds 0.03294730186462402\n",
      "Epoch 475: Train_loss 26906908672.0, Validation_loss 27135307776.0, Seconds 0.033208608627319336\n",
      "Epoch 476: Train_loss 26905647104.0, Validation_loss 27136915456.0, Seconds 0.03926658630371094\n",
      "Epoch 477: Train_loss 26904137728.0, Validation_loss 27137832960.0, Seconds 0.03432345390319824\n",
      "Epoch 478: Train_loss 26902759424.0, Validation_loss 27139592192.0, Seconds 0.031145811080932617\n",
      "Epoch 479: Train_loss 26901401600.0, Validation_loss 27140603904.0, Seconds 0.03180813789367676\n",
      "Epoch 480: Train_loss 26900092928.0, Validation_loss 27143178240.0, Seconds 0.03202939033508301\n",
      "Epoch 481: Train_loss 26898741248.0, Validation_loss 27145428992.0, Seconds 0.030330419540405273\n",
      "Epoch 482: Train_loss 26897303552.0, Validation_loss 27146758144.0, Seconds 0.03191089630126953\n",
      "Epoch 483: Train_loss 26896113664.0, Validation_loss 27149508608.0, Seconds 0.04280972480773926\n",
      "Epoch 484: Train_loss 26894725120.0, Validation_loss 27151386624.0, Seconds 0.03388619422912598\n",
      "Epoch 485: Train_loss 26893441024.0, Validation_loss 27151982592.0, Seconds 0.033231258392333984\n",
      "Epoch 486: Train_loss 26892357632.0, Validation_loss 27154458624.0, Seconds 0.031019210815429688\n",
      "Epoch 487: Train_loss 26890960896.0, Validation_loss 27155863552.0, Seconds 0.03310060501098633\n",
      "Epoch 488: Train_loss 26889711616.0, Validation_loss 27158423552.0, Seconds 0.033855438232421875\n",
      "Epoch 489: Train_loss 26888574976.0, Validation_loss 27162038272.0, Seconds 0.03291940689086914\n",
      "Epoch 490: Train_loss 26887301120.0, Validation_loss 27163977728.0, Seconds 0.03652501106262207\n",
      "Epoch 491: Train_loss 26886141952.0, Validation_loss 27165851648.0, Seconds 0.03669309616088867\n",
      "Epoch 492: Train_loss 26884909056.0, Validation_loss 27168598016.0, Seconds 0.03305983543395996\n",
      "Epoch 493: Train_loss 26883702784.0, Validation_loss 27170482176.0, Seconds 0.03309297561645508\n",
      "Epoch 494: Train_loss 26882605056.0, Validation_loss 27173537792.0, Seconds 0.03489875793457031\n",
      "Epoch 495: Train_loss 26881386496.0, Validation_loss 27176837120.0, Seconds 0.031626224517822266\n",
      "Epoch 496: Train_loss 26880309248.0, Validation_loss 27180263424.0, Seconds 0.031094074249267578\n",
      "Epoch 497: Train_loss 26879232000.0, Validation_loss 27182852096.0, Seconds 0.03512430191040039\n",
      "Epoch 498: Train_loss 26878054400.0, Validation_loss 27185715200.0, Seconds 0.0318751335144043\n",
      "Epoch 499: Train_loss 26876887040.0, Validation_loss 27188418560.0, Seconds 0.03523659706115723\n",
      "Epoch 500: Train_loss 26875723776.0, Validation_loss 27191261184.0, Seconds 0.033667564392089844\n",
      "Epoch 501: Train_loss 26874642432.0, Validation_loss 27194101760.0, Seconds 0.03354382514953613\n",
      "Epoch 502: Train_loss 26873501696.0, Validation_loss 27196727296.0, Seconds 0.0356442928314209\n",
      "Epoch 503: Train_loss 26872338432.0, Validation_loss 27198898176.0, Seconds 0.03414773941040039\n",
      "Epoch 504: Train_loss 26871248896.0, Validation_loss 27201646592.0, Seconds 0.034806013107299805\n",
      "Epoch 505: Train_loss 26870331392.0, Validation_loss 27204440064.0, Seconds 0.034642696380615234\n",
      "Epoch 506: Train_loss 26869323776.0, Validation_loss 27206168576.0, Seconds 0.0343928337097168\n",
      "Epoch 507: Train_loss 26868043776.0, Validation_loss 27205685248.0, Seconds 0.032114505767822266\n",
      "Epoch 508: Train_loss 26867142656.0, Validation_loss 27208574976.0, Seconds 0.029820680618286133\n",
      "Epoch 509: Train_loss 26866173952.0, Validation_loss 27210209280.0, Seconds 0.03608894348144531\n",
      "Epoch 510: Train_loss 26865086464.0, Validation_loss 27211874304.0, Seconds 0.03714895248413086\n",
      "Epoch 511: Train_loss 26864105472.0, Validation_loss 27214350336.0, Seconds 0.033942222595214844\n",
      "Epoch 512: Train_loss 26863171584.0, Validation_loss 27216193536.0, Seconds 0.031464576721191406\n",
      "Epoch 513: Train_loss 26862178304.0, Validation_loss 27217780736.0, Seconds 0.033570289611816406\n",
      "Epoch 514: Train_loss 26861068288.0, Validation_loss 27219664896.0, Seconds 0.03205704689025879\n",
      "Epoch 515: Train_loss 26860054528.0, Validation_loss 27221272576.0, Seconds 0.03386950492858887\n",
      "Epoch 516: Train_loss 26858821632.0, Validation_loss 27220590592.0, Seconds 0.037035465240478516\n",
      "Epoch 517: Train_loss 26857793536.0, Validation_loss 27222013952.0, Seconds 0.03304266929626465\n",
      "Epoch 518: Train_loss 26856650752.0, Validation_loss 27223513088.0, Seconds 0.03169393539428711\n",
      "Epoch 519: Train_loss 26855632896.0, Validation_loss 27225360384.0, Seconds 0.033182621002197266\n",
      "Epoch 520: Train_loss 26854576128.0, Validation_loss 27226312704.0, Seconds 0.031858205795288086\n",
      "Epoch 521: Train_loss 26853519360.0, Validation_loss 27227211776.0, Seconds 0.033246517181396484\n",
      "Epoch 522: Train_loss 26852413440.0, Validation_loss 27228416000.0, Seconds 0.03405952453613281\n",
      "Epoch 523: Train_loss 26851551232.0, Validation_loss 27231102976.0, Seconds 0.03580045700073242\n",
      "Epoch 524: Train_loss 26850447360.0, Validation_loss 27229622272.0, Seconds 0.03486824035644531\n",
      "Epoch 525: Train_loss 26849409024.0, Validation_loss 27230291968.0, Seconds 0.03174591064453125\n",
      "Epoch 526: Train_loss 26848634880.0, Validation_loss 27232913408.0, Seconds 0.03348422050476074\n",
      "Epoch 527: Train_loss 26847545344.0, Validation_loss 27233019904.0, Seconds 0.032857418060302734\n",
      "Epoch 528: Train_loss 26846529536.0, Validation_loss 27233421312.0, Seconds 0.0330510139465332\n",
      "Epoch 529: Train_loss 26845687808.0, Validation_loss 27235379200.0, Seconds 0.033936262130737305\n",
      "Epoch 530: Train_loss 26844823552.0, Validation_loss 27236712448.0, Seconds 0.037450313568115234\n",
      "Epoch 531: Train_loss 26843754496.0, Validation_loss 27235438592.0, Seconds 0.039703369140625\n",
      "Epoch 532: Train_loss 26842925056.0, Validation_loss 27239385088.0, Seconds 0.03275275230407715\n",
      "Epoch 533: Train_loss 26841995264.0, Validation_loss 27241658368.0, Seconds 0.03409981727600098\n",
      "Epoch 534: Train_loss 26840989696.0, Validation_loss 27242680320.0, Seconds 0.05236315727233887\n",
      "Epoch 535: Train_loss 26840072192.0, Validation_loss 27246401536.0, Seconds 0.033995628356933594\n",
      "Epoch 536: Train_loss 26839134208.0, Validation_loss 27250030592.0, Seconds 0.034628868103027344\n",
      "Epoch 537: Train_loss 26838104064.0, Validation_loss 27251849216.0, Seconds 0.034034013748168945\n",
      "Epoch 538: Train_loss 26837182464.0, Validation_loss 27253993472.0, Seconds 0.03293251991271973\n",
      "Epoch 539: Train_loss 26836357120.0, Validation_loss 27257706496.0, Seconds 0.032309532165527344\n",
      "Epoch 540: Train_loss 26835441664.0, Validation_loss 27259873280.0, Seconds 0.03396487236022949\n",
      "Epoch 541: Train_loss 26834468864.0, Validation_loss 27260178432.0, Seconds 0.033104658126831055\n",
      "Epoch 542: Train_loss 26833668096.0, Validation_loss 27262588928.0, Seconds 0.03203749656677246\n",
      "Epoch 543: Train_loss 26832828416.0, Validation_loss 27266191360.0, Seconds 0.03563046455383301\n",
      "Epoch 544: Train_loss 26831775744.0, Validation_loss 27267393536.0, Seconds 0.034978628158569336\n",
      "Epoch 545: Train_loss 26831028224.0, Validation_loss 27268618240.0, Seconds 0.0330197811126709\n",
      "Epoch 546: Train_loss 26830155776.0, Validation_loss 27270432768.0, Seconds 0.031972408294677734\n",
      "Epoch 547: Train_loss 26829404160.0, Validation_loss 27273836544.0, Seconds 0.032972097396850586\n",
      "Epoch 548: Train_loss 26828355584.0, Validation_loss 27273371648.0, Seconds 0.03217196464538574\n",
      "Epoch 549: Train_loss 26827515904.0, Validation_loss 27276566528.0, Seconds 0.033058881759643555\n",
      "Epoch 550: Train_loss 26826260480.0, Validation_loss 27275689984.0, Seconds 0.035869598388671875\n",
      "Epoch 551: Train_loss 26825316352.0, Validation_loss 27275220992.0, Seconds 0.03256678581237793\n",
      "Epoch 552: Train_loss 26824087552.0, Validation_loss 27273795584.0, Seconds 0.03374290466308594\n",
      "Epoch 553: Train_loss 26823141376.0, Validation_loss 27274743808.0, Seconds 0.03403306007385254\n",
      "Epoch 554: Train_loss 26822133760.0, Validation_loss 27275827200.0, Seconds 0.033647775650024414\n",
      "Epoch 555: Train_loss 26821257216.0, Validation_loss 27276707840.0, Seconds 0.03188014030456543\n",
      "Epoch 556: Train_loss 26820182016.0, Validation_loss 27276271616.0, Seconds 0.03372645378112793\n",
      "Epoch 557: Train_loss 26819352576.0, Validation_loss 27278264320.0, Seconds 0.03632044792175293\n",
      "Epoch 558: Train_loss 26818406400.0, Validation_loss 27277881344.0, Seconds 0.0350799560546875\n",
      "Epoch 559: Train_loss 26817413120.0, Validation_loss 27279210496.0, Seconds 0.03530621528625488\n",
      "Epoch 560: Train_loss 26816428032.0, Validation_loss 27280707584.0, Seconds 0.03281855583190918\n",
      "Epoch 561: Train_loss 26815594496.0, Validation_loss 27281344512.0, Seconds 0.03306913375854492\n",
      "Epoch 562: Train_loss 26814621696.0, Validation_loss 27281008640.0, Seconds 0.03199577331542969\n",
      "Epoch 563: Train_loss 26813698048.0, Validation_loss 27282708480.0, Seconds 0.03496909141540527\n",
      "Epoch 564: Train_loss 26812747776.0, Validation_loss 27283415040.0, Seconds 0.036847829818725586\n",
      "Epoch 565: Train_loss 26811756544.0, Validation_loss 27281606656.0, Seconds 0.03287982940673828\n",
      "Epoch 566: Train_loss 26810982400.0, Validation_loss 27282675712.0, Seconds 0.033063411712646484\n",
      "Epoch 567: Train_loss 26810050560.0, Validation_loss 27281999872.0, Seconds 0.03297710418701172\n",
      "Epoch 568: Train_loss 26809073664.0, Validation_loss 27282681856.0, Seconds 0.03195905685424805\n",
      "Epoch 569: Train_loss 26808326144.0, Validation_loss 27283394560.0, Seconds 0.03213620185852051\n",
      "Epoch 570: Train_loss 26807318528.0, Validation_loss 27283920896.0, Seconds 0.031881093978881836\n",
      "Epoch 571: Train_loss 26806097920.0, Validation_loss 27283216384.0, Seconds 0.03440451622009277\n",
      "Epoch 572: Train_loss 26805202944.0, Validation_loss 27282841600.0, Seconds 0.03418874740600586\n",
      "Epoch 573: Train_loss 26804168704.0, Validation_loss 27281868800.0, Seconds 0.0325465202331543\n",
      "Epoch 574: Train_loss 26803380224.0, Validation_loss 27285147648.0, Seconds 0.03218865394592285\n",
      "Epoch 575: Train_loss 26802434048.0, Validation_loss 27284449280.0, Seconds 0.03664803504943848\n",
      "Epoch 576: Train_loss 26802010112.0, Validation_loss 27288655872.0, Seconds 0.031777381896972656\n",
      "Epoch 577: Train_loss 26800611328.0, Validation_loss 27289440256.0, Seconds 0.03446769714355469\n",
      "Epoch 578: Train_loss 26799919104.0, Validation_loss 27291418624.0, Seconds 0.032767295837402344\n",
      "Epoch 579: Train_loss 26799142912.0, Validation_loss 27292868608.0, Seconds 0.032488107681274414\n",
      "Epoch 580: Train_loss 26798063616.0, Validation_loss 27293528064.0, Seconds 0.03182268142700195\n",
      "Epoch 581: Train_loss 26797271040.0, Validation_loss 27294103552.0, Seconds 0.03221273422241211\n",
      "Epoch 582: Train_loss 26796406784.0, Validation_loss 27294259200.0, Seconds 0.03275609016418457\n",
      "Epoch 583: Train_loss 26795563008.0, Validation_loss 27295092736.0, Seconds 0.03213953971862793\n",
      "Epoch 584: Train_loss 26794795008.0, Validation_loss 27296802816.0, Seconds 0.0318608283996582\n",
      "Epoch 585: Train_loss 26793689088.0, Validation_loss 27295959040.0, Seconds 0.036798715591430664\n",
      "Epoch 586: Train_loss 26793162752.0, Validation_loss 27298596864.0, Seconds 0.03425431251525879\n",
      "Epoch 587: Train_loss 26792232960.0, Validation_loss 27297853440.0, Seconds 0.030986309051513672\n",
      "Epoch 588: Train_loss 26791778304.0, Validation_loss 27299196928.0, Seconds 0.03471231460571289\n",
      "Epoch 589: Train_loss 26790973440.0, Validation_loss 27299086336.0, Seconds 0.03335213661193848\n",
      "Epoch 590: Train_loss 26790563840.0, Validation_loss 27300485120.0, Seconds 0.032857656478881836\n",
      "Epoch 591: Train_loss 26789795840.0, Validation_loss 27300921344.0, Seconds 0.03503131866455078\n",
      "Epoch 592: Train_loss 26789214208.0, Validation_loss 27301267456.0, Seconds 0.03508591651916504\n",
      "Epoch 593: Train_loss 26788519936.0, Validation_loss 27302737920.0, Seconds 0.029639005661010742\n",
      "Epoch 594: Train_loss 26787717120.0, Validation_loss 27302322176.0, Seconds 0.03607964515686035\n",
      "Epoch 595: Train_loss 26787403776.0, Validation_loss 27304126464.0, Seconds 0.03892159461975098\n",
      "Epoch 596: Train_loss 26786394112.0, Validation_loss 27302389760.0, Seconds 0.034224748611450195\n",
      "Epoch 597: Train_loss 26785845248.0, Validation_loss 27304091648.0, Seconds 0.03396153450012207\n",
      "Epoch 598: Train_loss 26785253376.0, Validation_loss 27303780352.0, Seconds 0.03217124938964844\n",
      "Epoch 599: Train_loss 26784671744.0, Validation_loss 27305328640.0, Seconds 0.02881312370300293\n",
      "Epoch 600: Train_loss 26783940608.0, Validation_loss 27304828928.0, Seconds 0.029110431671142578\n",
      "Epoch 601: Train_loss 26783490048.0, Validation_loss 27305254912.0, Seconds 0.03408050537109375\n",
      "Epoch 602: Train_loss 26782533632.0, Validation_loss 27306975232.0, Seconds 0.031682491302490234\n",
      "Epoch 603: Train_loss 26782007296.0, Validation_loss 27309164544.0, Seconds 0.03337359428405762\n",
      "Epoch 604: Train_loss 26781065216.0, Validation_loss 27309752320.0, Seconds 0.03161478042602539\n",
      "Epoch 605: Train_loss 26780370944.0, Validation_loss 27312422912.0, Seconds 0.03234982490539551\n",
      "Epoch 606: Train_loss 26779824128.0, Validation_loss 27314434048.0, Seconds 0.033888816833496094\n",
      "Epoch 607: Train_loss 26779025408.0, Validation_loss 27316754432.0, Seconds 0.13729071617126465\n",
      "Epoch 608: Train_loss 26778300416.0, Validation_loss 27317561344.0, Seconds 0.032480716705322266\n",
      "Epoch 609: Train_loss 26777628672.0, Validation_loss 27319963648.0, Seconds 0.03306460380554199\n",
      "Epoch 610: Train_loss 26777057280.0, Validation_loss 27322376192.0, Seconds 0.03391003608703613\n",
      "Epoch 611: Train_loss 26776326144.0, Validation_loss 27323039744.0, Seconds 0.03307652473449707\n",
      "Epoch 612: Train_loss 26775705600.0, Validation_loss 27325566976.0, Seconds 0.03393983840942383\n",
      "Epoch 613: Train_loss 26775343104.0, Validation_loss 27329032192.0, Seconds 0.03509521484375\n",
      "Epoch 614: Train_loss 26774519808.0, Validation_loss 27329421312.0, Seconds 0.03605365753173828\n",
      "Epoch 615: Train_loss 26774140928.0, Validation_loss 27334258688.0, Seconds 0.031085729598999023\n",
      "Epoch 616: Train_loss 26773471232.0, Validation_loss 27334047744.0, Seconds 0.03505873680114746\n",
      "Epoch 617: Train_loss 26773000192.0, Validation_loss 27337111552.0, Seconds 0.0369410514831543\n",
      "Epoch 618: Train_loss 26772400128.0, Validation_loss 27338723328.0, Seconds 0.035119056701660156\n",
      "Epoch 619: Train_loss 26771855360.0, Validation_loss 27339997184.0, Seconds 0.03386688232421875\n",
      "Epoch 620: Train_loss 26771390464.0, Validation_loss 27342305280.0, Seconds 0.03313302993774414\n",
      "Epoch 621: Train_loss 26770956288.0, Validation_loss 27344099328.0, Seconds 0.03865551948547363\n",
      "Epoch 622: Train_loss 26770405376.0, Validation_loss 27345664000.0, Seconds 0.03572344779968262\n",
      "Epoch 623: Train_loss 26769872896.0, Validation_loss 27346489344.0, Seconds 0.034546852111816406\n",
      "Epoch 624: Train_loss 26769348608.0, Validation_loss 27349125120.0, Seconds 0.03795623779296875\n",
      "Epoch 625: Train_loss 26768873472.0, Validation_loss 27350079488.0, Seconds 0.03056025505065918\n",
      "Epoch 626: Train_loss 26768728064.0, Validation_loss 27355095040.0, Seconds 0.03786969184875488\n",
      "Epoch 627: Train_loss 26767730688.0, Validation_loss 27353432064.0, Seconds 0.0332491397857666\n",
      "Epoch 628: Train_loss 26767382528.0, Validation_loss 27356833792.0, Seconds 0.032521963119506836\n",
      "Epoch 629: Train_loss 26767161344.0, Validation_loss 27361517568.0, Seconds 0.03614521026611328\n",
      "Epoch 630: Train_loss 26766368768.0, Validation_loss 27359737856.0, Seconds 0.0332949161529541\n",
      "Epoch 631: Train_loss 26766020608.0, Validation_loss 27362533376.0, Seconds 0.03289365768432617\n",
      "Epoch 632: Train_loss 26765692928.0, Validation_loss 27365144576.0, Seconds 0.03382253646850586\n",
      "Epoch 633: Train_loss 26765197312.0, Validation_loss 27366131712.0, Seconds 0.035978078842163086\n",
      "Epoch 634: Train_loss 26764632064.0, Validation_loss 27367882752.0, Seconds 0.030092954635620117\n",
      "Epoch 635: Train_loss 26764398592.0, Validation_loss 27370909696.0, Seconds 0.03375649452209473\n",
      "Epoch 636: Train_loss 26763769856.0, Validation_loss 27371538432.0, Seconds 0.035065650939941406\n",
      "Epoch 637: Train_loss 26763495424.0, Validation_loss 27374383104.0, Seconds 0.03401994705200195\n",
      "Epoch 638: Train_loss 26762741760.0, Validation_loss 27374870528.0, Seconds 0.031982421875\n",
      "Epoch 639: Train_loss 26762547200.0, Validation_loss 27377999872.0, Seconds 0.03401374816894531\n",
      "Epoch 640: Train_loss 26761963520.0, Validation_loss 27378475008.0, Seconds 0.033278703689575195\n",
      "Epoch 641: Train_loss 26761412608.0, Validation_loss 27379427328.0, Seconds 0.03379559516906738\n",
      "Epoch 642: Train_loss 26761017344.0, Validation_loss 27382714368.0, Seconds 0.034110069274902344\n",
      "Epoch 643: Train_loss 26760546304.0, Validation_loss 27383582720.0, Seconds 0.035864830017089844\n",
      "Epoch 644: Train_loss 26760237056.0, Validation_loss 27385542656.0, Seconds 0.032446861267089844\n",
      "Epoch 645: Train_loss 26759587840.0, Validation_loss 27384496128.0, Seconds 0.03250312805175781\n",
      "Epoch 646: Train_loss 26759419904.0, Validation_loss 27388198912.0, Seconds 0.03330588340759277\n",
      "Epoch 647: Train_loss 26758944768.0, Validation_loss 27389913088.0, Seconds 0.031627655029296875\n",
      "Epoch 648: Train_loss 26758486016.0, Validation_loss 27389736960.0, Seconds 0.032266855239868164\n",
      "Epoch 649: Train_loss 26758096896.0, Validation_loss 27391117312.0, Seconds 0.03388381004333496\n",
      "Epoch 650: Train_loss 26757849088.0, Validation_loss 27393941504.0, Seconds 0.03809523582458496\n",
      "Epoch 651: Train_loss 26757361664.0, Validation_loss 27394908160.0, Seconds 0.03181815147399902\n",
      "Epoch 652: Train_loss 26756902912.0, Validation_loss 27395221504.0, Seconds 0.0351865291595459\n",
      "Epoch 653: Train_loss 26756671488.0, Validation_loss 27397894144.0, Seconds 0.03211092948913574\n",
      "Epoch 654: Train_loss 26756194304.0, Validation_loss 27398850560.0, Seconds 0.030982255935668945\n",
      "Epoch 655: Train_loss 26755842048.0, Validation_loss 27399653376.0, Seconds 0.03385591506958008\n",
      "Epoch 656: Train_loss 26755565568.0, Validation_loss 27401480192.0, Seconds 0.0362396240234375\n",
      "Epoch 657: Train_loss 26755178496.0, Validation_loss 27403057152.0, Seconds 0.03392386436462402\n",
      "Epoch 658: Train_loss 26754740224.0, Validation_loss 27402946560.0, Seconds 0.034800052642822266\n",
      "Epoch 659: Train_loss 26754496512.0, Validation_loss 27406424064.0, Seconds 0.030827760696411133\n",
      "Epoch 660: Train_loss 26754035712.0, Validation_loss 27407814656.0, Seconds 0.033545494079589844\n",
      "Epoch 661: Train_loss 26753701888.0, Validation_loss 27407919104.0, Seconds 0.03354167938232422\n",
      "Epoch 662: Train_loss 26753232896.0, Validation_loss 27409682432.0, Seconds 0.0321042537689209\n",
      "Epoch 663: Train_loss 26752671744.0, Validation_loss 27410008064.0, Seconds 0.03402090072631836\n",
      "Epoch 664: Train_loss 26752100352.0, Validation_loss 27410673664.0, Seconds 0.03475809097290039\n",
      "Epoch 665: Train_loss 26751719424.0, Validation_loss 27412293632.0, Seconds 0.03416895866394043\n",
      "Epoch 666: Train_loss 26751260672.0, Validation_loss 27412885504.0, Seconds 0.03503060340881348\n",
      "Epoch 667: Train_loss 26750803968.0, Validation_loss 27414929408.0, Seconds 0.03606605529785156\n",
      "Epoch 668: Train_loss 26750156800.0, Validation_loss 27416285184.0, Seconds 0.033411264419555664\n",
      "Epoch 669: Train_loss 26749874176.0, Validation_loss 27418253312.0, Seconds 0.03339743614196777\n",
      "Epoch 670: Train_loss 26749396992.0, Validation_loss 27418998784.0, Seconds 0.034258365631103516\n",
      "Epoch 671: Train_loss 26749018112.0, Validation_loss 27421648896.0, Seconds 0.03697991371154785\n",
      "Epoch 672: Train_loss 26748528640.0, Validation_loss 27423291392.0, Seconds 0.03388524055480957\n",
      "Epoch 673: Train_loss 26748172288.0, Validation_loss 27424299008.0, Seconds 0.03325653076171875\n",
      "Epoch 674: Train_loss 26747754496.0, Validation_loss 27426631680.0, Seconds 0.03363752365112305\n",
      "Epoch 675: Train_loss 26747252736.0, Validation_loss 27428642816.0, Seconds 0.03308606147766113\n",
      "Epoch 676: Train_loss 26746882048.0, Validation_loss 27430281216.0, Seconds 0.03512001037597656\n",
      "Epoch 677: Train_loss 26746456064.0, Validation_loss 27432374272.0, Seconds 0.03401756286621094\n",
      "Epoch 678: Train_loss 26746028032.0, Validation_loss 27434323968.0, Seconds 0.03577375411987305\n",
      "Epoch 679: Train_loss 26745587712.0, Validation_loss 27436816384.0, Seconds 0.03615999221801758\n",
      "Epoch 680: Train_loss 26745063424.0, Validation_loss 27437514752.0, Seconds 0.037024736404418945\n",
      "Epoch 681: Train_loss 26744754176.0, Validation_loss 27440230400.0, Seconds 0.033887386322021484\n",
      "Epoch 682: Train_loss 26744393728.0, Validation_loss 27442259968.0, Seconds 0.03221917152404785\n",
      "Epoch 683: Train_loss 26743828480.0, Validation_loss 27442290688.0, Seconds 0.03570270538330078\n",
      "Epoch 684: Train_loss 26743398400.0, Validation_loss 27446110208.0, Seconds 0.033135175704956055\n",
      "Epoch 685: Train_loss 26743050240.0, Validation_loss 27448309760.0, Seconds 0.03406667709350586\n",
      "Epoch 686: Train_loss 26742597632.0, Validation_loss 27449839616.0, Seconds 0.032140254974365234\n",
      "Epoch 687: Train_loss 26742001664.0, Validation_loss 27450746880.0, Seconds 0.04044508934020996\n",
      "Epoch 688: Train_loss 26741819392.0, Validation_loss 27453927424.0, Seconds 0.034479379653930664\n",
      "Epoch 689: Train_loss 26741243904.0, Validation_loss 27453558784.0, Seconds 0.03581833839416504\n",
      "Epoch 690: Train_loss 26740963328.0, Validation_loss 27456892928.0, Seconds 0.033055782318115234\n",
      "Epoch 691: Train_loss 26740473856.0, Validation_loss 27459119104.0, Seconds 0.03765606880187988\n",
      "Epoch 692: Train_loss 26740248576.0, Validation_loss 27461316608.0, Seconds 0.03147459030151367\n",
      "Epoch 693: Train_loss 26739877888.0, Validation_loss 27462670336.0, Seconds 0.036435842514038086\n",
      "Epoch 694: Train_loss 26739382272.0, Validation_loss 27464097792.0, Seconds 0.03531932830810547\n",
      "Epoch 695: Train_loss 26739132416.0, Validation_loss 27466643456.0, Seconds 0.032175540924072266\n",
      "Epoch 696: Train_loss 26738661376.0, Validation_loss 27467171840.0, Seconds 0.032207489013671875\n",
      "Epoch 697: Train_loss 26738432000.0, Validation_loss 27469078528.0, Seconds 0.03393054008483887\n",
      "Epoch 698: Train_loss 26738069504.0, Validation_loss 27470405632.0, Seconds 0.04262852668762207\n",
      "Epoch 699: Train_loss 26737557504.0, Validation_loss 27470999552.0, Seconds 0.032068490982055664\n",
      "Epoch 700: Train_loss 26737344512.0, Validation_loss 27473659904.0, Seconds 0.03600263595581055\n",
      "Epoch 701: Train_loss 26736957440.0, Validation_loss 27473920000.0, Seconds 0.0339047908782959\n",
      "Epoch 702: Train_loss 26736564224.0, Validation_loss 27476434944.0, Seconds 0.0320894718170166\n",
      "Epoch 703: Train_loss 26736220160.0, Validation_loss 27477886976.0, Seconds 0.03216433525085449\n",
      "Epoch 704: Train_loss 26735994880.0, Validation_loss 27480064000.0, Seconds 0.03215479850769043\n",
      "Epoch 705: Train_loss 26735499264.0, Validation_loss 27480739840.0, Seconds 0.03461003303527832\n",
      "Epoch 706: Train_loss 26735267840.0, Validation_loss 27484219392.0, Seconds 0.03233671188354492\n",
      "Epoch 707: Train_loss 26734870528.0, Validation_loss 27485313024.0, Seconds 0.030995845794677734\n",
      "Epoch 708: Train_loss 26734567424.0, Validation_loss 27486623744.0, Seconds 0.033039093017578125\n",
      "Epoch 709: Train_loss 26734166016.0, Validation_loss 27488761856.0, Seconds 0.0368807315826416\n",
      "Epoch 710: Train_loss 26733967360.0, Validation_loss 27490023424.0, Seconds 0.03220820426940918\n",
      "Epoch 711: Train_loss 26733545472.0, Validation_loss 27490387968.0, Seconds 0.03368258476257324\n",
      "Epoch 712: Train_loss 26733185024.0, Validation_loss 27491317760.0, Seconds 0.03333544731140137\n",
      "Epoch 713: Train_loss 26733035520.0, Validation_loss 27492009984.0, Seconds 0.032631635665893555\n",
      "Epoch 714: Train_loss 26732609536.0, Validation_loss 27492870144.0, Seconds 0.03386044502258301\n",
      "Epoch 715: Train_loss 26732218368.0, Validation_loss 27492679680.0, Seconds 0.03132462501525879\n",
      "Epoch 716: Train_loss 26732242944.0, Validation_loss 27495391232.0, Seconds 0.03133726119995117\n",
      "Epoch 717: Train_loss 26731585536.0, Validation_loss 27495204864.0, Seconds 0.03465390205383301\n",
      "Epoch 718: Train_loss 26731405312.0, Validation_loss 27497066496.0, Seconds 0.03298020362854004\n",
      "Epoch 719: Train_loss 26731053056.0, Validation_loss 27497807872.0, Seconds 0.03753399848937988\n",
      "Epoch 720: Train_loss 26730737664.0, Validation_loss 27498960896.0, Seconds 0.032511234283447266\n",
      "Epoch 721: Train_loss 26730592256.0, Validation_loss 27501678592.0, Seconds 0.03470325469970703\n",
      "Epoch 722: Train_loss 26730092544.0, Validation_loss 27501709312.0, Seconds 0.036145925521850586\n",
      "Epoch 723: Train_loss 26729918464.0, Validation_loss 27502555136.0, Seconds 0.036514997482299805\n",
      "Epoch 724: Train_loss 26729510912.0, Validation_loss 27502835712.0, Seconds 0.033410072326660156\n",
      "Epoch 725: Train_loss 26729396224.0, Validation_loss 27504025600.0, Seconds 0.034102678298950195\n",
      "Epoch 726: Train_loss 26729074688.0, Validation_loss 27505743872.0, Seconds 0.03884410858154297\n",
      "Epoch 727: Train_loss 26728726528.0, Validation_loss 27506044928.0, Seconds 0.03724861145019531\n",
      "Epoch 728: Train_loss 26728392704.0, Validation_loss 27505876992.0, Seconds 0.03614974021911621\n",
      "Epoch 729: Train_loss 26728288256.0, Validation_loss 27507263488.0, Seconds 0.03195357322692871\n",
      "Epoch 730: Train_loss 26727979008.0, Validation_loss 27509127168.0, Seconds 0.03070378303527832\n",
      "Epoch 731: Train_loss 26727585792.0, Validation_loss 27509161984.0, Seconds 0.034207820892333984\n",
      "Epoch 732: Train_loss 26727458816.0, Validation_loss 27509356544.0, Seconds 0.03370308876037598\n",
      "Epoch 733: Train_loss 26727122944.0, Validation_loss 27509639168.0, Seconds 0.04120898246765137\n",
      "Epoch 734: Train_loss 26726975488.0, Validation_loss 27510943744.0, Seconds 0.03390049934387207\n",
      "Epoch 735: Train_loss 26726760448.0, Validation_loss 27512221696.0, Seconds 0.0353245735168457\n",
      "Epoch 736: Train_loss 26726543360.0, Validation_loss 27511885824.0, Seconds 0.03763294219970703\n",
      "Epoch 737: Train_loss 26726209536.0, Validation_loss 27513202688.0, Seconds 0.036104440689086914\n",
      "Epoch 738: Train_loss 26726068224.0, Validation_loss 27513706496.0, Seconds 0.039907217025756836\n",
      "Epoch 739: Train_loss 26725853184.0, Validation_loss 27513053184.0, Seconds 0.034047603607177734\n",
      "Epoch 740: Train_loss 26725558272.0, Validation_loss 27513618432.0, Seconds 0.035250186920166016\n",
      "Epoch 741: Train_loss 26725369856.0, Validation_loss 27514169344.0, Seconds 0.037030935287475586\n",
      "Epoch 742: Train_loss 26725122048.0, Validation_loss 27514677248.0, Seconds 0.03866887092590332\n",
      "Epoch 743: Train_loss 26724861952.0, Validation_loss 27515498496.0, Seconds 0.03675961494445801\n",
      "Epoch 744: Train_loss 26724820992.0, Validation_loss 27515500544.0, Seconds 0.03953289985656738\n",
      "Epoch 745: Train_loss 26724466688.0, Validation_loss 27515713536.0, Seconds 0.04068446159362793\n",
      "Epoch 746: Train_loss 26724278272.0, Validation_loss 27516639232.0, Seconds 0.038425445556640625\n",
      "Epoch 747: Train_loss 26724124672.0, Validation_loss 27516811264.0, Seconds 0.035753488540649414\n",
      "Epoch 748: Train_loss 26723930112.0, Validation_loss 27516477440.0, Seconds 0.032918691635131836\n",
      "Epoch 749: Train_loss 26723637248.0, Validation_loss 27516332032.0, Seconds 0.03512454032897949\n",
      "Epoch 750: Train_loss 26723581952.0, Validation_loss 27517779968.0, Seconds 0.03335762023925781\n",
      "Epoch 751: Train_loss 26723213312.0, Validation_loss 27517396992.0, Seconds 0.03572678565979004\n",
      "Epoch 752: Train_loss 26723108864.0, Validation_loss 27519297536.0, Seconds 0.03866720199584961\n",
      "Epoch 753: Train_loss 26722787328.0, Validation_loss 27519371264.0, Seconds 0.03705239295959473\n",
      "Epoch 754: Train_loss 26722742272.0, Validation_loss 27519760384.0, Seconds 0.03354763984680176\n",
      "Epoch 755: Train_loss 26722453504.0, Validation_loss 27520790528.0, Seconds 0.03554224967956543\n",
      "Epoch 756: Train_loss 26722174976.0, Validation_loss 27520249856.0, Seconds 0.033141374588012695\n",
      "Epoch 757: Train_loss 26722195456.0, Validation_loss 27521667072.0, Seconds 0.03876948356628418\n",
      "Epoch 758: Train_loss 26721867776.0, Validation_loss 27520888832.0, Seconds 0.034366607666015625\n",
      "Epoch 759: Train_loss 26721693696.0, Validation_loss 27522273280.0, Seconds 0.034909963607788086\n",
      "Epoch 760: Train_loss 26721456128.0, Validation_loss 27522617344.0, Seconds 0.0377650260925293\n",
      "Epoch 761: Train_loss 26721329152.0, Validation_loss 27521830912.0, Seconds 0.0368647575378418\n",
      "Epoch 762: Train_loss 26721114112.0, Validation_loss 27522363392.0, Seconds 0.034072160720825195\n",
      "Epoch 763: Train_loss 26721044480.0, Validation_loss 27523913728.0, Seconds 0.032926321029663086\n",
      "Epoch 764: Train_loss 26720819200.0, Validation_loss 27523543040.0, Seconds 0.035187482833862305\n",
      "Epoch 765: Train_loss 26720458752.0, Validation_loss 27523067904.0, Seconds 0.03784751892089844\n",
      "Epoch 766: Train_loss 26720442368.0, Validation_loss 27523891200.0, Seconds 0.03544282913208008\n",
      "Epoch 767: Train_loss 26720143360.0, Validation_loss 27523964928.0, Seconds 0.03979802131652832\n",
      "Epoch 768: Train_loss 26720018432.0, Validation_loss 27523790848.0, Seconds 0.036652565002441406\n",
      "Epoch 769: Train_loss 26719856640.0, Validation_loss 27524870144.0, Seconds 0.03657674789428711\n",
      "Epoch 770: Train_loss 26719625216.0, Validation_loss 27525502976.0, Seconds 0.03775596618652344\n",
      "Epoch 771: Train_loss 26719338496.0, Validation_loss 27525332992.0, Seconds 0.04036068916320801\n",
      "Epoch 772: Train_loss 26719381504.0, Validation_loss 27527129088.0, Seconds 0.03368258476257324\n",
      "Epoch 773: Train_loss 26719074304.0, Validation_loss 27526160384.0, Seconds 0.0318293571472168\n",
      "Epoch 774: Train_loss 26718982144.0, Validation_loss 27526451200.0, Seconds 0.034923553466796875\n",
      "Epoch 775: Train_loss 26718681088.0, Validation_loss 27527266304.0, Seconds 0.03327465057373047\n",
      "Epoch 776: Train_loss 26718560256.0, Validation_loss 27527182336.0, Seconds 0.036733150482177734\n",
      "Epoch 777: Train_loss 26718398464.0, Validation_loss 27527884800.0, Seconds 0.03834342956542969\n",
      "Epoch 778: Train_loss 26718144512.0, Validation_loss 27528001536.0, Seconds 0.04291057586669922\n",
      "Epoch 779: Train_loss 26718066688.0, Validation_loss 27528679424.0, Seconds 0.036089420318603516\n",
      "Epoch 780: Train_loss 26717870080.0, Validation_loss 27528683520.0, Seconds 0.036615848541259766\n",
      "Epoch 781: Train_loss 26717552640.0, Validation_loss 27528851456.0, Seconds 0.03702545166015625\n",
      "Epoch 782: Train_loss 26717499392.0, Validation_loss 27528859648.0, Seconds 0.03906583786010742\n",
      "Epoch 783: Train_loss 26717286400.0, Validation_loss 27527958528.0, Seconds 0.03321957588195801\n",
      "Epoch 784: Train_loss 26717245440.0, Validation_loss 27530260480.0, Seconds 0.03632402420043945\n",
      "Epoch 785: Train_loss 26716874752.0, Validation_loss 27529809920.0, Seconds 0.03832864761352539\n",
      "Epoch 786: Train_loss 26716755968.0, Validation_loss 27530106880.0, Seconds 0.031443119049072266\n",
      "Epoch 787: Train_loss 26716649472.0, Validation_loss 27530764288.0, Seconds 0.03708481788635254\n",
      "Epoch 788: Train_loss 26716377088.0, Validation_loss 27530108928.0, Seconds 0.03453564643859863\n",
      "Epoch 789: Train_loss 26716166144.0, Validation_loss 27529250816.0, Seconds 0.036040544509887695\n",
      "Epoch 790: Train_loss 26716196864.0, Validation_loss 27530362880.0, Seconds 0.036683082580566406\n",
      "Epoch 791: Train_loss 26715811840.0, Validation_loss 27529463808.0, Seconds 0.03864121437072754\n",
      "Epoch 792: Train_loss 26715678720.0, Validation_loss 27530780672.0, Seconds 0.0326075553894043\n",
      "Epoch 793: Train_loss 26715498496.0, Validation_loss 27531204608.0, Seconds 0.032067060470581055\n",
      "Epoch 794: Train_loss 26715213824.0, Validation_loss 27530342400.0, Seconds 0.0430607795715332\n",
      "Epoch 795: Train_loss 26715127808.0, Validation_loss 27530369024.0, Seconds 0.03699350357055664\n",
      "Epoch 796: Train_loss 26714963968.0, Validation_loss 27530768384.0, Seconds 0.04221343994140625\n",
      "Epoch 797: Train_loss 26714750976.0, Validation_loss 27531491328.0, Seconds 0.03492617607116699\n",
      "Epoch 798: Train_loss 26714624000.0, Validation_loss 27532748800.0, Seconds 0.034094810485839844\n",
      "Epoch 799: Train_loss 26714204160.0, Validation_loss 27531737088.0, Seconds 0.037132978439331055\n",
      "Epoch 800: Train_loss 26714380288.0, Validation_loss 27533494272.0, Seconds 0.03338027000427246\n",
      "Epoch 801: Train_loss 26714052608.0, Validation_loss 27532113920.0, Seconds 0.036663055419921875\n",
      "Epoch 802: Train_loss 26713706496.0, Validation_loss 27532267520.0, Seconds 0.03550577163696289\n",
      "Epoch 803: Train_loss 26713755648.0, Validation_loss 27533996032.0, Seconds 0.037333011627197266\n",
      "Epoch 804: Train_loss 26713487360.0, Validation_loss 27532859392.0, Seconds 0.03293418884277344\n",
      "Epoch 805: Train_loss 26713243648.0, Validation_loss 27533445120.0, Seconds 0.03581523895263672\n",
      "Epoch 806: Train_loss 26713260032.0, Validation_loss 27534016512.0, Seconds 0.03707575798034668\n",
      "Epoch 807: Train_loss 26713034752.0, Validation_loss 27533152256.0, Seconds 0.03414607048034668\n",
      "Epoch 808: Train_loss 26712791040.0, Validation_loss 27533168640.0, Seconds 0.03649449348449707\n",
      "Epoch 809: Train_loss 26712719360.0, Validation_loss 27534389248.0, Seconds 0.03747987747192383\n",
      "Epoch 810: Train_loss 26712522752.0, Validation_loss 27533535232.0, Seconds 0.036712646484375\n",
      "Epoch 811: Train_loss 26712309760.0, Validation_loss 27533172736.0, Seconds 0.03335905075073242\n",
      "Epoch 812: Train_loss 26712307712.0, Validation_loss 27534759936.0, Seconds 0.037946224212646484\n",
      "Epoch 813: Train_loss 26712033280.0, Validation_loss 27533240320.0, Seconds 0.03374886512756348\n",
      "Epoch 814: Train_loss 26711961600.0, Validation_loss 27534313472.0, Seconds 0.03601670265197754\n",
      "Epoch 815: Train_loss 26711556096.0, Validation_loss 27533647872.0, Seconds 0.03650832176208496\n",
      "Epoch 816: Train_loss 26711603200.0, Validation_loss 27534544896.0, Seconds 0.03556680679321289\n",
      "Epoch 817: Train_loss 26711300096.0, Validation_loss 27533879296.0, Seconds 0.033982276916503906\n",
      "Epoch 818: Train_loss 26711281664.0, Validation_loss 27534589952.0, Seconds 0.03932905197143555\n",
      "Epoch 819: Train_loss 26711099392.0, Validation_loss 27534086144.0, Seconds 0.036512136459350586\n",
      "Epoch 820: Train_loss 26710779904.0, Validation_loss 27533590528.0, Seconds 0.03954601287841797\n",
      "Epoch 821: Train_loss 26710663168.0, Validation_loss 27534319616.0, Seconds 0.035555124282836914\n",
      "Epoch 822: Train_loss 26710464512.0, Validation_loss 27534450688.0, Seconds 0.03742361068725586\n",
      "Epoch 823: Train_loss 26710341632.0, Validation_loss 27534508032.0, Seconds 0.03548622131347656\n",
      "Epoch 824: Train_loss 26710274048.0, Validation_loss 27534778368.0, Seconds 0.03519773483276367\n",
      "Epoch 825: Train_loss 26709878784.0, Validation_loss 27534235648.0, Seconds 0.1457815170288086\n",
      "Epoch 826: Train_loss 26709932032.0, Validation_loss 27535134720.0, Seconds 0.039249420166015625\n",
      "Epoch 827: Train_loss 26709680128.0, Validation_loss 27534585856.0, Seconds 0.04004406929016113\n",
      "Epoch 828: Train_loss 26709557248.0, Validation_loss 27535249408.0, Seconds 0.03841829299926758\n",
      "Epoch 829: Train_loss 26709409792.0, Validation_loss 27534927872.0, Seconds 0.0392000675201416\n",
      "Epoch 830: Train_loss 26709192704.0, Validation_loss 27536033792.0, Seconds 0.03412055969238281\n",
      "Epoch 831: Train_loss 26709098496.0, Validation_loss 27536986112.0, Seconds 0.03496050834655762\n",
      "Epoch 832: Train_loss 26708903936.0, Validation_loss 27535929344.0, Seconds 0.03705430030822754\n",
      "Epoch 833: Train_loss 26708742144.0, Validation_loss 27536236544.0, Seconds 0.0354156494140625\n",
      "Epoch 834: Train_loss 26708723712.0, Validation_loss 27536658432.0, Seconds 0.03557133674621582\n",
      "Epoch 835: Train_loss 26708570112.0, Validation_loss 27536906240.0, Seconds 0.03332972526550293\n",
      "Epoch 836: Train_loss 26708312064.0, Validation_loss 27537027072.0, Seconds 0.03511309623718262\n",
      "Epoch 837: Train_loss 26708166656.0, Validation_loss 27536846848.0, Seconds 0.04075121879577637\n",
      "Epoch 838: Train_loss 26708226048.0, Validation_loss 27535394816.0, Seconds 0.03512859344482422\n",
      "Epoch 839: Train_loss 26707838976.0, Validation_loss 27535706112.0, Seconds 0.0321044921875\n",
      "Epoch 840: Train_loss 26707869696.0, Validation_loss 27536535552.0, Seconds 0.04103803634643555\n",
      "Epoch 841: Train_loss 26707619840.0, Validation_loss 27536631808.0, Seconds 0.034560441970825195\n",
      "Epoch 842: Train_loss 26707466240.0, Validation_loss 27536939008.0, Seconds 0.034655094146728516\n",
      "Epoch 843: Train_loss 26707326976.0, Validation_loss 27536900096.0, Seconds 0.03763008117675781\n",
      "Epoch 844: Train_loss 26707179520.0, Validation_loss 27537205248.0, Seconds 0.045931339263916016\n",
      "Epoch 845: Train_loss 26707175424.0, Validation_loss 27537547264.0, Seconds 0.031647682189941406\n",
      "Epoch 846: Train_loss 26706970624.0, Validation_loss 27535796224.0, Seconds 0.034221649169921875\n",
      "Epoch 847: Train_loss 26706905088.0, Validation_loss 27537285120.0, Seconds 0.03212594985961914\n",
      "Epoch 848: Train_loss 26706569216.0, Validation_loss 27537219584.0, Seconds 0.03783869743347168\n",
      "Epoch 849: Train_loss 26706450432.0, Validation_loss 27537170432.0, Seconds 0.03917646408081055\n",
      "Epoch 850: Train_loss 26706280448.0, Validation_loss 27537135616.0, Seconds 0.04153561592102051\n",
      "Epoch 851: Train_loss 26706282496.0, Validation_loss 27537973248.0, Seconds 0.03820323944091797\n",
      "Epoch 852: Train_loss 26706006016.0, Validation_loss 27536148480.0, Seconds 0.03918170928955078\n",
      "Epoch 853: Train_loss 26705950720.0, Validation_loss 27537741824.0, Seconds 0.04095196723937988\n",
      "Epoch 854: Train_loss 26705647616.0, Validation_loss 27536824320.0, Seconds 0.03629636764526367\n",
      "Epoch 855: Train_loss 26705514496.0, Validation_loss 27536961536.0, Seconds 0.034030914306640625\n",
      "Epoch 856: Train_loss 26705494016.0, Validation_loss 27537659904.0, Seconds 0.03558802604675293\n",
      "Epoch 857: Train_loss 26705285120.0, Validation_loss 27537133568.0, Seconds 0.03325939178466797\n",
      "Epoch 858: Train_loss 26705332224.0, Validation_loss 27537049600.0, Seconds 0.0338594913482666\n",
      "Epoch 859: Train_loss 26705061888.0, Validation_loss 27537086464.0, Seconds 0.034885406494140625\n",
      "Epoch 860: Train_loss 26705006592.0, Validation_loss 27538810880.0, Seconds 0.03289604187011719\n",
      "Epoch 861: Train_loss 26704758784.0, Validation_loss 27537770496.0, Seconds 0.03828287124633789\n",
      "Epoch 862: Train_loss 26704660480.0, Validation_loss 27538288640.0, Seconds 0.03763008117675781\n",
      "Epoch 863: Train_loss 26704556032.0, Validation_loss 27538743296.0, Seconds 0.03645730018615723\n",
      "Epoch 864: Train_loss 26704291840.0, Validation_loss 27537698816.0, Seconds 0.03709983825683594\n",
      "Epoch 865: Train_loss 26704248832.0, Validation_loss 27537485824.0, Seconds 0.03676629066467285\n",
      "Epoch 866: Train_loss 26704488448.0, Validation_loss 27537965056.0, Seconds 0.036862850189208984\n",
      "Epoch 867: Train_loss 26703933440.0, Validation_loss 27536979968.0, Seconds 0.03908252716064453\n",
      "Epoch 868: Train_loss 26703919104.0, Validation_loss 27538278400.0, Seconds 0.037380218505859375\n",
      "Epoch 869: Train_loss 26703751168.0, Validation_loss 27537346560.0, Seconds 0.03550100326538086\n",
      "Epoch 870: Train_loss 26703618048.0, Validation_loss 27536812032.0, Seconds 0.037526845932006836\n",
      "Epoch 871: Train_loss 26703650816.0, Validation_loss 27536340992.0, Seconds 0.034876346588134766\n",
      "Epoch 872: Train_loss 26703409152.0, Validation_loss 27536357376.0, Seconds 0.034108877182006836\n",
      "Epoch 873: Train_loss 26703355904.0, Validation_loss 27537053696.0, Seconds 0.035004377365112305\n",
      "Epoch 874: Train_loss 26703003648.0, Validation_loss 27536633856.0, Seconds 0.03281569480895996\n",
      "Epoch 875: Train_loss 26702977024.0, Validation_loss 27536627712.0, Seconds 0.03566169738769531\n",
      "Epoch 876: Train_loss 26703042560.0, Validation_loss 27535898624.0, Seconds 0.03729391098022461\n",
      "Epoch 877: Train_loss 26702725120.0, Validation_loss 27536074752.0, Seconds 0.038697242736816406\n",
      "Epoch 878: Train_loss 26702548992.0, Validation_loss 27536482304.0, Seconds 0.036894798278808594\n",
      "Epoch 879: Train_loss 26702510080.0, Validation_loss 27537786880.0, Seconds 0.03702998161315918\n",
      "Epoch 880: Train_loss 26702309376.0, Validation_loss 27537524736.0, Seconds 0.039525747299194336\n",
      "Epoch 881: Train_loss 26702094336.0, Validation_loss 27536556032.0, Seconds 0.03664374351501465\n",
      "Epoch 882: Train_loss 26702223360.0, Validation_loss 27537213440.0, Seconds 0.032122135162353516\n",
      "Epoch 883: Train_loss 26702028800.0, Validation_loss 27537213440.0, Seconds 0.03484702110290527\n",
      "Epoch 884: Train_loss 26701797376.0, Validation_loss 27536074752.0, Seconds 0.03496241569519043\n",
      "Epoch 885: Train_loss 26701785088.0, Validation_loss 27534813184.0, Seconds 0.03913521766662598\n",
      "Epoch 886: Train_loss 26701795328.0, Validation_loss 27535708160.0, Seconds 0.03432655334472656\n",
      "Epoch 887: Train_loss 26701504512.0, Validation_loss 27535869952.0, Seconds 0.034578800201416016\n",
      "Epoch 888: Train_loss 26701209600.0, Validation_loss 27535519744.0, Seconds 0.032109737396240234\n",
      "Epoch 889: Train_loss 26701256704.0, Validation_loss 27536863232.0, Seconds 0.03889155387878418\n",
      "Epoch 890: Train_loss 26700982272.0, Validation_loss 27535525888.0, Seconds 0.03093099594116211\n",
      "Epoch 891: Train_loss 26701074432.0, Validation_loss 27536654336.0, Seconds 0.03433489799499512\n",
      "Epoch 892: Train_loss 26700820480.0, Validation_loss 27534563328.0, Seconds 0.03292441368103027\n",
      "Epoch 893: Train_loss 26700845056.0, Validation_loss 27536459776.0, Seconds 0.03806638717651367\n",
      "Epoch 894: Train_loss 26700652544.0, Validation_loss 27537072128.0, Seconds 0.03866934776306152\n",
      "Epoch 895: Train_loss 26700384256.0, Validation_loss 27536420864.0, Seconds 0.035280466079711914\n",
      "Epoch 896: Train_loss 26700544000.0, Validation_loss 27535749120.0, Seconds 0.042743682861328125\n",
      "Epoch 897: Train_loss 26700103680.0, Validation_loss 27534878720.0, Seconds 0.03495621681213379\n",
      "Epoch 898: Train_loss 26700115968.0, Validation_loss 27536308224.0, Seconds 0.0364069938659668\n",
      "Epoch 899: Train_loss 26700066816.0, Validation_loss 27536138240.0, Seconds 0.032981157302856445\n",
      "Epoch 900: Train_loss 26699956224.0, Validation_loss 27534372864.0, Seconds 0.03417325019836426\n",
      "Epoch 901: Train_loss 26699735040.0, Validation_loss 27534948352.0, Seconds 0.03267025947570801\n",
      "Epoch 902: Train_loss 26699685888.0, Validation_loss 27536713728.0, Seconds 0.040125131607055664\n",
      "Epoch 903: Train_loss 26699546624.0, Validation_loss 27535460352.0, Seconds 0.03987574577331543\n",
      "Epoch 904: Train_loss 26699436032.0, Validation_loss 27533402112.0, Seconds 0.03616023063659668\n",
      "Epoch 905: Train_loss 26699470848.0, Validation_loss 27534616576.0, Seconds 0.03662371635437012\n",
      "Epoch 906: Train_loss 26699249664.0, Validation_loss 27534632960.0, Seconds 0.037064552307128906\n",
      "Epoch 907: Train_loss 26699134976.0, Validation_loss 27535241216.0, Seconds 0.035065650939941406\n",
      "Epoch 908: Train_loss 26698987520.0, Validation_loss 27534977024.0, Seconds 0.036229610443115234\n",
      "Epoch 909: Train_loss 26698756096.0, Validation_loss 27534565376.0, Seconds 0.03691720962524414\n",
      "Epoch 910: Train_loss 26698776576.0, Validation_loss 27535677440.0, Seconds 0.035942792892456055\n",
      "Epoch 911: Train_loss 26698510336.0, Validation_loss 27534276608.0, Seconds 0.03399324417114258\n",
      "Epoch 912: Train_loss 26698536960.0, Validation_loss 27533903872.0, Seconds 0.03693246841430664\n",
      "Epoch 913: Train_loss 26698414080.0, Validation_loss 27535265792.0, Seconds 0.04054570198059082\n",
      "Epoch 914: Train_loss 26698094592.0, Validation_loss 27534516224.0, Seconds 0.03260684013366699\n",
      "Epoch 915: Train_loss 26698276864.0, Validation_loss 27535833088.0, Seconds 0.031775712966918945\n",
      "Epoch 916: Train_loss 26697945088.0, Validation_loss 27533043712.0, Seconds 0.03894543647766113\n",
      "Epoch 917: Train_loss 26697902080.0, Validation_loss 27536072704.0, Seconds 0.03408479690551758\n",
      "Epoch 918: Train_loss 26697762816.0, Validation_loss 27536408576.0, Seconds 0.03114175796508789\n",
      "Epoch 919: Train_loss 26697658368.0, Validation_loss 27536021504.0, Seconds 0.033779144287109375\n",
      "Epoch 920: Train_loss 26697617408.0, Validation_loss 27536588800.0, Seconds 0.03361988067626953\n",
      "Epoch 921: Train_loss 26697474048.0, Validation_loss 27535491072.0, Seconds 0.03453183174133301\n",
      "Epoch 922: Train_loss 26697422848.0, Validation_loss 27533918208.0, Seconds 0.03280496597290039\n",
      "Epoch 923: Train_loss 26697371648.0, Validation_loss 27535802368.0, Seconds 0.03512072563171387\n",
      "Epoch 924: Train_loss 26696986624.0, Validation_loss 27535003648.0, Seconds 0.03610348701477051\n",
      "Epoch 925: Train_loss 26697054208.0, Validation_loss 27535405056.0, Seconds 0.03334355354309082\n",
      "Epoch 926: Train_loss 26697013248.0, Validation_loss 27533774848.0, Seconds 0.03405022621154785\n",
      "Epoch 927: Train_loss 26696810496.0, Validation_loss 27534133248.0, Seconds 0.03442859649658203\n",
      "Epoch 928: Train_loss 26696699904.0, Validation_loss 27535106048.0, Seconds 0.03246736526489258\n",
      "Epoch 929: Train_loss 26696452096.0, Validation_loss 27534954496.0, Seconds 0.034612417221069336\n",
      "Epoch 930: Train_loss 26696560640.0, Validation_loss 27534571520.0, Seconds 0.03621530532836914\n",
      "Epoch 931: Train_loss 26696587264.0, Validation_loss 27533570048.0, Seconds 0.036066532135009766\n",
      "Epoch 932: Train_loss 26696304640.0, Validation_loss 27534061568.0, Seconds 0.0347437858581543\n",
      "Epoch 933: Train_loss 26696048640.0, Validation_loss 27534503936.0, Seconds 0.03412628173828125\n",
      "Epoch 934: Train_loss 26696022016.0, Validation_loss 27534012416.0, Seconds 0.03251457214355469\n",
      "Epoch 935: Train_loss 26696165376.0, Validation_loss 27532744704.0, Seconds 0.03544449806213379\n",
      "Epoch 936: Train_loss 26695835648.0, Validation_loss 27533590528.0, Seconds 0.029152631759643555\n",
      "Epoch 937: Train_loss 26695864320.0, Validation_loss 27534860288.0, Seconds 0.03617286682128906\n",
      "Epoch 938: Train_loss 26695628800.0, Validation_loss 27532910592.0, Seconds 0.030777692794799805\n",
      "Epoch 939: Train_loss 26695729152.0, Validation_loss 27531988992.0, Seconds 0.034852027893066406\n",
      "Epoch 940: Train_loss 26695331840.0, Validation_loss 27532001280.0, Seconds 0.03512978553771973\n",
      "Epoch 941: Train_loss 26695243776.0, Validation_loss 27533103104.0, Seconds 0.03415393829345703\n",
      "Epoch 942: Train_loss 26695186432.0, Validation_loss 27533072384.0, Seconds 0.03258514404296875\n",
      "Epoch 943: Train_loss 26694844416.0, Validation_loss 27531130880.0, Seconds 0.03615903854370117\n",
      "Epoch 944: Train_loss 26695168000.0, Validation_loss 27531829248.0, Seconds 0.03887748718261719\n",
      "Epoch 945: Train_loss 26694723584.0, Validation_loss 27531401216.0, Seconds 0.03413653373718262\n",
      "Epoch 946: Train_loss 26694627328.0, Validation_loss 27531796480.0, Seconds 0.03813767433166504\n",
      "Epoch 947: Train_loss 26694567936.0, Validation_loss 27531264000.0, Seconds 0.037580251693725586\n",
      "Epoch 948: Train_loss 26694391808.0, Validation_loss 27530082304.0, Seconds 0.03304576873779297\n",
      "Epoch 949: Train_loss 26694418432.0, Validation_loss 27531802624.0, Seconds 0.03912925720214844\n",
      "Epoch 950: Train_loss 26694144000.0, Validation_loss 27531087872.0, Seconds 0.03913116455078125\n",
      "Epoch 951: Train_loss 26693883904.0, Validation_loss 27529728000.0, Seconds 0.038387298583984375\n",
      "Epoch 952: Train_loss 26694103040.0, Validation_loss 27529994240.0, Seconds 0.03464961051940918\n",
      "Epoch 953: Train_loss 26693953536.0, Validation_loss 27530172416.0, Seconds 0.036827802658081055\n",
      "Epoch 954: Train_loss 26693531648.0, Validation_loss 27529170944.0, Seconds 0.035295724868774414\n",
      "Epoch 955: Train_loss 26693556224.0, Validation_loss 27529646080.0, Seconds 0.03699064254760742\n",
      "Epoch 956: Train_loss 26693519360.0, Validation_loss 27528300544.0, Seconds 0.03598737716674805\n",
      "Epoch 957: Train_loss 26693388288.0, Validation_loss 27529814016.0, Seconds 0.03200817108154297\n",
      "Epoch 958: Train_loss 26693138432.0, Validation_loss 27529490432.0, Seconds 0.03463292121887207\n",
      "Epoch 959: Train_loss 26693021696.0, Validation_loss 27528757248.0, Seconds 0.038248300552368164\n",
      "Epoch 960: Train_loss 26693154816.0, Validation_loss 27529015296.0, Seconds 0.03383803367614746\n",
      "Epoch 961: Train_loss 26692837376.0, Validation_loss 27529482240.0, Seconds 0.03533029556274414\n",
      "Epoch 962: Train_loss 26692722688.0, Validation_loss 27529443328.0, Seconds 0.039655447006225586\n",
      "Epoch 963: Train_loss 26692655104.0, Validation_loss 27529961472.0, Seconds 0.03894400596618652\n",
      "Epoch 964: Train_loss 26692626432.0, Validation_loss 27528994816.0, Seconds 0.03124690055847168\n",
      "Epoch 965: Train_loss 26692435968.0, Validation_loss 27530156032.0, Seconds 0.03200221061706543\n",
      "Epoch 966: Train_loss 26692188160.0, Validation_loss 27530240000.0, Seconds 0.031133413314819336\n",
      "Epoch 967: Train_loss 26692059136.0, Validation_loss 27529404416.0, Seconds 0.03157687187194824\n",
      "Epoch 968: Train_loss 26692298752.0, Validation_loss 27529070592.0, Seconds 0.03309059143066406\n",
      "Epoch 969: Train_loss 26691919872.0, Validation_loss 27529754624.0, Seconds 0.03700423240661621\n",
      "Epoch 970: Train_loss 26691717120.0, Validation_loss 27530229760.0, Seconds 0.0342860221862793\n",
      "Epoch 971: Train_loss 26691682304.0, Validation_loss 27529123840.0, Seconds 0.033170461654663086\n",
      "Epoch 972: Train_loss 26691796992.0, Validation_loss 27529211904.0, Seconds 0.03285932540893555\n",
      "Epoch 973: Train_loss 26691434496.0, Validation_loss 27529777152.0, Seconds 0.03366208076477051\n",
      "Epoch 974: Train_loss 26691346432.0, Validation_loss 27529582592.0, Seconds 0.030159473419189453\n",
      "Epoch 975: Train_loss 26691375104.0, Validation_loss 27529850880.0, Seconds 0.034221649169921875\n",
      "Epoch 976: Train_loss 26691223552.0, Validation_loss 27528857600.0, Seconds 0.037735700607299805\n",
      "Epoch 977: Train_loss 26691106816.0, Validation_loss 27529830400.0, Seconds 0.03282046318054199\n",
      "Epoch 978: Train_loss 26690797568.0, Validation_loss 27529615360.0, Seconds 0.03433656692504883\n",
      "Epoch 979: Train_loss 26690859008.0, Validation_loss 27530967040.0, Seconds 0.03618001937866211\n",
      "Epoch 980: Train_loss 26690594816.0, Validation_loss 27528957952.0, Seconds 0.0348658561706543\n",
      "Epoch 981: Train_loss 26690766848.0, Validation_loss 27529140224.0, Seconds 0.03274655342102051\n",
      "Epoch 982: Train_loss 26690516992.0, Validation_loss 27530199040.0, Seconds 0.0332036018371582\n",
      "Epoch 983: Train_loss 26690297856.0, Validation_loss 27528873984.0, Seconds 0.04278993606567383\n",
      "Epoch 984: Train_loss 26690361344.0, Validation_loss 27528103936.0, Seconds 0.031912803649902344\n",
      "Epoch 985: Train_loss 26690240512.0, Validation_loss 27529048064.0, Seconds 0.03304886817932129\n",
      "Epoch 986: Train_loss 26690041856.0, Validation_loss 27527999488.0, Seconds 0.033151865005493164\n",
      "Epoch 987: Train_loss 26690158592.0, Validation_loss 27527204864.0, Seconds 0.03404545783996582\n",
      "Epoch 988: Train_loss 26689812480.0, Validation_loss 27528124416.0, Seconds 0.03279519081115723\n",
      "Epoch 989: Train_loss 26689732608.0, Validation_loss 27529668608.0, Seconds 0.03931879997253418\n",
      "Epoch 990: Train_loss 26689531904.0, Validation_loss 27528536064.0, Seconds 0.03480792045593262\n",
      "Epoch 991: Train_loss 26689560576.0, Validation_loss 27528384512.0, Seconds 0.03323936462402344\n",
      "Epoch 992: Train_loss 26689390592.0, Validation_loss 27528626176.0, Seconds 0.0346527099609375\n",
      "Epoch 993: Train_loss 26689357824.0, Validation_loss 27529728000.0, Seconds 0.03128695487976074\n",
      "Epoch 994: Train_loss 26689083392.0, Validation_loss 27528792064.0, Seconds 0.03401660919189453\n",
      "Epoch 995: Train_loss 26689196032.0, Validation_loss 27527653376.0, Seconds 0.03564023971557617\n",
      "Epoch 996: Train_loss 26689064960.0, Validation_loss 27529392128.0, Seconds 0.03611445426940918\n",
      "Epoch 997: Train_loss 26688784384.0, Validation_loss 27528491008.0, Seconds 0.033817291259765625\n",
      "Epoch 998: Train_loss 26688849920.0, Validation_loss 27528124416.0, Seconds 0.03326010704040527\n",
      "Epoch 999: Train_loss 26688618496.0, Validation_loss 27528679424.0, Seconds 0.03620147705078125\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).view(-1, 1)\n",
    "        output = net(data)\n",
    "        L = loss(output, target)\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    y_train_pred = net(X_train)\n",
    "    training_loss = loss(y_train_pred, y_train.view(-1, 1)).item()\n",
    "    y_test_pred = net(X_test)\n",
    "    test_loss = loss(y_test_pred, y_test.view(-1, 1)).item()\n",
    "    \n",
    "    train_losses.append(training_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Epoch {}: Train_loss {}, Validation_loss {}, Seconds {}\".format(epoch, training_loss, test_loss, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11fd39871f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(test_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss values\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = net(X_train)\n",
    "y_test_pred = net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.detach().cpu().numpy()\n",
    "y_test = y_test.detach().cpu().numpy()\n",
    "y_train_pred = y_train_pred.detach().cpu().numpy()\n",
    "y_test_pred = y_test_pred.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.06e+05\n",
      "train MSE: 2.67e+10\n",
      "train R2: 0.437\n"
     ]
    }
   ],
   "source": [
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 1.01e+05\n",
      "test MSE: 2.75e+10\n",
      "test R2: 0.484\n"
     ]
    }
   ],
   "source": [
    "print('test MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('test MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('test R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
