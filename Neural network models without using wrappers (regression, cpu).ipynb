{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2.csv')\n",
    "df.dropna(subset=['price'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "target = 'price'\n",
    "features.remove(target)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target].str.strip(\"$\").str.replace(\",\",\"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "class Data_Transformer(object):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        self.mean_weight = new_df[\"Weight\"].mean() # obtain mean weight\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase weekday\n",
    "        self.majority_month = new_df[\"Month\"].mode()[0] # obtain majority purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        self.majority_weekday = new_df[\"Weekday\"].mode()[0] # obtain majority purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df[\"Ingredient Number\"] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        self.mean_ingredient_number = new_df[\"Ingredient Number\"].mean() # obtain mean ingredient number\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with median ingredient number\n",
    "        self.pl_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Level\"] = pd.Series(self.pl_le.fit_transform(X[\"product_level\"])) # fit and transform product level with label-encoder\n",
    "        self.majority_product_level = new_df[\"Product Level\"].mode()[0] # obtain majority product level code\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        self.pt_le = LabelEncoder() # create label-encoder\n",
    "        new_df[\"Product Type\"] = pd.Series(self.pt_le.fit_transform(X[\"product_type\"])) # fit and transform product type with label-encoder\n",
    "        self.majority_product_type = new_df[\"Product Type\"].mode()[0] # obtain majority product type code\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        self.cost_imputer = XGBRegressor() # create a XGBoost imputer for cost\n",
    "        df_for_imputing_cost = new_df.dropna() # create training data for cost imputer by dropping missing data\n",
    "        self.cost_imputer.fit(df_for_imputing_cost[[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]], df_for_imputing_cost[\"Cost\"]) # fit cost imputer\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Weight\"] = X[\"weight\"].map(self.weight2num) # convert weight to numerical value\n",
    "        new_df[\"Weight\"].fillna(self.mean_weight,inplace=True) # fill in missing weight with mean weight\n",
    "        new_df[\"Month\"] = pd.to_datetime(X[\"purchase_date\"]).dt.month # convert purchase date to purchase month\n",
    "        new_df[\"Month\"].fillna(self.majority_month,inplace=True) # fill in missing purchase month with majority purchase month\n",
    "        new_df[\"Weekday\"] = pd.to_datetime(X[\"purchase_date\"]).dt.weekday # convert purchase date to purchase weekday\n",
    "        new_df[\"Weekday\"].fillna(self.majority_weekday,inplace=True) # fill in missing purchase weekday with majority purchase weekday\n",
    "        new_df['Ingredient Number'] = X[\"ingredient\"].map(self.get_numbers) # obtain number of ingredients in recipe\n",
    "        new_df['Ingredient Number'].fillna(self.mean_ingredient_number,inplace=True) # fill in missing ingredient number with mean ingredient number\n",
    "        new_df[\"Product Level\"] = self.pl_le.transform(X[\"product_level\"]) # transform product level with label-encoder\n",
    "        new_df[\"Product Level\"].fillna(self.majority_product_level,inplace=True) # fill in missing product level with majority product level code\n",
    "        new_df[\"Product Type\"] = self.pt_le.transform(X[\"product_type\"]) # transform product type with label-encoder\n",
    "        new_df[\"Product Type\"].fillna(self.majority_product_type,inplace=True) # fill in missing product type with majority product type code\n",
    "        new_df[\"Cost\"] = X[\"cost\"].str.strip(\"$\").str.strip(\"k\").astype(float)*1000 # convert cost to numerical value\n",
    "        imputed_cost = pd.Series(self.cost_imputer.predict(new_df[new_df[\"Cost\"].isnull()][[\"Weight\",\"Month\",\"Weekday\",\"Ingredient Number\",\"Product Level\",\"Product Type\"]])) # obtain imputed cost\n",
    "        imputed_cost.index = new_df[new_df[\"Cost\"].isnull()][\"Cost\"].index # set index of imputed cost\n",
    "        new_df[\"Cost\"].fillna(imputed_cost,inplace=True) # fill in missing cost with imputed cost\n",
    "        return new_df # return new_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def weight2num(self, x): # function to convert weight to number\n",
    "        if type(x) == str:\n",
    "            x = x.strip('Kg').split(' Ton ')\n",
    "            return float(x[0])*1000+float(x[1])\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    def get_numbers(self, x): # function to get number of ingredients in recipe\n",
    "        if type(x) == str:\n",
    "            return len(x.split(','))\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('dtf', Data_Transformer()),\n",
    "        ('scaler', MinMaxScaler())]\n",
    "preproc = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc.fit_transform(X_train)\n",
    "X_test = preproc.transform(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(7, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "batch_size = 200\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSELoss(reduction='mean')\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train_loss 82726936576.0, Validation_loss 78282866688.0, Seconds 0.05850553512573242\n",
      "Epoch 1: Train_loss 82526765056.0, Validation_loss 78086406144.0, Seconds 0.02700328826904297\n",
      "Epoch 2: Train_loss 81272700928.0, Validation_loss 76856025088.0, Seconds 0.030998945236206055\n",
      "Epoch 3: Train_loss 76463783936.0, Validation_loss 72143478784.0, Seconds 0.03201913833618164\n",
      "Epoch 4: Train_loss 64549306368.0, Validation_loss 60519936000.0, Seconds 0.026521921157836914\n",
      "Epoch 5: Train_loss 50351890432.0, Validation_loss 46979723264.0, Seconds 0.030001401901245117\n",
      "Epoch 6: Train_loss 49327505408.0, Validation_loss 46394449920.0, Seconds 0.03199052810668945\n",
      "Epoch 7: Train_loss 47780016128.0, Validation_loss 44532662272.0, Seconds 0.030512094497680664\n",
      "Epoch 8: Train_loss 47050686464.0, Validation_loss 43727974400.0, Seconds 0.03600001335144043\n",
      "Epoch 9: Train_loss 46188720128.0, Validation_loss 42866057216.0, Seconds 0.02800154685974121\n",
      "Epoch 10: Train_loss 45371478016.0, Validation_loss 41964847104.0, Seconds 0.028513669967651367\n",
      "Epoch 11: Train_loss 44512448512.0, Validation_loss 41021378560.0, Seconds 0.0310060977935791\n",
      "Epoch 12: Train_loss 43569496064.0, Validation_loss 39996678144.0, Seconds 0.03100132942199707\n",
      "Epoch 13: Train_loss 42542313472.0, Validation_loss 38865592320.0, Seconds 0.027009963989257812\n",
      "Epoch 14: Train_loss 41402343424.0, Validation_loss 37602807808.0, Seconds 0.028495073318481445\n",
      "Epoch 15: Train_loss 40130138112.0, Validation_loss 36184752128.0, Seconds 0.03300285339355469\n",
      "Epoch 16: Train_loss 38733164544.0, Validation_loss 34612920320.0, Seconds 0.029000043869018555\n",
      "Epoch 17: Train_loss 37254746112.0, Validation_loss 32930914304.0, Seconds 0.027512788772583008\n",
      "Epoch 18: Train_loss 35796520960.0, Validation_loss 31243821056.0, Seconds 0.03000020980834961\n",
      "Epoch 19: Train_loss 34514419712.0, Validation_loss 29726576640.0, Seconds 0.02600240707397461\n",
      "Epoch 20: Train_loss 33520617472.0, Validation_loss 28522946560.0, Seconds 0.028078317642211914\n",
      "Epoch 21: Train_loss 32784136192.0, Validation_loss 27626973184.0, Seconds 0.025590896606445312\n",
      "Epoch 22: Train_loss 32190605312.0, Validation_loss 26923878400.0, Seconds 0.04900050163269043\n",
      "Epoch 23: Train_loss 31673487360.0, Validation_loss 26347231232.0, Seconds 0.030529260635375977\n",
      "Epoch 24: Train_loss 31222849536.0, Validation_loss 25862205440.0, Seconds 0.03400588035583496\n",
      "Epoch 25: Train_loss 30840115200.0, Validation_loss 25458366464.0, Seconds 0.03199267387390137\n",
      "Epoch 26: Train_loss 30520659968.0, Validation_loss 25139181568.0, Seconds 0.02801060676574707\n",
      "Epoch 27: Train_loss 30251591680.0, Validation_loss 24878649344.0, Seconds 0.028409719467163086\n",
      "Epoch 28: Train_loss 30023587840.0, Validation_loss 24668792832.0, Seconds 0.028998374938964844\n",
      "Epoch 29: Train_loss 29827878912.0, Validation_loss 24506513408.0, Seconds 0.02699732780456543\n",
      "Epoch 30: Train_loss 29658808320.0, Validation_loss 24384100352.0, Seconds 0.03750944137573242\n",
      "Epoch 31: Train_loss 29516201984.0, Validation_loss 24289517568.0, Seconds 0.028010845184326172\n",
      "Epoch 32: Train_loss 29400629248.0, Validation_loss 24220047360.0, Seconds 0.02799820899963379\n",
      "Epoch 33: Train_loss 29309427712.0, Validation_loss 24175890432.0, Seconds 0.027535438537597656\n",
      "Epoch 34: Train_loss 29235644416.0, Validation_loss 24147601408.0, Seconds 0.029992103576660156\n",
      "Epoch 35: Train_loss 29172504576.0, Validation_loss 24128786432.0, Seconds 0.02800154685974121\n",
      "Epoch 36: Train_loss 29117952000.0, Validation_loss 24116383744.0, Seconds 0.032004356384277344\n",
      "Epoch 37: Train_loss 29070800896.0, Validation_loss 24106381312.0, Seconds 0.027510881423950195\n",
      "Epoch 38: Train_loss 29030838272.0, Validation_loss 24097363968.0, Seconds 0.030992746353149414\n",
      "Epoch 39: Train_loss 28996083712.0, Validation_loss 24089337856.0, Seconds 0.02900528907775879\n",
      "Epoch 40: Train_loss 28965179392.0, Validation_loss 24084285440.0, Seconds 0.025526046752929688\n",
      "Epoch 41: Train_loss 28937701376.0, Validation_loss 24083519488.0, Seconds 0.029000043869018555\n",
      "Epoch 42: Train_loss 28912031744.0, Validation_loss 24085889024.0, Seconds 0.027999401092529297\n",
      "Epoch 43: Train_loss 28887271424.0, Validation_loss 24089110528.0, Seconds 0.025004148483276367\n",
      "Epoch 44: Train_loss 28865107968.0, Validation_loss 24092217344.0, Seconds 0.025576114654541016\n",
      "Epoch 45: Train_loss 28845400064.0, Validation_loss 24092712960.0, Seconds 0.02792978286743164\n",
      "Epoch 46: Train_loss 28827168768.0, Validation_loss 24092461056.0, Seconds 0.028998136520385742\n",
      "Epoch 47: Train_loss 28810645504.0, Validation_loss 24092157952.0, Seconds 0.028010845184326172\n",
      "Epoch 48: Train_loss 28795088896.0, Validation_loss 24091086848.0, Seconds 0.027527809143066406\n",
      "Epoch 49: Train_loss 28780369920.0, Validation_loss 24089831424.0, Seconds 0.026999950408935547\n",
      "Epoch 50: Train_loss 28766654464.0, Validation_loss 24090494976.0, Seconds 0.02700018882751465\n",
      "Epoch 51: Train_loss 28754327552.0, Validation_loss 24091785216.0, Seconds 0.03154158592224121\n",
      "Epoch 52: Train_loss 28743413760.0, Validation_loss 24093151232.0, Seconds 0.03899979591369629\n",
      "Epoch 53: Train_loss 28733478912.0, Validation_loss 24093196288.0, Seconds 0.058525800704956055\n",
      "Epoch 54: Train_loss 28724166656.0, Validation_loss 24093593600.0, Seconds 0.044996023178100586\n",
      "Epoch 55: Train_loss 28714870784.0, Validation_loss 24093771776.0, Seconds 0.0330047607421875\n",
      "Epoch 56: Train_loss 28706494464.0, Validation_loss 24092860416.0, Seconds 0.029526710510253906\n",
      "Epoch 57: Train_loss 28698724352.0, Validation_loss 24091871232.0, Seconds 0.02500128746032715\n",
      "Epoch 58: Train_loss 28691007488.0, Validation_loss 24090730496.0, Seconds 0.028003692626953125\n",
      "Epoch 59: Train_loss 28683350016.0, Validation_loss 24088707072.0, Seconds 0.02800154685974121\n",
      "Epoch 60: Train_loss 28675956736.0, Validation_loss 24087816192.0, Seconds 0.027531147003173828\n",
      "Epoch 61: Train_loss 28668323840.0, Validation_loss 24087375872.0, Seconds 0.027998924255371094\n",
      "Epoch 62: Train_loss 28660615168.0, Validation_loss 24086843392.0, Seconds 0.028001070022583008\n",
      "Epoch 63: Train_loss 28653199360.0, Validation_loss 24086587392.0, Seconds 0.026507139205932617\n",
      "Epoch 64: Train_loss 28646035456.0, Validation_loss 24085895168.0, Seconds 0.031000852584838867\n",
      "Epoch 65: Train_loss 28639780864.0, Validation_loss 24086163456.0, Seconds 0.02900099754333496\n",
      "Epoch 66: Train_loss 28634183680.0, Validation_loss 24086427648.0, Seconds 0.026006221771240234\n",
      "Epoch 67: Train_loss 28629262336.0, Validation_loss 24087171072.0, Seconds 0.026504039764404297\n",
      "Epoch 68: Train_loss 28624459776.0, Validation_loss 24088225792.0, Seconds 0.027999401092529297\n",
      "Epoch 69: Train_loss 28619821056.0, Validation_loss 24089102336.0, Seconds 0.03200125694274902\n",
      "Epoch 70: Train_loss 28615442432.0, Validation_loss 24089272320.0, Seconds 0.02654266357421875\n",
      "Epoch 71: Train_loss 28611065856.0, Validation_loss 24089008128.0, Seconds 0.032999515533447266\n",
      "Epoch 72: Train_loss 28607049728.0, Validation_loss 24089114624.0, Seconds 0.03400111198425293\n",
      "Epoch 73: Train_loss 28603414528.0, Validation_loss 24089468928.0, Seconds 0.034522056579589844\n",
      "Epoch 74: Train_loss 28599767040.0, Validation_loss 24090009600.0, Seconds 0.030038833618164062\n",
      "Epoch 75: Train_loss 28596129792.0, Validation_loss 24090161152.0, Seconds 0.02996087074279785\n",
      "Epoch 76: Train_loss 28592484352.0, Validation_loss 24089843712.0, Seconds 0.032503604888916016\n",
      "Epoch 77: Train_loss 28589150208.0, Validation_loss 24089120768.0, Seconds 0.03100442886352539\n",
      "Epoch 78: Train_loss 28585990144.0, Validation_loss 24088504320.0, Seconds 0.029999494552612305\n",
      "Epoch 79: Train_loss 28582801408.0, Validation_loss 24087318528.0, Seconds 0.033011674880981445\n",
      "Epoch 80: Train_loss 28579743744.0, Validation_loss 24086355968.0, Seconds 0.027517080307006836\n",
      "Epoch 81: Train_loss 28576813056.0, Validation_loss 24085534720.0, Seconds 0.03099966049194336\n",
      "Epoch 82: Train_loss 28573652992.0, Validation_loss 24084185088.0, Seconds 0.03099846839904785\n",
      "Epoch 83: Train_loss 28570667008.0, Validation_loss 24081995776.0, Seconds 0.02951669692993164\n",
      "Epoch 84: Train_loss 28567820288.0, Validation_loss 24079523840.0, Seconds 0.027004480361938477\n",
      "Epoch 85: Train_loss 28565145600.0, Validation_loss 24078198784.0, Seconds 0.03200244903564453\n",
      "Epoch 86: Train_loss 28562442240.0, Validation_loss 24077029376.0, Seconds 0.03151369094848633\n",
      "Epoch 87: Train_loss 28559845376.0, Validation_loss 24076124160.0, Seconds 0.028998613357543945\n",
      "Epoch 88: Train_loss 28557199360.0, Validation_loss 24075667456.0, Seconds 0.030046463012695312\n",
      "Epoch 89: Train_loss 28554733568.0, Validation_loss 24075466752.0, Seconds 0.028959035873413086\n",
      "Epoch 90: Train_loss 28552345600.0, Validation_loss 24075266048.0, Seconds 0.030509471893310547\n",
      "Epoch 91: Train_loss 28549894144.0, Validation_loss 24075235328.0, Seconds 0.032001495361328125\n",
      "Epoch 92: Train_loss 28547586048.0, Validation_loss 24074842112.0, Seconds 0.029004573822021484\n",
      "Epoch 93: Train_loss 28545255424.0, Validation_loss 24074184704.0, Seconds 0.032514095306396484\n",
      "Epoch 94: Train_loss 28543062016.0, Validation_loss 24073891840.0, Seconds 0.02799248695373535\n",
      "Epoch 95: Train_loss 28540760064.0, Validation_loss 24072949760.0, Seconds 0.027080774307250977\n",
      "Epoch 96: Train_loss 28538656768.0, Validation_loss 24072556544.0, Seconds 0.03144431114196777\n",
      "Epoch 97: Train_loss 28536438784.0, Validation_loss 24071794688.0, Seconds 0.03200125694274902\n",
      "Epoch 98: Train_loss 28534208512.0, Validation_loss 24071184384.0, Seconds 0.02899956703186035\n",
      "Epoch 99: Train_loss 28531933184.0, Validation_loss 24069969920.0, Seconds 0.03206014633178711\n",
      "Epoch 100: Train_loss 28529115136.0, Validation_loss 24068661248.0, Seconds 0.027543067932128906\n",
      "Epoch 101: Train_loss 28526454784.0, Validation_loss 24067295232.0, Seconds 0.03300118446350098\n",
      "Epoch 102: Train_loss 28523868160.0, Validation_loss 24066078720.0, Seconds 0.03200173377990723\n",
      "Epoch 103: Train_loss 28521498624.0, Validation_loss 24065503232.0, Seconds 0.02853846549987793\n",
      "Epoch 104: Train_loss 28519045120.0, Validation_loss 24065314816.0, Seconds 0.03099203109741211\n",
      "Epoch 105: Train_loss 28516519936.0, Validation_loss 24064757760.0, Seconds 0.03200340270996094\n",
      "Epoch 106: Train_loss 28514011136.0, Validation_loss 24063322112.0, Seconds 0.0315093994140625\n",
      "Epoch 107: Train_loss 28511281152.0, Validation_loss 24060995584.0, Seconds 0.03100109100341797\n",
      "Epoch 108: Train_loss 28508852224.0, Validation_loss 24059539456.0, Seconds 0.03099679946899414\n",
      "Epoch 109: Train_loss 28506314752.0, Validation_loss 24058083328.0, Seconds 0.03661537170410156\n",
      "Epoch 110: Train_loss 28504002560.0, Validation_loss 24057067520.0, Seconds 0.027003049850463867\n",
      "Epoch 111: Train_loss 28501385216.0, Validation_loss 24055433216.0, Seconds 0.028995037078857422\n",
      "Epoch 112: Train_loss 28498679808.0, Validation_loss 24053020672.0, Seconds 0.0330812931060791\n",
      "Epoch 113: Train_loss 28495560704.0, Validation_loss 24050931712.0, Seconds 0.027593135833740234\n",
      "Epoch 114: Train_loss 28493125632.0, Validation_loss 24049018880.0, Seconds 0.02799677848815918\n",
      "Epoch 115: Train_loss 28490514432.0, Validation_loss 24046931968.0, Seconds 0.030000686645507812\n",
      "Epoch 116: Train_loss 28487913472.0, Validation_loss 24045240320.0, Seconds 0.030509471893310547\n",
      "Epoch 117: Train_loss 28485435392.0, Validation_loss 24043309056.0, Seconds 0.030999183654785156\n",
      "Epoch 118: Train_loss 28483192832.0, Validation_loss 24041834496.0, Seconds 0.03199934959411621\n",
      "Epoch 119: Train_loss 28480575488.0, Validation_loss 24039847936.0, Seconds 0.02653789520263672\n",
      "Epoch 120: Train_loss 28478339072.0, Validation_loss 24037484544.0, Seconds 0.03099989891052246\n",
      "Epoch 121: Train_loss 28475713536.0, Validation_loss 24035235840.0, Seconds 0.03199481964111328\n",
      "Epoch 122: Train_loss 28473434112.0, Validation_loss 24032817152.0, Seconds 0.029004573822021484\n",
      "Epoch 123: Train_loss 28471123968.0, Validation_loss 24031156224.0, Seconds 0.03054952621459961\n",
      "Epoch 124: Train_loss 28468717568.0, Validation_loss 24029001728.0, Seconds 0.02898406982421875\n",
      "Epoch 125: Train_loss 28466518016.0, Validation_loss 24026931200.0, Seconds 0.027997970581054688\n",
      "Epoch 126: Train_loss 28464064512.0, Validation_loss 24025335808.0, Seconds 0.03059101104736328\n",
      "Epoch 127: Train_loss 28461594624.0, Validation_loss 24024344576.0, Seconds 0.03300976753234863\n",
      "Epoch 128: Train_loss 28458868736.0, Validation_loss 24022235136.0, Seconds 0.02606344223022461\n",
      "Epoch 129: Train_loss 28456331264.0, Validation_loss 24019073024.0, Seconds 0.029449462890625\n",
      "Epoch 130: Train_loss 28453318656.0, Validation_loss 24016291840.0, Seconds 0.02800154685974121\n",
      "Epoch 131: Train_loss 28450279424.0, Validation_loss 24013238272.0, Seconds 0.029000520706176758\n",
      "Epoch 132: Train_loss 28446873600.0, Validation_loss 24010471424.0, Seconds 0.033003807067871094\n",
      "Epoch 133: Train_loss 28443267072.0, Validation_loss 24007356416.0, Seconds 0.030514955520629883\n",
      "Epoch 134: Train_loss 28439613440.0, Validation_loss 24004628480.0, Seconds 0.027992725372314453\n",
      "Epoch 135: Train_loss 28436547584.0, Validation_loss 24002269184.0, Seconds 0.030999183654785156\n",
      "Epoch 136: Train_loss 28433305600.0, Validation_loss 23999870976.0, Seconds 0.0275113582611084\n",
      "Epoch 137: Train_loss 28429881344.0, Validation_loss 23997356032.0, Seconds 0.028997182846069336\n",
      "Epoch 138: Train_loss 28426293248.0, Validation_loss 23995103232.0, Seconds 0.029999971389770508\n",
      "Epoch 139: Train_loss 28422889472.0, Validation_loss 23993071616.0, Seconds 0.026019573211669922\n",
      "Epoch 140: Train_loss 28419467264.0, Validation_loss 23991173120.0, Seconds 0.025530099868774414\n",
      "Epoch 141: Train_loss 28415909888.0, Validation_loss 23988785152.0, Seconds 0.02899956703186035\n",
      "Epoch 142: Train_loss 28412545024.0, Validation_loss 23986210816.0, Seconds 0.031992197036743164\n",
      "Epoch 143: Train_loss 28409202688.0, Validation_loss 23983755264.0, Seconds 0.035538673400878906\n",
      "Epoch 144: Train_loss 28406097920.0, Validation_loss 23982792704.0, Seconds 0.03199315071105957\n",
      "Epoch 145: Train_loss 28402931712.0, Validation_loss 23980920832.0, Seconds 0.02800440788269043\n",
      "Epoch 146: Train_loss 28399697920.0, Validation_loss 23978731520.0, Seconds 0.03053450584411621\n",
      "Epoch 147: Train_loss 28396767232.0, Validation_loss 23976763392.0, Seconds 0.02800154685974121\n",
      "Epoch 148: Train_loss 28393541632.0, Validation_loss 23974279168.0, Seconds 0.029072999954223633\n",
      "Epoch 149: Train_loss 28390643712.0, Validation_loss 23972268032.0, Seconds 0.028948068618774414\n",
      "Epoch 150: Train_loss 28387715072.0, Validation_loss 23969871872.0, Seconds 0.029521703720092773\n",
      "Epoch 151: Train_loss 28384296960.0, Validation_loss 23969769472.0, Seconds 0.029007434844970703\n",
      "Epoch 152: Train_loss 28379838464.0, Validation_loss 23971201024.0, Seconds 0.029998064041137695\n",
      "Epoch 153: Train_loss 28375703552.0, Validation_loss 23971411968.0, Seconds 0.0306093692779541\n",
      "Epoch 154: Train_loss 28371572736.0, Validation_loss 23970095104.0, Seconds 0.029001235961914062\n",
      "Epoch 155: Train_loss 28367239168.0, Validation_loss 23969945600.0, Seconds 0.02699899673461914\n",
      "Epoch 156: Train_loss 28363292672.0, Validation_loss 23969779712.0, Seconds 0.0270841121673584\n",
      "Epoch 157: Train_loss 28359223296.0, Validation_loss 23969470464.0, Seconds 0.028519868850708008\n",
      "Epoch 158: Train_loss 28355446784.0, Validation_loss 23967897600.0, Seconds 0.030002117156982422\n",
      "Epoch 159: Train_loss 28351467520.0, Validation_loss 23967105024.0, Seconds 0.03307485580444336\n",
      "Epoch 160: Train_loss 28347680768.0, Validation_loss 23966320640.0, Seconds 0.02953028678894043\n",
      "Epoch 161: Train_loss 28343941120.0, Validation_loss 23966101504.0, Seconds 0.03200101852416992\n",
      "Epoch 162: Train_loss 28340375552.0, Validation_loss 23964379136.0, Seconds 0.03400826454162598\n",
      "Epoch 163: Train_loss 28336572416.0, Validation_loss 23963416576.0, Seconds 0.03351736068725586\n",
      "Epoch 164: Train_loss 28332898304.0, Validation_loss 23961704448.0, Seconds 0.03299760818481445\n",
      "Epoch 165: Train_loss 28329103360.0, Validation_loss 23960526848.0, Seconds 0.037006378173828125\n",
      "Epoch 166: Train_loss 28325640192.0, Validation_loss 23959461888.0, Seconds 0.029509782791137695\n",
      "Epoch 167: Train_loss 28321957888.0, Validation_loss 23957196800.0, Seconds 0.02800273895263672\n",
      "Epoch 168: Train_loss 28318150656.0, Validation_loss 23956105216.0, Seconds 0.028996944427490234\n",
      "Epoch 169: Train_loss 28314429440.0, Validation_loss 23955060736.0, Seconds 0.029527664184570312\n",
      "Epoch 170: Train_loss 28310566912.0, Validation_loss 23953723392.0, Seconds 0.03098773956298828\n",
      "Epoch 171: Train_loss 28306810880.0, Validation_loss 23952463872.0, Seconds 0.031018495559692383\n",
      "Epoch 172: Train_loss 28303108096.0, Validation_loss 23951452160.0, Seconds 0.15381145477294922\n",
      "Epoch 173: Train_loss 28299341824.0, Validation_loss 23951194112.0, Seconds 0.03199934959411621\n",
      "Epoch 174: Train_loss 28295526400.0, Validation_loss 23950112768.0, Seconds 0.03000664710998535\n",
      "Epoch 175: Train_loss 28291749888.0, Validation_loss 23947915264.0, Seconds 0.029521465301513672\n",
      "Epoch 176: Train_loss 28287399936.0, Validation_loss 23945578496.0, Seconds 0.033997297286987305\n",
      "Epoch 177: Train_loss 28283867136.0, Validation_loss 23944478720.0, Seconds 0.03600716590881348\n",
      "Epoch 178: Train_loss 28279764992.0, Validation_loss 23943159808.0, Seconds 0.032517194747924805\n",
      "Epoch 179: Train_loss 28275738624.0, Validation_loss 23941083136.0, Seconds 0.033997535705566406\n",
      "Epoch 180: Train_loss 28272197632.0, Validation_loss 23939258368.0, Seconds 0.028998613357543945\n",
      "Epoch 181: Train_loss 28268222464.0, Validation_loss 23937849344.0, Seconds 0.02852654457092285\n",
      "Epoch 182: Train_loss 28264478720.0, Validation_loss 23937038336.0, Seconds 0.03100299835205078\n",
      "Epoch 183: Train_loss 28260472832.0, Validation_loss 23935289344.0, Seconds 0.03599667549133301\n",
      "Epoch 184: Train_loss 28256485376.0, Validation_loss 23932329984.0, Seconds 0.03751087188720703\n",
      "Epoch 185: Train_loss 28252416000.0, Validation_loss 23929413632.0, Seconds 0.033002614974975586\n",
      "Epoch 186: Train_loss 28248397824.0, Validation_loss 23926890496.0, Seconds 0.03999686241149902\n",
      "Epoch 187: Train_loss 28244680704.0, Validation_loss 23924471808.0, Seconds 0.0315096378326416\n",
      "Epoch 188: Train_loss 28240465920.0, Validation_loss 23923447808.0, Seconds 0.03399920463562012\n",
      "Epoch 189: Train_loss 28236898304.0, Validation_loss 23922757632.0, Seconds 0.03200483322143555\n",
      "Epoch 190: Train_loss 28232802304.0, Validation_loss 23921582080.0, Seconds 0.031511545181274414\n",
      "Epoch 191: Train_loss 28228739072.0, Validation_loss 23920539648.0, Seconds 0.030003070831298828\n",
      "Epoch 192: Train_loss 28224575488.0, Validation_loss 23919280128.0, Seconds 0.03199911117553711\n",
      "Epoch 193: Train_loss 28220463104.0, Validation_loss 23918659584.0, Seconds 0.029511690139770508\n",
      "Epoch 194: Train_loss 28216463360.0, Validation_loss 23917510656.0, Seconds 0.032000064849853516\n",
      "Epoch 195: Train_loss 28212389888.0, Validation_loss 23916238848.0, Seconds 0.02900075912475586\n",
      "Epoch 196: Train_loss 28208248832.0, Validation_loss 23914637312.0, Seconds 0.02902054786682129\n",
      "Epoch 197: Train_loss 28203980800.0, Validation_loss 23911919616.0, Seconds 0.02753424644470215\n",
      "Epoch 198: Train_loss 28200007680.0, Validation_loss 23909900288.0, Seconds 0.02799248695373535\n",
      "Epoch 199: Train_loss 28195850240.0, Validation_loss 23908212736.0, Seconds 0.03300786018371582\n",
      "Epoch 200: Train_loss 28191997952.0, Validation_loss 23905884160.0, Seconds 0.028546571731567383\n",
      "Epoch 201: Train_loss 28187791360.0, Validation_loss 23904376832.0, Seconds 0.028998851776123047\n",
      "Epoch 202: Train_loss 28183838720.0, Validation_loss 23902085120.0, Seconds 0.027988195419311523\n",
      "Epoch 203: Train_loss 28179718144.0, Validation_loss 23900835840.0, Seconds 0.03207993507385254\n",
      "Epoch 204: Train_loss 28175777792.0, Validation_loss 23898875904.0, Seconds 0.02660202980041504\n",
      "Epoch 205: Train_loss 28171829248.0, Validation_loss 23896868864.0, Seconds 0.028997182846069336\n",
      "Epoch 206: Train_loss 28167628800.0, Validation_loss 23896516608.0, Seconds 0.028998851776123047\n",
      "Epoch 207: Train_loss 28163739648.0, Validation_loss 23896004608.0, Seconds 0.028518199920654297\n",
      "Epoch 208: Train_loss 28159440896.0, Validation_loss 23894796288.0, Seconds 0.031999826431274414\n",
      "Epoch 209: Train_loss 28155394048.0, Validation_loss 23893676032.0, Seconds 0.026998281478881836\n",
      "Epoch 210: Train_loss 28151007232.0, Validation_loss 23892234240.0, Seconds 0.03021097183227539\n",
      "Epoch 211: Train_loss 28147005440.0, Validation_loss 23890225152.0, Seconds 0.03300023078918457\n",
      "Epoch 212: Train_loss 28142870528.0, Validation_loss 23888173056.0, Seconds 0.03300666809082031\n",
      "Epoch 213: Train_loss 28138903552.0, Validation_loss 23886673920.0, Seconds 0.027074575424194336\n",
      "Epoch 214: Train_loss 28134811648.0, Validation_loss 23884425216.0, Seconds 0.029657363891601562\n",
      "Epoch 215: Train_loss 28131133440.0, Validation_loss 23883282432.0, Seconds 0.028934001922607422\n",
      "Epoch 216: Train_loss 28127236096.0, Validation_loss 23882731520.0, Seconds 0.03000354766845703\n",
      "Epoch 217: Train_loss 28123500544.0, Validation_loss 23882366976.0, Seconds 0.028679609298706055\n",
      "Epoch 218: Train_loss 28119707648.0, Validation_loss 23881539584.0, Seconds 0.028975725173950195\n",
      "Epoch 219: Train_loss 28116099072.0, Validation_loss 23880355840.0, Seconds 0.028997421264648438\n",
      "Epoch 220: Train_loss 28112193536.0, Validation_loss 23879178240.0, Seconds 0.030077695846557617\n",
      "Epoch 221: Train_loss 28108550144.0, Validation_loss 23877994496.0, Seconds 0.031595706939697266\n",
      "Epoch 222: Train_loss 28104671232.0, Validation_loss 23875608576.0, Seconds 0.033005475997924805\n",
      "Epoch 223: Train_loss 28100943872.0, Validation_loss 23873273856.0, Seconds 0.02899932861328125\n",
      "Epoch 224: Train_loss 28097214464.0, Validation_loss 23871033344.0, Seconds 0.026504993438720703\n",
      "Epoch 225: Train_loss 28093534208.0, Validation_loss 23869478912.0, Seconds 0.0280001163482666\n",
      "Epoch 226: Train_loss 28089536512.0, Validation_loss 23866773504.0, Seconds 0.0290374755859375\n",
      "Epoch 227: Train_loss 28085919744.0, Validation_loss 23864365056.0, Seconds 0.029468059539794922\n",
      "Epoch 228: Train_loss 28082010112.0, Validation_loss 23862493184.0, Seconds 0.03200721740722656\n",
      "Epoch 229: Train_loss 28078090240.0, Validation_loss 23861596160.0, Seconds 0.03299999237060547\n",
      "Epoch 230: Train_loss 28074233856.0, Validation_loss 23860965376.0, Seconds 0.030516624450683594\n",
      "Epoch 231: Train_loss 28069095424.0, Validation_loss 23862704128.0, Seconds 0.027997255325317383\n",
      "Epoch 232: Train_loss 28063387648.0, Validation_loss 23866394624.0, Seconds 0.028059959411621094\n",
      "Epoch 233: Train_loss 28058290176.0, Validation_loss 23867267072.0, Seconds 0.028957128524780273\n",
      "Epoch 234: Train_loss 28052908032.0, Validation_loss 23866128384.0, Seconds 0.028508424758911133\n",
      "Epoch 235: Train_loss 28047751168.0, Validation_loss 23864991744.0, Seconds 0.02800130844116211\n",
      "Epoch 236: Train_loss 28042862592.0, Validation_loss 23861526528.0, Seconds 0.02800440788269043\n",
      "Epoch 237: Train_loss 28038152192.0, Validation_loss 23857686528.0, Seconds 0.028497695922851562\n",
      "Epoch 238: Train_loss 28033318912.0, Validation_loss 23856717824.0, Seconds 0.029006242752075195\n",
      "Epoch 239: Train_loss 28028604416.0, Validation_loss 23856340992.0, Seconds 0.026996850967407227\n",
      "Epoch 240: Train_loss 28023570432.0, Validation_loss 23853692928.0, Seconds 0.029000282287597656\n",
      "Epoch 241: Train_loss 28018493440.0, Validation_loss 23851452416.0, Seconds 0.030544042587280273\n",
      "Epoch 242: Train_loss 28013332480.0, Validation_loss 23849955328.0, Seconds 0.02899456024169922\n",
      "Epoch 243: Train_loss 28008433664.0, Validation_loss 23847401472.0, Seconds 0.02700042724609375\n",
      "Epoch 244: Train_loss 28003334144.0, Validation_loss 23845541888.0, Seconds 0.027019023895263672\n",
      "Epoch 245: Train_loss 27998535680.0, Validation_loss 23841935360.0, Seconds 0.03152132034301758\n",
      "Epoch 246: Train_loss 27993219072.0, Validation_loss 23839277056.0, Seconds 0.03300118446350098\n",
      "Epoch 247: Train_loss 27987619840.0, Validation_loss 23836198912.0, Seconds 0.030002593994140625\n",
      "Epoch 248: Train_loss 27982446592.0, Validation_loss 23831298048.0, Seconds 0.03051018714904785\n",
      "Epoch 249: Train_loss 27977687040.0, Validation_loss 23827675136.0, Seconds 0.02699899673461914\n",
      "Epoch 250: Train_loss 27973070848.0, Validation_loss 23824357376.0, Seconds 0.028998136520385742\n",
      "Epoch 251: Train_loss 27968530432.0, Validation_loss 23822219264.0, Seconds 0.028510570526123047\n",
      "Epoch 252: Train_loss 27963875328.0, Validation_loss 23821662208.0, Seconds 0.0280001163482666\n",
      "Epoch 253: Train_loss 27959595008.0, Validation_loss 23818807296.0, Seconds 0.026999950408935547\n",
      "Epoch 254: Train_loss 27955122176.0, Validation_loss 23815712768.0, Seconds 0.02800607681274414\n",
      "Epoch 255: Train_loss 27950493696.0, Validation_loss 23814297600.0, Seconds 0.028501510620117188\n",
      "Epoch 256: Train_loss 27945979904.0, Validation_loss 23813453824.0, Seconds 0.02800750732421875\n",
      "Epoch 257: Train_loss 27941505024.0, Validation_loss 23811385344.0, Seconds 0.027997970581054688\n",
      "Epoch 258: Train_loss 27937261568.0, Validation_loss 23808712704.0, Seconds 0.02951645851135254\n",
      "Epoch 259: Train_loss 27932801024.0, Validation_loss 23806765056.0, Seconds 0.028004169464111328\n",
      "Epoch 260: Train_loss 27928342528.0, Validation_loss 23805728768.0, Seconds 0.02599644660949707\n",
      "Epoch 261: Train_loss 27924246528.0, Validation_loss 23805046784.0, Seconds 0.028003931045532227\n",
      "Epoch 262: Train_loss 27919407104.0, Validation_loss 23803760640.0, Seconds 0.030512094497680664\n",
      "Epoch 263: Train_loss 27914838016.0, Validation_loss 23802896384.0, Seconds 0.030992746353149414\n",
      "Epoch 264: Train_loss 27910199296.0, Validation_loss 23801706496.0, Seconds 0.029000043869018555\n",
      "Epoch 265: Train_loss 27905918976.0, Validation_loss 23799244800.0, Seconds 0.02951216697692871\n",
      "Epoch 266: Train_loss 27902064640.0, Validation_loss 23797336064.0, Seconds 0.02899789810180664\n",
      "Epoch 267: Train_loss 27897896960.0, Validation_loss 23795939328.0, Seconds 0.029001712799072266\n",
      "Epoch 268: Train_loss 27894054912.0, Validation_loss 23794012160.0, Seconds 0.032506465911865234\n",
      "Epoch 269: Train_loss 27890186240.0, Validation_loss 23792435200.0, Seconds 0.03200554847717285\n",
      "Epoch 270: Train_loss 27886202880.0, Validation_loss 23790968832.0, Seconds 0.02700018882751465\n",
      "Epoch 271: Train_loss 27882405888.0, Validation_loss 23789127680.0, Seconds 0.030005216598510742\n",
      "Epoch 272: Train_loss 27878805504.0, Validation_loss 23786754048.0, Seconds 0.030515193939208984\n",
      "Epoch 273: Train_loss 27874932736.0, Validation_loss 23785027584.0, Seconds 0.03101062774658203\n",
      "Epoch 274: Train_loss 27871205376.0, Validation_loss 23783651328.0, Seconds 0.02906489372253418\n",
      "Epoch 275: Train_loss 27867465728.0, Validation_loss 23782762496.0, Seconds 0.03243446350097656\n",
      "Epoch 276: Train_loss 27864066048.0, Validation_loss 23781621760.0, Seconds 0.03400278091430664\n",
      "Epoch 277: Train_loss 27860350976.0, Validation_loss 23780485120.0, Seconds 0.0319972038269043\n",
      "Epoch 278: Train_loss 27856750592.0, Validation_loss 23779307520.0, Seconds 0.0295870304107666\n",
      "Epoch 279: Train_loss 27852941312.0, Validation_loss 23778504704.0, Seconds 0.028927087783813477\n",
      "Epoch 280: Train_loss 27849003008.0, Validation_loss 23776704512.0, Seconds 0.032000064849853516\n",
      "Epoch 281: Train_loss 27845318656.0, Validation_loss 23775811584.0, Seconds 0.027011394500732422\n",
      "Epoch 282: Train_loss 27841718272.0, Validation_loss 23773843456.0, Seconds 0.027507543563842773\n",
      "Epoch 283: Train_loss 27838078976.0, Validation_loss 23771488256.0, Seconds 0.03099846839904785\n",
      "Epoch 284: Train_loss 27834632192.0, Validation_loss 23768801280.0, Seconds 0.033002614974975586\n",
      "Epoch 285: Train_loss 27830980608.0, Validation_loss 23765577728.0, Seconds 0.03550863265991211\n",
      "Epoch 286: Train_loss 27827331072.0, Validation_loss 23763425280.0, Seconds 0.029999256134033203\n",
      "Epoch 287: Train_loss 27823810560.0, Validation_loss 23761868800.0, Seconds 0.03300666809082031\n",
      "Epoch 288: Train_loss 27820666880.0, Validation_loss 23760433152.0, Seconds 0.03353238105773926\n",
      "Epoch 289: Train_loss 27816927232.0, Validation_loss 23758528512.0, Seconds 0.033002376556396484\n",
      "Epoch 290: Train_loss 27814035456.0, Validation_loss 23757340672.0, Seconds 0.029003620147705078\n",
      "Epoch 291: Train_loss 27810424832.0, Validation_loss 23755755520.0, Seconds 0.03451824188232422\n",
      "Epoch 292: Train_loss 27807166464.0, Validation_loss 23753433088.0, Seconds 0.03199934959411621\n",
      "Epoch 293: Train_loss 27803928576.0, Validation_loss 23752763392.0, Seconds 0.03299570083618164\n",
      "Epoch 294: Train_loss 27800307712.0, Validation_loss 23752669184.0, Seconds 0.030612468719482422\n",
      "Epoch 295: Train_loss 27797467136.0, Validation_loss 23750305792.0, Seconds 0.032994985580444336\n",
      "Epoch 296: Train_loss 27794173952.0, Validation_loss 23750051840.0, Seconds 0.0299985408782959\n",
      "Epoch 297: Train_loss 27791241216.0, Validation_loss 23749916672.0, Seconds 0.029512405395507812\n",
      "Epoch 298: Train_loss 27787929600.0, Validation_loss 23748155392.0, Seconds 0.028009653091430664\n",
      "Epoch 299: Train_loss 27784894464.0, Validation_loss 23747420160.0, Seconds 0.030995845794677734\n",
      "Epoch 300: Train_loss 27781715968.0, Validation_loss 23746443264.0, Seconds 0.03000497817993164\n",
      "Epoch 301: Train_loss 27778848768.0, Validation_loss 23744757760.0, Seconds 0.02752852439880371\n",
      "Epoch 302: Train_loss 27775885312.0, Validation_loss 23744872448.0, Seconds 0.029007434844970703\n",
      "Epoch 303: Train_loss 27773081600.0, Validation_loss 23745542144.0, Seconds 0.027990341186523438\n",
      "Epoch 304: Train_loss 27770263552.0, Validation_loss 23744264192.0, Seconds 0.027695417404174805\n",
      "Epoch 305: Train_loss 27767250944.0, Validation_loss 23744059392.0, Seconds 0.03292512893676758\n",
      "Epoch 306: Train_loss 27764676608.0, Validation_loss 23743039488.0, Seconds 0.032994985580444336\n",
      "Epoch 307: Train_loss 27761833984.0, Validation_loss 23742394368.0, Seconds 0.030515193939208984\n",
      "Epoch 308: Train_loss 27759253504.0, Validation_loss 23740301312.0, Seconds 0.032006025314331055\n",
      "Epoch 309: Train_loss 27756607488.0, Validation_loss 23739559936.0, Seconds 0.02906656265258789\n",
      "Epoch 310: Train_loss 27753990144.0, Validation_loss 23738427392.0, Seconds 0.029939651489257812\n",
      "Epoch 311: Train_loss 27751272448.0, Validation_loss 23736969216.0, Seconds 0.026506662368774414\n",
      "Epoch 312: Train_loss 27748790272.0, Validation_loss 23736395776.0, Seconds 0.028005599975585938\n",
      "Epoch 313: Train_loss 27746387968.0, Validation_loss 23734059008.0, Seconds 0.029999732971191406\n",
      "Epoch 314: Train_loss 27743537152.0, Validation_loss 23733366784.0, Seconds 0.028542280197143555\n",
      "Epoch 315: Train_loss 27741399040.0, Validation_loss 23730372608.0, Seconds 0.03000664710998535\n",
      "Epoch 316: Train_loss 27738613760.0, Validation_loss 23729965056.0, Seconds 0.028991222381591797\n",
      "Epoch 317: Train_loss 27736492032.0, Validation_loss 23727464448.0, Seconds 0.030006885528564453\n",
      "Epoch 318: Train_loss 27733665792.0, Validation_loss 23727390720.0, Seconds 0.029551982879638672\n",
      "Epoch 319: Train_loss 27731517440.0, Validation_loss 23725076480.0, Seconds 0.027958154678344727\n",
      "Epoch 320: Train_loss 27728998400.0, Validation_loss 23724718080.0, Seconds 0.029001712799072266\n",
      "Epoch 321: Train_loss 27726723072.0, Validation_loss 23723069440.0, Seconds 0.02951979637145996\n",
      "Epoch 322: Train_loss 27724517376.0, Validation_loss 23722885120.0, Seconds 0.025992631912231445\n",
      "Epoch 323: Train_loss 27722268672.0, Validation_loss 23722106880.0, Seconds 0.0299985408782959\n",
      "Epoch 324: Train_loss 27719905280.0, Validation_loss 23721230336.0, Seconds 0.03450822830200195\n",
      "Epoch 325: Train_loss 27718078464.0, Validation_loss 23719870464.0, Seconds 0.02899932861328125\n",
      "Epoch 326: Train_loss 27715506176.0, Validation_loss 23719342080.0, Seconds 0.03400015830993652\n",
      "Epoch 327: Train_loss 27713642496.0, Validation_loss 23718410240.0, Seconds 0.03352046012878418\n",
      "Epoch 328: Train_loss 27711246336.0, Validation_loss 23717019648.0, Seconds 0.03400468826293945\n",
      "Epoch 329: Train_loss 27709329408.0, Validation_loss 23715895296.0, Seconds 0.032006263732910156\n",
      "Epoch 330: Train_loss 27706947584.0, Validation_loss 23713966080.0, Seconds 0.03200340270996094\n",
      "Epoch 331: Train_loss 27705036800.0, Validation_loss 23712329728.0, Seconds 0.03252768516540527\n",
      "Epoch 332: Train_loss 27702949888.0, Validation_loss 23710844928.0, Seconds 0.027991771697998047\n",
      "Epoch 333: Train_loss 27700824064.0, Validation_loss 23709378560.0, Seconds 0.032013654708862305\n",
      "Epoch 334: Train_loss 27698776064.0, Validation_loss 23708665856.0, Seconds 0.03150773048400879\n",
      "Epoch 335: Train_loss 27696738304.0, Validation_loss 23707576320.0, Seconds 0.028002262115478516\n",
      "Epoch 336: Train_loss 27694573568.0, Validation_loss 23706433536.0, Seconds 0.02999401092529297\n",
      "Epoch 337: Train_loss 27692812288.0, Validation_loss 23704971264.0, Seconds 0.02950763702392578\n",
      "Epoch 338: Train_loss 27690653696.0, Validation_loss 23704154112.0, Seconds 0.025999784469604492\n",
      "Epoch 339: Train_loss 27688773632.0, Validation_loss 23703025664.0, Seconds 0.025999784469604492\n",
      "Epoch 340: Train_loss 27686940672.0, Validation_loss 23701241856.0, Seconds 0.027004718780517578\n",
      "Epoch 341: Train_loss 27684855808.0, Validation_loss 23699814400.0, Seconds 0.028519153594970703\n",
      "Epoch 342: Train_loss 27683039232.0, Validation_loss 23698272256.0, Seconds 0.028993844985961914\n",
      "Epoch 343: Train_loss 27680845824.0, Validation_loss 23696922624.0, Seconds 0.03000044822692871\n",
      "Epoch 344: Train_loss 27679180800.0, Validation_loss 23694526464.0, Seconds 0.026747465133666992\n",
      "Epoch 345: Train_loss 27677181952.0, Validation_loss 23693027328.0, Seconds 0.030923128128051758\n",
      "Epoch 346: Train_loss 27675271168.0, Validation_loss 23691368448.0, Seconds 0.029074668884277344\n",
      "Epoch 347: Train_loss 27673264128.0, Validation_loss 23689984000.0, Seconds 0.031928062438964844\n",
      "Epoch 348: Train_loss 27671547904.0, Validation_loss 23688855552.0, Seconds 0.030505895614624023\n",
      "Epoch 349: Train_loss 27669633024.0, Validation_loss 23687172096.0, Seconds 0.026999473571777344\n",
      "Epoch 350: Train_loss 27667953664.0, Validation_loss 23685429248.0, Seconds 0.03301668167114258\n",
      "Epoch 351: Train_loss 27665876992.0, Validation_loss 23684458496.0, Seconds 0.027514219284057617\n",
      "Epoch 352: Train_loss 27664187392.0, Validation_loss 23679662080.0, Seconds 0.027997493743896484\n",
      "Epoch 353: Train_loss 27661053952.0, Validation_loss 23673939968.0, Seconds 0.03300619125366211\n",
      "Epoch 354: Train_loss 27658248192.0, Validation_loss 23667023872.0, Seconds 0.029510498046875\n",
      "Epoch 355: Train_loss 27655024640.0, Validation_loss 23660062720.0, Seconds 0.02707982063293457\n",
      "Epoch 356: Train_loss 27652085760.0, Validation_loss 23654240256.0, Seconds 0.02691936492919922\n",
      "Epoch 357: Train_loss 27649441792.0, Validation_loss 23649533952.0, Seconds 0.03200554847717285\n",
      "Epoch 358: Train_loss 27647193088.0, Validation_loss 23645050880.0, Seconds 0.027506589889526367\n",
      "Epoch 359: Train_loss 27644749824.0, Validation_loss 23642476544.0, Seconds 0.026935100555419922\n",
      "Epoch 360: Train_loss 27642832896.0, Validation_loss 23640248320.0, Seconds 0.0289914608001709\n",
      "Epoch 361: Train_loss 27640788992.0, Validation_loss 23637960704.0, Seconds 0.028508901596069336\n",
      "Epoch 362: Train_loss 27638843392.0, Validation_loss 23636144128.0, Seconds 0.03100728988647461\n",
      "Epoch 363: Train_loss 27637368832.0, Validation_loss 23634587648.0, Seconds 0.032000064849853516\n",
      "Epoch 364: Train_loss 27635406848.0, Validation_loss 23632891904.0, Seconds 0.03200244903564453\n",
      "Epoch 365: Train_loss 27633549312.0, Validation_loss 23630977024.0, Seconds 0.031514883041381836\n",
      "Epoch 366: Train_loss 27632064512.0, Validation_loss 23628892160.0, Seconds 0.028072595596313477\n",
      "Epoch 367: Train_loss 27630231552.0, Validation_loss 23627251712.0, Seconds 0.02794647216796875\n",
      "Epoch 368: Train_loss 27628623872.0, Validation_loss 23624654848.0, Seconds 0.026534318923950195\n",
      "Epoch 369: Train_loss 27627036672.0, Validation_loss 23622942720.0, Seconds 0.029000520706176758\n",
      "Epoch 370: Train_loss 27625480192.0, Validation_loss 23620823040.0, Seconds 0.0279996395111084\n",
      "Epoch 371: Train_loss 27623841792.0, Validation_loss 23618674688.0, Seconds 0.029003381729125977\n",
      "Epoch 372: Train_loss 27622164480.0, Validation_loss 23616835584.0, Seconds 0.03051161766052246\n",
      "Epoch 373: Train_loss 27620401152.0, Validation_loss 23615823872.0, Seconds 0.029000282287597656\n",
      "Epoch 374: Train_loss 27619057664.0, Validation_loss 23614158848.0, Seconds 0.029015779495239258\n",
      "Epoch 375: Train_loss 27617200128.0, Validation_loss 23615148032.0, Seconds 0.029518604278564453\n",
      "Epoch 376: Train_loss 27616004096.0, Validation_loss 23611754496.0, Seconds 0.03399825096130371\n",
      "Epoch 377: Train_loss 27614076928.0, Validation_loss 23611840512.0, Seconds 0.03300738334655762\n",
      "Epoch 378: Train_loss 27612985344.0, Validation_loss 23607851008.0, Seconds 0.03153491020202637\n",
      "Epoch 379: Train_loss 27611260928.0, Validation_loss 23606036480.0, Seconds 0.03000187873840332\n",
      "Epoch 380: Train_loss 27609808896.0, Validation_loss 23604977664.0, Seconds 0.033002614974975586\n",
      "Epoch 381: Train_loss 27608444928.0, Validation_loss 23603052544.0, Seconds 0.028530120849609375\n",
      "Epoch 382: Train_loss 27606747136.0, Validation_loss 23600412672.0, Seconds 0.03100132942199707\n",
      "Epoch 383: Train_loss 27605612544.0, Validation_loss 23598495744.0, Seconds 0.03200697898864746\n",
      "Epoch 384: Train_loss 27604035584.0, Validation_loss 23597617152.0, Seconds 0.029590845108032227\n",
      "Epoch 385: Train_loss 27602743296.0, Validation_loss 23595823104.0, Seconds 0.03000354766845703\n",
      "Epoch 386: Train_loss 27601108992.0, Validation_loss 23593916416.0, Seconds 0.031003713607788086\n",
      "Epoch 387: Train_loss 27599935488.0, Validation_loss 23592269824.0, Seconds 0.03200531005859375\n",
      "Epoch 388: Train_loss 27598768128.0, Validation_loss 23591211008.0, Seconds 0.0295102596282959\n",
      "Epoch 389: Train_loss 27597154304.0, Validation_loss 23589120000.0, Seconds 0.03006601333618164\n",
      "Epoch 390: Train_loss 27595917312.0, Validation_loss 23587921920.0, Seconds 0.15298914909362793\n",
      "Epoch 391: Train_loss 27594614784.0, Validation_loss 23588399104.0, Seconds 0.030000686645507812\n",
      "Epoch 392: Train_loss 27593236480.0, Validation_loss 23587901440.0, Seconds 0.03699851036071777\n",
      "Epoch 393: Train_loss 27592075264.0, Validation_loss 23585331200.0, Seconds 0.03052234649658203\n",
      "Epoch 394: Train_loss 27590739968.0, Validation_loss 23583682560.0, Seconds 0.0299985408782959\n",
      "Epoch 395: Train_loss 27589474304.0, Validation_loss 23582613504.0, Seconds 0.031001806259155273\n",
      "Epoch 396: Train_loss 27588349952.0, Validation_loss 23581337600.0, Seconds 0.030002593994140625\n",
      "Epoch 397: Train_loss 27587035136.0, Validation_loss 23580764160.0, Seconds 0.031458377838134766\n",
      "Epoch 398: Train_loss 27585916928.0, Validation_loss 23578955776.0, Seconds 0.03299999237060547\n",
      "Epoch 399: Train_loss 27584555008.0, Validation_loss 23577335808.0, Seconds 0.029002904891967773\n",
      "Epoch 400: Train_loss 27583567872.0, Validation_loss 23576295424.0, Seconds 0.028506755828857422\n",
      "Epoch 401: Train_loss 27582160896.0, Validation_loss 23575586816.0, Seconds 0.03100109100341797\n",
      "Epoch 402: Train_loss 27581069312.0, Validation_loss 23574421504.0, Seconds 0.028001070022583008\n",
      "Epoch 403: Train_loss 27579912192.0, Validation_loss 23573972992.0, Seconds 0.026545286178588867\n",
      "Epoch 404: Train_loss 27578384384.0, Validation_loss 23572699136.0, Seconds 0.02899456024169922\n",
      "Epoch 405: Train_loss 27577520128.0, Validation_loss 23570638848.0, Seconds 0.03299427032470703\n",
      "Epoch 406: Train_loss 27576152064.0, Validation_loss 23569567744.0, Seconds 0.030077219009399414\n",
      "Epoch 407: Train_loss 27574851584.0, Validation_loss 23569223680.0, Seconds 0.02751755714416504\n",
      "Epoch 408: Train_loss 27573846016.0, Validation_loss 23568281600.0, Seconds 0.030000925064086914\n",
      "Epoch 409: Train_loss 27572824064.0, Validation_loss 23568201728.0, Seconds 0.030999422073364258\n",
      "Epoch 410: Train_loss 27571597312.0, Validation_loss 23566501888.0, Seconds 0.03351449966430664\n",
      "Epoch 411: Train_loss 27570456576.0, Validation_loss 23566409728.0, Seconds 0.03099966049194336\n",
      "Epoch 412: Train_loss 27569334272.0, Validation_loss 23565807616.0, Seconds 0.033998727798461914\n",
      "Epoch 413: Train_loss 27568347136.0, Validation_loss 23563225088.0, Seconds 0.030511140823364258\n",
      "Epoch 414: Train_loss 27567138816.0, Validation_loss 23563712512.0, Seconds 0.03400778770446777\n",
      "Epoch 415: Train_loss 27566290944.0, Validation_loss 23562217472.0, Seconds 0.03299236297607422\n",
      "Epoch 416: Train_loss 27565058048.0, Validation_loss 23560890368.0, Seconds 0.03051304817199707\n",
      "Epoch 417: Train_loss 27564189696.0, Validation_loss 23561070592.0, Seconds 0.027007102966308594\n",
      "Epoch 418: Train_loss 27562983424.0, Validation_loss 23559424000.0, Seconds 0.027999401092529297\n",
      "Epoch 419: Train_loss 27562016768.0, Validation_loss 23557855232.0, Seconds 0.0330049991607666\n",
      "Epoch 420: Train_loss 27561162752.0, Validation_loss 23557138432.0, Seconds 0.031510114669799805\n",
      "Epoch 421: Train_loss 27560071168.0, Validation_loss 23556530176.0, Seconds 0.02800154685974121\n",
      "Epoch 422: Train_loss 27558946816.0, Validation_loss 23555590144.0, Seconds 0.026999950408935547\n",
      "Epoch 423: Train_loss 27558187008.0, Validation_loss 23554639872.0, Seconds 0.030538558959960938\n",
      "Epoch 424: Train_loss 27557040128.0, Validation_loss 23553146880.0, Seconds 0.03200173377990723\n",
      "Epoch 425: Train_loss 27556075520.0, Validation_loss 23551993856.0, Seconds 0.032073974609375\n",
      "Epoch 426: Train_loss 27555139584.0, Validation_loss 23551694848.0, Seconds 0.03052377700805664\n",
      "Epoch 427: Train_loss 27554099200.0, Validation_loss 23550224384.0, Seconds 0.03000497817993164\n",
      "Epoch 428: Train_loss 27553298432.0, Validation_loss 23548764160.0, Seconds 0.029997587203979492\n",
      "Epoch 429: Train_loss 27552344064.0, Validation_loss 23548000256.0, Seconds 0.03451395034790039\n",
      "Epoch 430: Train_loss 27551344640.0, Validation_loss 23546693632.0, Seconds 0.029999732971191406\n",
      "Epoch 431: Train_loss 27550578688.0, Validation_loss 23545010176.0, Seconds 0.0310060977935791\n",
      "Epoch 432: Train_loss 27549493248.0, Validation_loss 23545122816.0, Seconds 0.033069610595703125\n",
      "Epoch 433: Train_loss 27548700672.0, Validation_loss 23543263232.0, Seconds 0.03358721733093262\n",
      "Epoch 434: Train_loss 27547707392.0, Validation_loss 23542380544.0, Seconds 0.02700018882751465\n",
      "Epoch 435: Train_loss 27546904576.0, Validation_loss 23541127168.0, Seconds 0.026015281677246094\n",
      "Epoch 436: Train_loss 27546028032.0, Validation_loss 23539957760.0, Seconds 0.03249859809875488\n",
      "Epoch 437: Train_loss 27545217024.0, Validation_loss 23539075072.0, Seconds 0.027998924255371094\n",
      "Epoch 438: Train_loss 27544166400.0, Validation_loss 23537653760.0, Seconds 0.031000375747680664\n",
      "Epoch 439: Train_loss 27543521280.0, Validation_loss 23536300032.0, Seconds 0.03152799606323242\n",
      "Epoch 440: Train_loss 27542497280.0, Validation_loss 23535171584.0, Seconds 0.03199958801269531\n",
      "Epoch 441: Train_loss 27541745664.0, Validation_loss 23533551616.0, Seconds 0.02800750732421875\n",
      "Epoch 442: Train_loss 27541039104.0, Validation_loss 23533072384.0, Seconds 0.031528472900390625\n",
      "Epoch 443: Train_loss 27539888128.0, Validation_loss 23532847104.0, Seconds 0.030097484588623047\n",
      "Epoch 444: Train_loss 27539275776.0, Validation_loss 23531528192.0, Seconds 0.02891254425048828\n",
      "Epoch 445: Train_loss 27538094080.0, Validation_loss 23530881024.0, Seconds 0.02700662612915039\n",
      "Epoch 446: Train_loss 27537545216.0, Validation_loss 23529183232.0, Seconds 0.02852344512939453\n",
      "Epoch 447: Train_loss 27536482304.0, Validation_loss 23527661568.0, Seconds 0.03099966049194336\n",
      "Epoch 448: Train_loss 27535466496.0, Validation_loss 23526543360.0, Seconds 0.030009746551513672\n",
      "Epoch 449: Train_loss 27534626816.0, Validation_loss 23525068800.0, Seconds 0.028524398803710938\n",
      "Epoch 450: Train_loss 27533721600.0, Validation_loss 23523158016.0, Seconds 0.02799844741821289\n",
      "Epoch 451: Train_loss 27532716032.0, Validation_loss 23522600960.0, Seconds 0.02800154685974121\n",
      "Epoch 452: Train_loss 27531765760.0, Validation_loss 23520706560.0, Seconds 0.027016162872314453\n",
      "Epoch 453: Train_loss 27530823680.0, Validation_loss 23519612928.0, Seconds 0.027519702911376953\n",
      "Epoch 454: Train_loss 27529558016.0, Validation_loss 23517595648.0, Seconds 0.02899909019470215\n",
      "Epoch 455: Train_loss 27528544256.0, Validation_loss 23514796032.0, Seconds 0.029002904891967773\n",
      "Epoch 456: Train_loss 27527118848.0, Validation_loss 23510577152.0, Seconds 0.029536724090576172\n",
      "Epoch 457: Train_loss 27525761024.0, Validation_loss 23507056640.0, Seconds 0.03200578689575195\n",
      "Epoch 458: Train_loss 27524567040.0, Validation_loss 23504703488.0, Seconds 0.030987977981567383\n",
      "Epoch 459: Train_loss 27523504128.0, Validation_loss 23504150528.0, Seconds 0.026002168655395508\n",
      "Epoch 460: Train_loss 27522277376.0, Validation_loss 23503177728.0, Seconds 0.029529571533203125\n",
      "Epoch 461: Train_loss 27521341440.0, Validation_loss 23500746752.0, Seconds 0.03199887275695801\n",
      "Epoch 462: Train_loss 27520452608.0, Validation_loss 23498862592.0, Seconds 0.032000064849853516\n",
      "Epoch 463: Train_loss 27519447040.0, Validation_loss 23497517056.0, Seconds 0.030522823333740234\n",
      "Epoch 464: Train_loss 27518799872.0, Validation_loss 23497402368.0, Seconds 0.03199458122253418\n",
      "Epoch 465: Train_loss 27517835264.0, Validation_loss 23496247296.0, Seconds 0.02899909019470215\n",
      "Epoch 466: Train_loss 27517218816.0, Validation_loss 23494787072.0, Seconds 0.03251051902770996\n",
      "Epoch 467: Train_loss 27516198912.0, Validation_loss 23492325376.0, Seconds 0.028999805450439453\n",
      "Epoch 468: Train_loss 27515604992.0, Validation_loss 23490799616.0, Seconds 0.029001235961914062\n",
      "Epoch 469: Train_loss 27514806272.0, Validation_loss 23489320960.0, Seconds 0.028019428253173828\n",
      "Epoch 470: Train_loss 27514077184.0, Validation_loss 23486468096.0, Seconds 0.02853250503540039\n",
      "Epoch 471: Train_loss 27513260032.0, Validation_loss 23483899904.0, Seconds 0.02799701690673828\n",
      "Epoch 472: Train_loss 27512487936.0, Validation_loss 23481872384.0, Seconds 0.04850459098815918\n",
      "Epoch 473: Train_loss 27511654400.0, Validation_loss 23479859200.0, Seconds 0.029011249542236328\n",
      "Epoch 474: Train_loss 27511031808.0, Validation_loss 23479285760.0, Seconds 0.03899359703063965\n",
      "Epoch 475: Train_loss 27510128640.0, Validation_loss 23477753856.0, Seconds 0.03453660011291504\n",
      "Epoch 476: Train_loss 27509319680.0, Validation_loss 23475142656.0, Seconds 0.030991554260253906\n",
      "Epoch 477: Train_loss 27508615168.0, Validation_loss 23473084416.0, Seconds 0.03700065612792969\n",
      "Epoch 478: Train_loss 27507693568.0, Validation_loss 23471820800.0, Seconds 0.03551173210144043\n",
      "Epoch 479: Train_loss 27506946048.0, Validation_loss 23470086144.0, Seconds 0.029001951217651367\n",
      "Epoch 480: Train_loss 27506130944.0, Validation_loss 23468734464.0, Seconds 0.032994747161865234\n",
      "Epoch 481: Train_loss 27505735680.0, Validation_loss 23467165696.0, Seconds 0.03351092338562012\n",
      "Epoch 482: Train_loss 27504760832.0, Validation_loss 23465924608.0, Seconds 0.03099966049194336\n",
      "Epoch 483: Train_loss 27504044032.0, Validation_loss 23464372224.0, Seconds 0.031000852584838867\n",
      "Epoch 484: Train_loss 27503507456.0, Validation_loss 23463008256.0, Seconds 0.028002023696899414\n",
      "Epoch 485: Train_loss 27502755840.0, Validation_loss 23461582848.0, Seconds 0.03050827980041504\n",
      "Epoch 486: Train_loss 27502018560.0, Validation_loss 23460360192.0, Seconds 0.030997514724731445\n",
      "Epoch 487: Train_loss 27501330432.0, Validation_loss 23459506176.0, Seconds 0.03400564193725586\n",
      "Epoch 488: Train_loss 27500746752.0, Validation_loss 23457382400.0, Seconds 0.03451037406921387\n",
      "Epoch 489: Train_loss 27499839488.0, Validation_loss 23455948800.0, Seconds 0.032997846603393555\n",
      "Epoch 490: Train_loss 27499053056.0, Validation_loss 23453722624.0, Seconds 0.028998136520385742\n",
      "Epoch 491: Train_loss 27498143744.0, Validation_loss 23452780544.0, Seconds 0.036512136459350586\n",
      "Epoch 492: Train_loss 27497609216.0, Validation_loss 23451688960.0, Seconds 0.04200124740600586\n",
      "Epoch 493: Train_loss 27496794112.0, Validation_loss 23451865088.0, Seconds 0.037531375885009766\n",
      "Epoch 494: Train_loss 27496013824.0, Validation_loss 23451504640.0, Seconds 0.03400731086730957\n",
      "Epoch 495: Train_loss 27495481344.0, Validation_loss 23449909248.0, Seconds 0.04100322723388672\n",
      "Epoch 496: Train_loss 27494850560.0, Validation_loss 23449341952.0, Seconds 0.04151153564453125\n",
      "Epoch 497: Train_loss 27494035456.0, Validation_loss 23449741312.0, Seconds 0.043001413345336914\n",
      "Epoch 498: Train_loss 27493466112.0, Validation_loss 23448227840.0, Seconds 0.041512250900268555\n",
      "Epoch 499: Train_loss 27492884480.0, Validation_loss 23446976512.0, Seconds 0.031999826431274414\n",
      "Epoch 500: Train_loss 27492249600.0, Validation_loss 23446714368.0, Seconds 0.031008243560791016\n",
      "Epoch 501: Train_loss 27491454976.0, Validation_loss 23445538816.0, Seconds 0.03201484680175781\n",
      "Epoch 502: Train_loss 27490785280.0, Validation_loss 23445352448.0, Seconds 0.032510995864868164\n",
      "Epoch 503: Train_loss 27490252800.0, Validation_loss 23443425280.0, Seconds 0.02899956703186035\n",
      "Epoch 504: Train_loss 27489949696.0, Validation_loss 23443408896.0, Seconds 0.02900528907775879\n",
      "Epoch 505: Train_loss 27489085440.0, Validation_loss 23443324928.0, Seconds 0.027510881423950195\n",
      "Epoch 506: Train_loss 27488493568.0, Validation_loss 23442159616.0, Seconds 0.029999494552612305\n",
      "Epoch 507: Train_loss 27487946752.0, Validation_loss 23441420288.0, Seconds 0.03199911117553711\n",
      "Epoch 508: Train_loss 27487078400.0, Validation_loss 23441061888.0, Seconds 0.027509689331054688\n",
      "Epoch 509: Train_loss 27486513152.0, Validation_loss 23439722496.0, Seconds 0.028996944427490234\n",
      "Epoch 510: Train_loss 27485978624.0, Validation_loss 23439298560.0, Seconds 0.031000614166259766\n",
      "Epoch 511: Train_loss 27485024256.0, Validation_loss 23439339520.0, Seconds 0.03101038932800293\n",
      "Epoch 512: Train_loss 27484596224.0, Validation_loss 23439181824.0, Seconds 0.029526710510253906\n",
      "Epoch 513: Train_loss 27483637760.0, Validation_loss 23438032896.0, Seconds 0.02700519561767578\n",
      "Epoch 514: Train_loss 27483256832.0, Validation_loss 23437101056.0, Seconds 0.032994985580444336\n",
      "Epoch 515: Train_loss 27482355712.0, Validation_loss 23436701696.0, Seconds 0.028516292572021484\n",
      "Epoch 516: Train_loss 27481800704.0, Validation_loss 23436310528.0, Seconds 0.03199577331542969\n",
      "Epoch 517: Train_loss 27481049088.0, Validation_loss 23435145216.0, Seconds 0.03099846839904785\n",
      "Epoch 518: Train_loss 27480363008.0, Validation_loss 23434414080.0, Seconds 0.03351473808288574\n",
      "Epoch 519: Train_loss 27479660544.0, Validation_loss 23433887744.0, Seconds 0.028998851776123047\n",
      "Epoch 520: Train_loss 27478835200.0, Validation_loss 23432415232.0, Seconds 0.036000728607177734\n",
      "Epoch 521: Train_loss 27478384640.0, Validation_loss 23431014400.0, Seconds 0.032511234283447266\n",
      "Epoch 522: Train_loss 27477645312.0, Validation_loss 23430762496.0, Seconds 0.03101325035095215\n",
      "Epoch 523: Train_loss 27477020672.0, Validation_loss 23429120000.0, Seconds 0.03098607063293457\n",
      "Epoch 524: Train_loss 27476197376.0, Validation_loss 23428661248.0, Seconds 0.03151059150695801\n",
      "Epoch 525: Train_loss 27475523584.0, Validation_loss 23427084288.0, Seconds 0.03700590133666992\n",
      "Epoch 526: Train_loss 27474999296.0, Validation_loss 23425544192.0, Seconds 0.03600621223449707\n",
      "Epoch 527: Train_loss 27474204672.0, Validation_loss 23424528384.0, Seconds 0.030518531799316406\n",
      "Epoch 528: Train_loss 27473553408.0, Validation_loss 23423109120.0, Seconds 0.029995441436767578\n",
      "Epoch 529: Train_loss 27472830464.0, Validation_loss 23420723200.0, Seconds 0.029001474380493164\n",
      "Epoch 530: Train_loss 27472183296.0, Validation_loss 23418277888.0, Seconds 0.031001567840576172\n",
      "Epoch 531: Train_loss 27471613952.0, Validation_loss 23416176640.0, Seconds 0.030504703521728516\n",
      "Epoch 532: Train_loss 27470602240.0, Validation_loss 23415320576.0, Seconds 0.03299975395202637\n",
      "Epoch 533: Train_loss 27470051328.0, Validation_loss 23414001664.0, Seconds 0.0330042839050293\n",
      "Epoch 534: Train_loss 27469314048.0, Validation_loss 23413499904.0, Seconds 0.03351187705993652\n",
      "Epoch 535: Train_loss 27468720128.0, Validation_loss 23412148224.0, Seconds 0.03299307823181152\n",
      "Epoch 536: Train_loss 27467722752.0, Validation_loss 23410810880.0, Seconds 0.02900218963623047\n",
      "Epoch 537: Train_loss 27467044864.0, Validation_loss 23409498112.0, Seconds 0.032506465911865234\n",
      "Epoch 538: Train_loss 27466463232.0, Validation_loss 23408205824.0, Seconds 0.029999732971191406\n",
      "Epoch 539: Train_loss 27465512960.0, Validation_loss 23406446592.0, Seconds 0.03000044822692871\n",
      "Epoch 540: Train_loss 27465201664.0, Validation_loss 23404769280.0, Seconds 0.03152585029602051\n",
      "Epoch 541: Train_loss 27463913472.0, Validation_loss 23403497472.0, Seconds 0.028001785278320312\n",
      "Epoch 542: Train_loss 27463317504.0, Validation_loss 23401811968.0, Seconds 0.03300356864929199\n",
      "Epoch 543: Train_loss 27462760448.0, Validation_loss 23400437760.0, Seconds 0.03454422950744629\n",
      "Epoch 544: Train_loss 27461787648.0, Validation_loss 23398637568.0, Seconds 0.029999971389770508\n",
      "Epoch 545: Train_loss 27461244928.0, Validation_loss 23396771840.0, Seconds 0.030999183654785156\n",
      "Epoch 546: Train_loss 27460177920.0, Validation_loss 23395090432.0, Seconds 0.029016971588134766\n",
      "Epoch 547: Train_loss 27459510272.0, Validation_loss 23393490944.0, Seconds 0.03150486946105957\n",
      "Epoch 548: Train_loss 27458856960.0, Validation_loss 23391236096.0, Seconds 0.03004908561706543\n",
      "Epoch 549: Train_loss 27458031616.0, Validation_loss 23389648896.0, Seconds 0.02797412872314453\n",
      "Epoch 550: Train_loss 27458066432.0, Validation_loss 23388469248.0, Seconds 0.031503915786743164\n",
      "Epoch 551: Train_loss 27456858112.0, Validation_loss 23387312128.0, Seconds 0.03299975395202637\n",
      "Epoch 552: Train_loss 27455854592.0, Validation_loss 23386234880.0, Seconds 0.032000064849853516\n",
      "Epoch 553: Train_loss 27455846400.0, Validation_loss 23385753600.0, Seconds 0.026671171188354492\n",
      "Epoch 554: Train_loss 27454830592.0, Validation_loss 23384414208.0, Seconds 0.02607583999633789\n",
      "Epoch 555: Train_loss 27454162944.0, Validation_loss 23383048192.0, Seconds 0.028925657272338867\n",
      "Epoch 556: Train_loss 27453165568.0, Validation_loss 23382472704.0, Seconds 0.029008865356445312\n",
      "Epoch 557: Train_loss 27452841984.0, Validation_loss 23380572160.0, Seconds 0.029594898223876953\n",
      "Epoch 558: Train_loss 27451654144.0, Validation_loss 23379472384.0, Seconds 0.030011415481567383\n",
      "Epoch 559: Train_loss 27451265024.0, Validation_loss 23377713152.0, Seconds 0.028989553451538086\n",
      "Epoch 560: Train_loss 27450263552.0, Validation_loss 23376607232.0, Seconds 0.032534122467041016\n",
      "Epoch 561: Train_loss 27449888768.0, Validation_loss 23375558656.0, Seconds 0.029999732971191406\n",
      "Epoch 562: Train_loss 27449358336.0, Validation_loss 23374004224.0, Seconds 0.027007579803466797\n",
      "Epoch 563: Train_loss 27448500224.0, Validation_loss 23372976128.0, Seconds 0.030514240264892578\n",
      "Epoch 564: Train_loss 27447785472.0, Validation_loss 23372056576.0, Seconds 0.0390017032623291\n",
      "Epoch 565: Train_loss 27447009280.0, Validation_loss 23370960896.0, Seconds 0.032996177673339844\n",
      "Epoch 566: Train_loss 27446620160.0, Validation_loss 23370168320.0, Seconds 0.03351449966430664\n",
      "Epoch 567: Train_loss 27445626880.0, Validation_loss 23367677952.0, Seconds 0.033998966217041016\n",
      "Epoch 568: Train_loss 27445047296.0, Validation_loss 23365601280.0, Seconds 0.031003475189208984\n",
      "Epoch 569: Train_loss 27444064256.0, Validation_loss 23363295232.0, Seconds 0.033617258071899414\n",
      "Epoch 570: Train_loss 27443496960.0, Validation_loss 23361943552.0, Seconds 0.03499484062194824\n",
      "Epoch 571: Train_loss 27442665472.0, Validation_loss 23359094784.0, Seconds 0.030012845993041992\n",
      "Epoch 572: Train_loss 27442333696.0, Validation_loss 23357659136.0, Seconds 0.03151988983154297\n",
      "Epoch 573: Train_loss 27441207296.0, Validation_loss 23356391424.0, Seconds 0.03099966049194336\n",
      "Epoch 574: Train_loss 27440683008.0, Validation_loss 23354755072.0, Seconds 0.029995203018188477\n",
      "Epoch 575: Train_loss 27439769600.0, Validation_loss 23353178112.0, Seconds 0.034009456634521484\n",
      "Epoch 576: Train_loss 27439484928.0, Validation_loss 23352266752.0, Seconds 0.03451871871948242\n",
      "Epoch 577: Train_loss 27438604288.0, Validation_loss 23349665792.0, Seconds 0.03101181983947754\n",
      "Epoch 578: Train_loss 27437832192.0, Validation_loss 23348588544.0, Seconds 0.032015085220336914\n",
      "Epoch 579: Train_loss 27437246464.0, Validation_loss 23347292160.0, Seconds 0.03152155876159668\n",
      "Epoch 580: Train_loss 27436371968.0, Validation_loss 23344750592.0, Seconds 0.031000614166259766\n",
      "Epoch 581: Train_loss 27435096064.0, Validation_loss 23342274560.0, Seconds 0.03300356864929199\n",
      "Epoch 582: Train_loss 27435182080.0, Validation_loss 23341277184.0, Seconds 0.033505916595458984\n",
      "Epoch 583: Train_loss 27433826304.0, Validation_loss 23340165120.0, Seconds 0.032007455825805664\n",
      "Epoch 584: Train_loss 27433203712.0, Validation_loss 23338981376.0, Seconds 0.03502249717712402\n",
      "Epoch 585: Train_loss 27432910848.0, Validation_loss 23338043392.0, Seconds 0.028521299362182617\n",
      "Epoch 586: Train_loss 27431927808.0, Validation_loss 23337472000.0, Seconds 0.029999494552612305\n",
      "Epoch 587: Train_loss 27431043072.0, Validation_loss 23335665664.0, Seconds 0.029007673263549805\n",
      "Epoch 588: Train_loss 27430703104.0, Validation_loss 23334746112.0, Seconds 0.032514333724975586\n",
      "Epoch 589: Train_loss 27429879808.0, Validation_loss 23334481920.0, Seconds 0.03205132484436035\n",
      "Epoch 590: Train_loss 27429138432.0, Validation_loss 23331168256.0, Seconds 0.03294825553894043\n",
      "Epoch 591: Train_loss 27428706304.0, Validation_loss 23327924224.0, Seconds 0.02951526641845703\n",
      "Epoch 592: Train_loss 27427768320.0, Validation_loss 23324585984.0, Seconds 0.03099989891052246\n",
      "Epoch 593: Train_loss 27427129344.0, Validation_loss 23323054080.0, Seconds 0.03200101852416992\n",
      "Epoch 594: Train_loss 27426144256.0, Validation_loss 23320573952.0, Seconds 0.035547733306884766\n",
      "Epoch 595: Train_loss 27425894400.0, Validation_loss 23318724608.0, Seconds 0.02898693084716797\n",
      "Epoch 596: Train_loss 27424729088.0, Validation_loss 23317389312.0, Seconds 0.03300285339355469\n",
      "Epoch 597: Train_loss 27424761856.0, Validation_loss 23317026816.0, Seconds 0.031011581420898438\n",
      "Epoch 598: Train_loss 27423418368.0, Validation_loss 23316609024.0, Seconds 0.035523176193237305\n",
      "Epoch 599: Train_loss 27423021056.0, Validation_loss 23315607552.0, Seconds 0.03498482704162598\n",
      "Epoch 600: Train_loss 27422070784.0, Validation_loss 23314167808.0, Seconds 0.033514976501464844\n",
      "Epoch 601: Train_loss 27421835264.0, Validation_loss 23313793024.0, Seconds 0.02999711036682129\n",
      "Epoch 602: Train_loss 27420823552.0, Validation_loss 23312414720.0, Seconds 0.036002397537231445\n",
      "Epoch 603: Train_loss 27420493824.0, Validation_loss 23311046656.0, Seconds 0.035515785217285156\n",
      "Epoch 604: Train_loss 27419211776.0, Validation_loss 23307659264.0, Seconds 0.03699803352355957\n",
      "Epoch 605: Train_loss 27418748928.0, Validation_loss 23306117120.0, Seconds 0.03400373458862305\n",
      "Epoch 606: Train_loss 27418181632.0, Validation_loss 23305496576.0, Seconds 0.035335540771484375\n",
      "Epoch 607: Train_loss 27417374720.0, Validation_loss 23304230912.0, Seconds 0.029999256134033203\n",
      "Epoch 608: Train_loss 27416584192.0, Validation_loss 23302666240.0, Seconds 0.1525278091430664\n",
      "Epoch 609: Train_loss 27416074240.0, Validation_loss 23302242304.0, Seconds 0.028521299362182617\n",
      "Epoch 610: Train_loss 27415099392.0, Validation_loss 23300214784.0, Seconds 0.031990766525268555\n",
      "Epoch 611: Train_loss 27414585344.0, Validation_loss 23299035136.0, Seconds 0.029999256134033203\n",
      "Epoch 612: Train_loss 27413655552.0, Validation_loss 23298648064.0, Seconds 0.034516096115112305\n",
      "Epoch 613: Train_loss 27413487616.0, Validation_loss 23299082240.0, Seconds 0.03600049018859863\n",
      "Epoch 614: Train_loss 27412051968.0, Validation_loss 23297028096.0, Seconds 0.03800082206726074\n",
      "Epoch 615: Train_loss 27411824640.0, Validation_loss 23295641600.0, Seconds 0.03651094436645508\n",
      "Epoch 616: Train_loss 27411243008.0, Validation_loss 23296985088.0, Seconds 0.03599905967712402\n",
      "Epoch 617: Train_loss 27410286592.0, Validation_loss 23295260672.0, Seconds 0.033004045486450195\n",
      "Epoch 618: Train_loss 27410176000.0, Validation_loss 23293804544.0, Seconds 0.029514551162719727\n",
      "Epoch 619: Train_loss 27408891904.0, Validation_loss 23293437952.0, Seconds 0.030993938446044922\n",
      "Epoch 620: Train_loss 27408687104.0, Validation_loss 23292348416.0, Seconds 0.03100419044494629\n",
      "Epoch 621: Train_loss 27408285696.0, Validation_loss 23290808320.0, Seconds 0.03450894355773926\n",
      "Epoch 622: Train_loss 27407151104.0, Validation_loss 23290122240.0, Seconds 0.0279998779296875\n",
      "Epoch 623: Train_loss 27407288320.0, Validation_loss 23289767936.0, Seconds 0.03099989891052246\n",
      "Epoch 624: Train_loss 27405946880.0, Validation_loss 23289016320.0, Seconds 0.03151369094848633\n",
      "Epoch 625: Train_loss 27405967360.0, Validation_loss 23288793088.0, Seconds 0.029001951217651367\n",
      "Epoch 626: Train_loss 27405031424.0, Validation_loss 23290089472.0, Seconds 0.030005931854248047\n",
      "Epoch 627: Train_loss 27404449792.0, Validation_loss 23287783424.0, Seconds 0.0295412540435791\n",
      "Epoch 628: Train_loss 27404085248.0, Validation_loss 23286775808.0, Seconds 0.029995441436767578\n",
      "Epoch 629: Train_loss 27403145216.0, Validation_loss 23285446656.0, Seconds 0.03700542449951172\n",
      "Epoch 630: Train_loss 27402928128.0, Validation_loss 23285487616.0, Seconds 0.0355067253112793\n",
      "Epoch 631: Train_loss 27402098688.0, Validation_loss 23284484096.0, Seconds 0.03600144386291504\n",
      "Epoch 632: Train_loss 27401443328.0, Validation_loss 23284416512.0, Seconds 0.037000417709350586\n",
      "Epoch 633: Train_loss 27400972288.0, Validation_loss 23284207616.0, Seconds 0.036098480224609375\n",
      "Epoch 634: Train_loss 27400486912.0, Validation_loss 23282003968.0, Seconds 0.033002614974975586\n",
      "Epoch 635: Train_loss 27399589888.0, Validation_loss 23280715776.0, Seconds 0.030999183654785156\n",
      "Epoch 636: Train_loss 27399170048.0, Validation_loss 23280795648.0, Seconds 0.03152012825012207\n",
      "Epoch 637: Train_loss 27398754304.0, Validation_loss 23279091712.0, Seconds 0.031000375747680664\n",
      "Epoch 638: Train_loss 27398053888.0, Validation_loss 23279077376.0, Seconds 0.0299985408782959\n",
      "Epoch 639: Train_loss 27397107712.0, Validation_loss 23277762560.0, Seconds 0.02852773666381836\n",
      "Epoch 640: Train_loss 27397296128.0, Validation_loss 23276302336.0, Seconds 0.02700948715209961\n",
      "Epoch 641: Train_loss 27395676160.0, Validation_loss 23275003904.0, Seconds 0.02701568603515625\n",
      "Epoch 642: Train_loss 27396016128.0, Validation_loss 23274450944.0, Seconds 0.028983592987060547\n",
      "Epoch 643: Train_loss 27395106816.0, Validation_loss 23273283584.0, Seconds 0.02959275245666504\n",
      "Epoch 644: Train_loss 27394891776.0, Validation_loss 23273510912.0, Seconds 0.0289919376373291\n",
      "Epoch 645: Train_loss 27393984512.0, Validation_loss 23272456192.0, Seconds 0.029999732971191406\n",
      "Epoch 646: Train_loss 27393648640.0, Validation_loss 23272155136.0, Seconds 0.032521724700927734\n",
      "Epoch 647: Train_loss 27393032192.0, Validation_loss 23270086656.0, Seconds 0.02899932861328125\n",
      "Epoch 648: Train_loss 27392669696.0, Validation_loss 23270293504.0, Seconds 0.030007123947143555\n",
      "Epoch 649: Train_loss 27392393216.0, Validation_loss 23268968448.0, Seconds 0.029003381729125977\n",
      "Epoch 650: Train_loss 27391758336.0, Validation_loss 23267387392.0, Seconds 0.030583620071411133\n",
      "Epoch 651: Train_loss 27391285248.0, Validation_loss 23268231168.0, Seconds 0.02698993682861328\n",
      "Epoch 652: Train_loss 27391141888.0, Validation_loss 23267522560.0, Seconds 0.02892923355102539\n",
      "Epoch 653: Train_loss 27390267392.0, Validation_loss 23265452032.0, Seconds 0.03050971031188965\n",
      "Epoch 654: Train_loss 27390332928.0, Validation_loss 23264950272.0, Seconds 0.030000925064086914\n",
      "Epoch 655: Train_loss 27389618176.0, Validation_loss 23266299904.0, Seconds 0.031000137329101562\n",
      "Epoch 656: Train_loss 27389286400.0, Validation_loss 23264385024.0, Seconds 0.036069631576538086\n",
      "Epoch 657: Train_loss 27388592128.0, Validation_loss 23263397888.0, Seconds 0.03899884223937988\n",
      "Epoch 658: Train_loss 27388682240.0, Validation_loss 23262775296.0, Seconds 0.03199958801269531\n",
      "Epoch 659: Train_loss 27387596800.0, Validation_loss 23263961088.0, Seconds 0.032343149185180664\n",
      "Epoch 660: Train_loss 27387820032.0, Validation_loss 23263275008.0, Seconds 0.03300070762634277\n",
      "Epoch 661: Train_loss 27386673152.0, Validation_loss 23262001152.0, Seconds 0.033998727798461914\n",
      "Epoch 662: Train_loss 27386789888.0, Validation_loss 23261194240.0, Seconds 0.032540082931518555\n",
      "Epoch 663: Train_loss 27386220544.0, Validation_loss 23261814784.0, Seconds 0.02999734878540039\n",
      "Epoch 664: Train_loss 27385597952.0, Validation_loss 23262332928.0, Seconds 0.03300213813781738\n",
      "Epoch 665: Train_loss 27385657344.0, Validation_loss 23261612032.0, Seconds 0.03351545333862305\n",
      "Epoch 666: Train_loss 27384702976.0, Validation_loss 23260659712.0, Seconds 0.026000022888183594\n",
      "Epoch 667: Train_loss 27384438784.0, Validation_loss 23260633088.0, Seconds 0.031000375747680664\n",
      "Epoch 668: Train_loss 27383748608.0, Validation_loss 23259793408.0, Seconds 0.030014991760253906\n",
      "Epoch 669: Train_loss 27383834624.0, Validation_loss 23260114944.0, Seconds 0.02851700782775879\n",
      "Epoch 670: Train_loss 27382753280.0, Validation_loss 23258275840.0, Seconds 0.0290069580078125\n",
      "Epoch 671: Train_loss 27382654976.0, Validation_loss 23258046464.0, Seconds 0.03099203109741211\n",
      "Epoch 672: Train_loss 27382319104.0, Validation_loss 23258953728.0, Seconds 0.03453874588012695\n",
      "Epoch 673: Train_loss 27381620736.0, Validation_loss 23257335808.0, Seconds 0.03199911117553711\n",
      "Epoch 674: Train_loss 27381018624.0, Validation_loss 23256825856.0, Seconds 0.03199934959411621\n",
      "Epoch 675: Train_loss 27381594112.0, Validation_loss 23256854528.0, Seconds 0.03152751922607422\n",
      "Epoch 676: Train_loss 27379943424.0, Validation_loss 23257260032.0, Seconds 0.030980348587036133\n",
      "Epoch 677: Train_loss 27379951616.0, Validation_loss 23257198592.0, Seconds 0.031000137329101562\n",
      "Epoch 678: Train_loss 27379122176.0, Validation_loss 23255085056.0, Seconds 0.027516603469848633\n",
      "Epoch 679: Train_loss 27378946048.0, Validation_loss 23255547904.0, Seconds 0.029004573822021484\n",
      "Epoch 680: Train_loss 27378554880.0, Validation_loss 23256336384.0, Seconds 0.028003215789794922\n",
      "Epoch 681: Train_loss 27377801216.0, Validation_loss 23253600256.0, Seconds 0.027994155883789062\n",
      "Epoch 682: Train_loss 27377539072.0, Validation_loss 23255076864.0, Seconds 0.028511524200439453\n",
      "Epoch 683: Train_loss 27377534976.0, Validation_loss 23254798336.0, Seconds 0.027991771697998047\n",
      "Epoch 684: Train_loss 27376193536.0, Validation_loss 23254417408.0, Seconds 0.02900099754333496\n",
      "Epoch 685: Train_loss 27376646144.0, Validation_loss 23252707328.0, Seconds 0.030541419982910156\n",
      "Epoch 686: Train_loss 27375839232.0, Validation_loss 23254224896.0, Seconds 0.029996395111083984\n",
      "Epoch 687: Train_loss 27375087616.0, Validation_loss 23252615168.0, Seconds 0.03007960319519043\n",
      "Epoch 688: Train_loss 27375376384.0, Validation_loss 23252092928.0, Seconds 0.03092503547668457\n",
      "Epoch 689: Train_loss 27374424064.0, Validation_loss 23252881408.0, Seconds 0.030514001846313477\n",
      "Epoch 690: Train_loss 27374239744.0, Validation_loss 23252740096.0, Seconds 0.029994487762451172\n",
      "Epoch 691: Train_loss 27373926400.0, Validation_loss 23252729856.0, Seconds 0.035003662109375\n",
      "Epoch 692: Train_loss 27372820480.0, Validation_loss 23251085312.0, Seconds 0.03305554389953613\n",
      "Epoch 693: Train_loss 27373113344.0, Validation_loss 23251146752.0, Seconds 0.033000946044921875\n",
      "Epoch 694: Train_loss 27371898880.0, Validation_loss 23250878464.0, Seconds 0.0350031852722168\n",
      "Epoch 695: Train_loss 27372365824.0, Validation_loss 23249500160.0, Seconds 0.031021595001220703\n",
      "Epoch 696: Train_loss 27371546624.0, Validation_loss 23250788352.0, Seconds 0.03299736976623535\n",
      "Epoch 697: Train_loss 27370862592.0, Validation_loss 23249743872.0, Seconds 0.028001785278320312\n",
      "Epoch 698: Train_loss 27370584064.0, Validation_loss 23249131520.0, Seconds 0.0305178165435791\n",
      "Epoch 699: Train_loss 27370598400.0, Validation_loss 23248967680.0, Seconds 0.02799677848815918\n",
      "Epoch 700: Train_loss 27369895936.0, Validation_loss 23247632384.0, Seconds 0.026998519897460938\n",
      "Epoch 701: Train_loss 27369842688.0, Validation_loss 23248357376.0, Seconds 0.031525611877441406\n",
      "Epoch 702: Train_loss 27368910848.0, Validation_loss 23247636480.0, Seconds 0.029987812042236328\n",
      "Epoch 703: Train_loss 27368792064.0, Validation_loss 23247575040.0, Seconds 0.029999971389770508\n",
      "Epoch 704: Train_loss 27368574976.0, Validation_loss 23247341568.0, Seconds 0.033019304275512695\n",
      "Epoch 705: Train_loss 27367714816.0, Validation_loss 23247091712.0, Seconds 0.03350543975830078\n",
      "Epoch 706: Train_loss 27367704576.0, Validation_loss 23245807616.0, Seconds 0.03600001335144043\n",
      "Epoch 707: Train_loss 27366967296.0, Validation_loss 23244275712.0, Seconds 0.035520076751708984\n",
      "Epoch 708: Train_loss 27366936576.0, Validation_loss 23244478464.0, Seconds 0.03301668167114258\n",
      "Epoch 709: Train_loss 27366309888.0, Validation_loss 23244533760.0, Seconds 0.03106975555419922\n",
      "Epoch 710: Train_loss 27366223872.0, Validation_loss 23243540480.0, Seconds 0.030936241149902344\n",
      "Epoch 711: Train_loss 27365537792.0, Validation_loss 23242797056.0, Seconds 0.028508663177490234\n",
      "Epoch 712: Train_loss 27365267456.0, Validation_loss 23240515584.0, Seconds 0.026998281478881836\n",
      "Epoch 713: Train_loss 27364632576.0, Validation_loss 23241551872.0, Seconds 0.03098917007446289\n",
      "Epoch 714: Train_loss 27364548608.0, Validation_loss 23239104512.0, Seconds 0.03152751922607422\n",
      "Epoch 715: Train_loss 27364319232.0, Validation_loss 23239360512.0, Seconds 0.033010005950927734\n",
      "Epoch 716: Train_loss 27363921920.0, Validation_loss 23239510016.0, Seconds 0.03399395942687988\n",
      "Epoch 717: Train_loss 27363559424.0, Validation_loss 23239669760.0, Seconds 0.029520750045776367\n",
      "Epoch 718: Train_loss 27363332096.0, Validation_loss 23239219200.0, Seconds 0.03199911117553711\n",
      "Epoch 719: Train_loss 27362402304.0, Validation_loss 23238952960.0, Seconds 0.02700018882751465\n",
      "Epoch 720: Train_loss 27362598912.0, Validation_loss 23238367232.0, Seconds 0.0305178165435791\n",
      "Epoch 721: Train_loss 27361888256.0, Validation_loss 23237138432.0, Seconds 0.027004480361938477\n",
      "Epoch 722: Train_loss 27361605632.0, Validation_loss 23236548608.0, Seconds 0.029001235961914062\n",
      "Epoch 723: Train_loss 27361449984.0, Validation_loss 23236579328.0, Seconds 0.031016111373901367\n",
      "Epoch 724: Train_loss 27360641024.0, Validation_loss 23237105664.0, Seconds 0.0315089225769043\n",
      "Epoch 725: Train_loss 27360688128.0, Validation_loss 23235846144.0, Seconds 0.0269925594329834\n",
      "Epoch 726: Train_loss 27360401408.0, Validation_loss 23236106240.0, Seconds 0.026998281478881836\n",
      "Epoch 727: Train_loss 27359682560.0, Validation_loss 23235371008.0, Seconds 0.02853703498840332\n",
      "Epoch 728: Train_loss 27359449088.0, Validation_loss 23235037184.0, Seconds 0.03000020980834961\n",
      "Epoch 729: Train_loss 27358898176.0, Validation_loss 23233894400.0, Seconds 0.03400087356567383\n",
      "Epoch 730: Train_loss 27358769152.0, Validation_loss 23233062912.0, Seconds 0.038038015365600586\n",
      "Epoch 731: Train_loss 27357980672.0, Validation_loss 23234043904.0, Seconds 0.03499913215637207\n",
      "Epoch 732: Train_loss 27357997056.0, Validation_loss 23233693696.0, Seconds 0.034000396728515625\n",
      "Epoch 733: Train_loss 27357005824.0, Validation_loss 23232407552.0, Seconds 0.030552148818969727\n",
      "Epoch 734: Train_loss 27357360128.0, Validation_loss 23231406080.0, Seconds 0.026988506317138672\n",
      "Epoch 735: Train_loss 27356026880.0, Validation_loss 23231459328.0, Seconds 0.026011943817138672\n",
      "Epoch 736: Train_loss 27356311552.0, Validation_loss 23231078400.0, Seconds 0.02899336814880371\n",
      "Epoch 737: Train_loss 27355222016.0, Validation_loss 23230742528.0, Seconds 0.030506610870361328\n",
      "Epoch 738: Train_loss 27355537408.0, Validation_loss 23229607936.0, Seconds 0.030997753143310547\n",
      "Epoch 739: Train_loss 27354478592.0, Validation_loss 23230275584.0, Seconds 0.032999515533447266\n",
      "Epoch 740: Train_loss 27354249216.0, Validation_loss 23228866560.0, Seconds 0.03451037406921387\n",
      "Epoch 741: Train_loss 27353786368.0, Validation_loss 23227443200.0, Seconds 0.03099989891052246\n",
      "Epoch 742: Train_loss 27353636864.0, Validation_loss 23228151808.0, Seconds 0.037072181701660156\n",
      "Epoch 743: Train_loss 27352707072.0, Validation_loss 23228366848.0, Seconds 0.0316767692565918\n",
      "Epoch 744: Train_loss 27352952832.0, Validation_loss 23227822080.0, Seconds 0.03100728988647461\n",
      "Epoch 745: Train_loss 27351865344.0, Validation_loss 23227123712.0, Seconds 0.03000473976135254\n",
      "Epoch 746: Train_loss 27352420352.0, Validation_loss 23226587136.0, Seconds 0.03151345252990723\n",
      "Epoch 747: Train_loss 27351101440.0, Validation_loss 23228278784.0, Seconds 0.02800607681274414\n",
      "Epoch 748: Train_loss 27351355392.0, Validation_loss 23226519552.0, Seconds 0.02999258041381836\n",
      "Epoch 749: Train_loss 27350675456.0, Validation_loss 23226085376.0, Seconds 0.029002904891967773\n",
      "Epoch 750: Train_loss 27350771712.0, Validation_loss 23226660864.0, Seconds 0.026506423950195312\n",
      "Epoch 751: Train_loss 27349827584.0, Validation_loss 23227013120.0, Seconds 0.031000137329101562\n",
      "Epoch 752: Train_loss 27350128640.0, Validation_loss 23226656768.0, Seconds 0.02899765968322754\n",
      "Epoch 753: Train_loss 27349231616.0, Validation_loss 23226238976.0, Seconds 0.031548261642456055\n",
      "Epoch 754: Train_loss 27349571584.0, Validation_loss 23225284608.0, Seconds 0.028996944427490234\n",
      "Epoch 755: Train_loss 27348574208.0, Validation_loss 23226695680.0, Seconds 0.03199934959411621\n",
      "Epoch 756: Train_loss 27348332544.0, Validation_loss 23224573952.0, Seconds 0.02501392364501953\n",
      "Epoch 757: Train_loss 27348453376.0, Validation_loss 23225321472.0, Seconds 0.031516075134277344\n",
      "Epoch 758: Train_loss 27347548160.0, Validation_loss 23225647104.0, Seconds 0.03299736976623535\n",
      "Epoch 759: Train_loss 27347658752.0, Validation_loss 23225987072.0, Seconds 0.0330049991607666\n",
      "Epoch 760: Train_loss 27346569216.0, Validation_loss 23225337856.0, Seconds 0.03352856636047363\n",
      "Epoch 761: Train_loss 27346667520.0, Validation_loss 23225628672.0, Seconds 0.027999162673950195\n",
      "Epoch 762: Train_loss 27346079744.0, Validation_loss 23224788992.0, Seconds 0.02800583839416504\n",
      "Epoch 763: Train_loss 27345819648.0, Validation_loss 23223828480.0, Seconds 0.028508663177490234\n",
      "Epoch 764: Train_loss 27345238016.0, Validation_loss 23225706496.0, Seconds 0.028003692626953125\n",
      "Epoch 765: Train_loss 27345053696.0, Validation_loss 23223220224.0, Seconds 0.03000640869140625\n",
      "Epoch 766: Train_loss 27344771072.0, Validation_loss 23224201216.0, Seconds 0.025992155075073242\n",
      "Epoch 767: Train_loss 27344433152.0, Validation_loss 23223453696.0, Seconds 0.03351020812988281\n",
      "Epoch 768: Train_loss 27343980544.0, Validation_loss 23225247744.0, Seconds 0.03599739074707031\n",
      "Epoch 769: Train_loss 27343904768.0, Validation_loss 23224055808.0, Seconds 0.028083324432373047\n",
      "Epoch 770: Train_loss 27343052800.0, Validation_loss 23222999040.0, Seconds 0.030455827713012695\n",
      "Epoch 771: Train_loss 27343527936.0, Validation_loss 23223105536.0, Seconds 0.030999183654785156\n",
      "Epoch 772: Train_loss 27342278656.0, Validation_loss 23223078912.0, Seconds 0.031006813049316406\n",
      "Epoch 773: Train_loss 27342831616.0, Validation_loss 23223699456.0, Seconds 0.03152298927307129\n",
      "Epoch 774: Train_loss 27341719552.0, Validation_loss 23223156736.0, Seconds 0.027001619338989258\n",
      "Epoch 775: Train_loss 27341801472.0, Validation_loss 23222269952.0, Seconds 0.03699898719787598\n",
      "Epoch 776: Train_loss 27341328384.0, Validation_loss 23222984704.0, Seconds 0.052516937255859375\n",
      "Epoch 777: Train_loss 27340472320.0, Validation_loss 23223687168.0, Seconds 0.03000664710998535\n",
      "Epoch 778: Train_loss 27341457408.0, Validation_loss 23222700032.0, Seconds 0.029005765914916992\n",
      "Epoch 779: Train_loss 27340089344.0, Validation_loss 23222806528.0, Seconds 0.02951836585998535\n",
      "Epoch 780: Train_loss 27340140544.0, Validation_loss 23223144448.0, Seconds 0.029995441436767578\n",
      "Epoch 781: Train_loss 27339732992.0, Validation_loss 23223558144.0, Seconds 0.032012939453125\n",
      "Epoch 782: Train_loss 27339200512.0, Validation_loss 23221934080.0, Seconds 0.033507585525512695\n",
      "Epoch 783: Train_loss 27339302912.0, Validation_loss 23222509568.0, Seconds 0.030003786087036133\n",
      "Epoch 784: Train_loss 27338489856.0, Validation_loss 23223832576.0, Seconds 0.025999784469604492\n",
      "Epoch 785: Train_loss 27338344448.0, Validation_loss 23221708800.0, Seconds 0.0315248966217041\n",
      "Epoch 786: Train_loss 27338512384.0, Validation_loss 23223144448.0, Seconds 0.033000946044921875\n",
      "Epoch 787: Train_loss 27337611264.0, Validation_loss 23222843392.0, Seconds 0.02799820899963379\n",
      "Epoch 788: Train_loss 27337592832.0, Validation_loss 23221846016.0, Seconds 0.02808356285095215\n",
      "Epoch 789: Train_loss 27337078784.0, Validation_loss 23224076288.0, Seconds 0.03160429000854492\n",
      "Epoch 790: Train_loss 27336933376.0, Validation_loss 23224139776.0, Seconds 0.030987024307250977\n",
      "Epoch 791: Train_loss 27336316928.0, Validation_loss 23221710848.0, Seconds 0.027007102966308594\n",
      "Epoch 792: Train_loss 27336550400.0, Validation_loss 23223482368.0, Seconds 0.029509305953979492\n",
      "Epoch 793: Train_loss 27335290880.0, Validation_loss 23223867392.0, Seconds 0.03000473976135254\n",
      "Epoch 794: Train_loss 27335776256.0, Validation_loss 23221497856.0, Seconds 0.03199505805969238\n",
      "Epoch 795: Train_loss 27335268352.0, Validation_loss 23222568960.0, Seconds 0.03053903579711914\n",
      "Epoch 796: Train_loss 27334778880.0, Validation_loss 23222558720.0, Seconds 0.03299379348754883\n",
      "Epoch 797: Train_loss 27335133184.0, Validation_loss 23222951936.0, Seconds 0.029005765914916992\n",
      "Epoch 798: Train_loss 27334342656.0, Validation_loss 23223033856.0, Seconds 0.03150224685668945\n",
      "Epoch 799: Train_loss 27334436864.0, Validation_loss 23222890496.0, Seconds 0.029998779296875\n",
      "Epoch 800: Train_loss 27333779456.0, Validation_loss 23221837824.0, Seconds 0.026999473571777344\n",
      "Epoch 801: Train_loss 27333470208.0, Validation_loss 23220942848.0, Seconds 0.027006864547729492\n",
      "Epoch 802: Train_loss 27333441536.0, Validation_loss 23221839872.0, Seconds 0.026533126831054688\n",
      "Epoch 803: Train_loss 27332874240.0, Validation_loss 23221284864.0, Seconds 0.024993419647216797\n",
      "Epoch 804: Train_loss 27332831232.0, Validation_loss 23221127168.0, Seconds 0.031002521514892578\n",
      "Epoch 805: Train_loss 27332149248.0, Validation_loss 23222069248.0, Seconds 0.03252768516540527\n",
      "Epoch 806: Train_loss 27332691968.0, Validation_loss 23221227520.0, Seconds 0.03201484680175781\n",
      "Epoch 807: Train_loss 27331811328.0, Validation_loss 23220983808.0, Seconds 0.032000064849853516\n",
      "Epoch 808: Train_loss 27331813376.0, Validation_loss 23221587968.0, Seconds 0.0319981575012207\n",
      "Epoch 809: Train_loss 27331366912.0, Validation_loss 23221112832.0, Seconds 0.03050827980041504\n",
      "Epoch 810: Train_loss 27331184640.0, Validation_loss 23221729280.0, Seconds 0.03099966049194336\n",
      "Epoch 811: Train_loss 27331002368.0, Validation_loss 23221125120.0, Seconds 0.027001142501831055\n",
      "Epoch 812: Train_loss 27330674688.0, Validation_loss 23220295680.0, Seconds 0.03251218795776367\n",
      "Epoch 813: Train_loss 27330258944.0, Validation_loss 23221901312.0, Seconds 0.032009124755859375\n",
      "Epoch 814: Train_loss 27330127872.0, Validation_loss 23220416512.0, Seconds 0.03098917007446289\n",
      "Epoch 815: Train_loss 27330121728.0, Validation_loss 23220002816.0, Seconds 0.03167462348937988\n",
      "Epoch 816: Train_loss 27329644544.0, Validation_loss 23220885504.0, Seconds 0.03000020980834961\n",
      "Epoch 817: Train_loss 27329011712.0, Validation_loss 23220776960.0, Seconds 0.025994300842285156\n",
      "Epoch 818: Train_loss 27329812480.0, Validation_loss 23219476480.0, Seconds 0.029012680053710938\n",
      "Epoch 819: Train_loss 27328614400.0, Validation_loss 23220449280.0, Seconds 0.030504703521728516\n",
      "Epoch 820: Train_loss 27328946176.0, Validation_loss 23219636224.0, Seconds 0.02899312973022461\n",
      "Epoch 821: Train_loss 27327907840.0, Validation_loss 23220992000.0, Seconds 0.02800154685974121\n",
      "Epoch 822: Train_loss 27328714752.0, Validation_loss 23219900416.0, Seconds 0.02850484848022461\n",
      "Epoch 823: Train_loss 27327668224.0, Validation_loss 23219699712.0, Seconds 0.03207731246948242\n",
      "Epoch 824: Train_loss 27327602688.0, Validation_loss 23220322304.0, Seconds 0.02892279624938965\n",
      "Epoch 825: Train_loss 27327387648.0, Validation_loss 23219152896.0, Seconds 0.03050851821899414\n",
      "Epoch 826: Train_loss 27327727616.0, Validation_loss 23219030016.0, Seconds 0.14068865776062012\n",
      "Epoch 827: Train_loss 27326615552.0, Validation_loss 23219658752.0, Seconds 0.031995534896850586\n",
      "Epoch 828: Train_loss 27327035392.0, Validation_loss 23218542592.0, Seconds 0.02850818634033203\n",
      "Epoch 829: Train_loss 27326351360.0, Validation_loss 23218774016.0, Seconds 0.030000925064086914\n",
      "Epoch 830: Train_loss 27326214144.0, Validation_loss 23219195904.0, Seconds 0.03200030326843262\n",
      "Epoch 831: Train_loss 27326228480.0, Validation_loss 23219263488.0, Seconds 0.032684326171875\n",
      "Epoch 832: Train_loss 27325794304.0, Validation_loss 23217166336.0, Seconds 0.03000354766845703\n",
      "Epoch 833: Train_loss 27325327360.0, Validation_loss 23219441664.0, Seconds 0.031998395919799805\n",
      "Epoch 834: Train_loss 27325308928.0, Validation_loss 23218436096.0, Seconds 0.02900242805480957\n",
      "Epoch 835: Train_loss 27325259776.0, Validation_loss 23217375232.0, Seconds 0.02849888801574707\n",
      "Epoch 836: Train_loss 27324780544.0, Validation_loss 23218405376.0, Seconds 0.025999784469604492\n",
      "Epoch 837: Train_loss 27324749824.0, Validation_loss 23219099648.0, Seconds 0.03300166130065918\n",
      "Epoch 838: Train_loss 27324350464.0, Validation_loss 23219163136.0, Seconds 0.031540870666503906\n",
      "Epoch 839: Train_loss 27324260352.0, Validation_loss 23220152320.0, Seconds 0.026993274688720703\n",
      "Epoch 840: Train_loss 27323695104.0, Validation_loss 23218814976.0, Seconds 0.03000164031982422\n",
      "Epoch 841: Train_loss 27323990016.0, Validation_loss 23217008640.0, Seconds 0.03200173377990723\n",
      "Epoch 842: Train_loss 27323326464.0, Validation_loss 23218180096.0, Seconds 0.03051161766052246\n",
      "Epoch 843: Train_loss 27323381760.0, Validation_loss 23217563648.0, Seconds 0.029996871948242188\n",
      "Epoch 844: Train_loss 27322845184.0, Validation_loss 23218096128.0, Seconds 0.030003070831298828\n",
      "Epoch 845: Train_loss 27322992640.0, Validation_loss 23216371712.0, Seconds 0.03050851821899414\n",
      "Epoch 846: Train_loss 27322255360.0, Validation_loss 23216398336.0, Seconds 0.02900409698486328\n",
      "Epoch 847: Train_loss 27322775552.0, Validation_loss 23217721344.0, Seconds 0.03199291229248047\n",
      "Epoch 848: Train_loss 27321624576.0, Validation_loss 23217176576.0, Seconds 0.028512001037597656\n",
      "Epoch 849: Train_loss 27322288128.0, Validation_loss 23216717824.0, Seconds 0.029000520706176758\n",
      "Epoch 850: Train_loss 27321716736.0, Validation_loss 23217025024.0, Seconds 0.02900385856628418\n",
      "Epoch 851: Train_loss 27321673728.0, Validation_loss 23218927616.0, Seconds 0.029003143310546875\n",
      "Epoch 852: Train_loss 27321225216.0, Validation_loss 23217115136.0, Seconds 0.03151869773864746\n",
      "Epoch 853: Train_loss 27321069568.0, Validation_loss 23216490496.0, Seconds 0.02699756622314453\n",
      "Epoch 854: Train_loss 27320942592.0, Validation_loss 23215648768.0, Seconds 0.029999971389770508\n",
      "Epoch 855: Train_loss 27320459264.0, Validation_loss 23217737728.0, Seconds 0.031508684158325195\n",
      "Epoch 856: Train_loss 27320156160.0, Validation_loss 23215679488.0, Seconds 0.031005859375\n",
      "Epoch 857: Train_loss 27320891392.0, Validation_loss 23216191488.0, Seconds 0.029993295669555664\n",
      "Epoch 858: Train_loss 27319810048.0, Validation_loss 23217414144.0, Seconds 0.03254580497741699\n",
      "Epoch 859: Train_loss 27319359488.0, Validation_loss 23216977920.0, Seconds 0.027998924255371094\n",
      "Epoch 860: Train_loss 27319773184.0, Validation_loss 23216195584.0, Seconds 0.028998374938964844\n",
      "Epoch 861: Train_loss 27319205888.0, Validation_loss 23214968832.0, Seconds 0.027001619338989258\n",
      "Epoch 862: Train_loss 27319207936.0, Validation_loss 23215816704.0, Seconds 0.0315859317779541\n",
      "Epoch 863: Train_loss 27318499328.0, Validation_loss 23216603136.0, Seconds 0.02592301368713379\n",
      "Epoch 864: Train_loss 27318913024.0, Validation_loss 23215876096.0, Seconds 0.02899909019470215\n",
      "Epoch 865: Train_loss 27318331392.0, Validation_loss 23215808512.0, Seconds 0.030598163604736328\n",
      "Epoch 866: Train_loss 27318261760.0, Validation_loss 23217086464.0, Seconds 0.030925512313842773\n",
      "Epoch 867: Train_loss 27317962752.0, Validation_loss 23215900672.0, Seconds 0.02799844741821289\n",
      "Epoch 868: Train_loss 27317719040.0, Validation_loss 23215112192.0, Seconds 0.03034210205078125\n",
      "Epoch 869: Train_loss 27317891072.0, Validation_loss 23213733888.0, Seconds 0.028996944427490234\n",
      "Epoch 870: Train_loss 27317272576.0, Validation_loss 23215005696.0, Seconds 0.03100132942199707\n",
      "Epoch 871: Train_loss 27316985856.0, Validation_loss 23215554560.0, Seconds 0.028004169464111328\n",
      "Epoch 872: Train_loss 27316824064.0, Validation_loss 23215263744.0, Seconds 0.03264808654785156\n",
      "Epoch 873: Train_loss 27316549632.0, Validation_loss 23215122432.0, Seconds 0.029001235961914062\n",
      "Epoch 874: Train_loss 27316277248.0, Validation_loss 23214891008.0, Seconds 0.029999732971191406\n",
      "Epoch 875: Train_loss 27316445184.0, Validation_loss 23213180928.0, Seconds 0.031270503997802734\n",
      "Epoch 876: Train_loss 27315937280.0, Validation_loss 23215818752.0, Seconds 0.02900099754333496\n",
      "Epoch 877: Train_loss 27315927040.0, Validation_loss 23213862912.0, Seconds 0.03000354766845703\n",
      "Epoch 878: Train_loss 27315480576.0, Validation_loss 23214209024.0, Seconds 0.03352546691894531\n",
      "Epoch 879: Train_loss 27315619840.0, Validation_loss 23213862912.0, Seconds 0.0279996395111084\n",
      "Epoch 880: Train_loss 27315177472.0, Validation_loss 23215630336.0, Seconds 0.03000330924987793\n",
      "Epoch 881: Train_loss 27315091456.0, Validation_loss 23214858240.0, Seconds 0.030004262924194336\n",
      "Epoch 882: Train_loss 27314536448.0, Validation_loss 23213944832.0, Seconds 0.03050398826599121\n",
      "Epoch 883: Train_loss 27314810880.0, Validation_loss 23214538752.0, Seconds 0.030000686645507812\n",
      "Epoch 884: Train_loss 27313870848.0, Validation_loss 23214862336.0, Seconds 0.03200030326843262\n",
      "Epoch 885: Train_loss 27314749440.0, Validation_loss 23213445120.0, Seconds 0.031519412994384766\n",
      "Epoch 886: Train_loss 27313864704.0, Validation_loss 23213537280.0, Seconds 0.027999401092529297\n",
      "Epoch 887: Train_loss 27313807360.0, Validation_loss 23214487552.0, Seconds 0.03199338912963867\n",
      "Epoch 888: Train_loss 27313135616.0, Validation_loss 23214393344.0, Seconds 0.027637481689453125\n",
      "Epoch 889: Train_loss 27313545216.0, Validation_loss 23214411776.0, Seconds 0.02700042724609375\n",
      "Epoch 890: Train_loss 27312777216.0, Validation_loss 23213377536.0, Seconds 0.02800607681274414\n",
      "Epoch 891: Train_loss 27312685056.0, Validation_loss 23214184448.0, Seconds 0.034998178482055664\n",
      "Epoch 892: Train_loss 27312564224.0, Validation_loss 23213545472.0, Seconds 0.03151106834411621\n",
      "Epoch 893: Train_loss 27312244736.0, Validation_loss 23215136768.0, Seconds 0.029997587203979492\n",
      "Epoch 894: Train_loss 27312273408.0, Validation_loss 23212648448.0, Seconds 0.03400397300720215\n",
      "Epoch 895: Train_loss 27311689728.0, Validation_loss 23214585856.0, Seconds 0.03250455856323242\n",
      "Epoch 896: Train_loss 27311620096.0, Validation_loss 23213221888.0, Seconds 0.029999494552612305\n",
      "Epoch 897: Train_loss 27311443968.0, Validation_loss 23214415872.0, Seconds 0.03300142288208008\n",
      "Epoch 898: Train_loss 27311173632.0, Validation_loss 23214067712.0, Seconds 0.030514240264892578\n",
      "Epoch 899: Train_loss 27311175680.0, Validation_loss 23214919680.0, Seconds 0.027997255325317383\n",
      "Epoch 900: Train_loss 27310921728.0, Validation_loss 23213907968.0, Seconds 0.02800130844116211\n",
      "Epoch 901: Train_loss 27310428160.0, Validation_loss 23213498368.0, Seconds 0.02700519561767578\n",
      "Epoch 902: Train_loss 27310184448.0, Validation_loss 23214428160.0, Seconds 0.03251457214355469\n",
      "Epoch 903: Train_loss 27310147584.0, Validation_loss 23213633536.0, Seconds 0.03100442886352539\n",
      "Epoch 904: Train_loss 27310219264.0, Validation_loss 23213170688.0, Seconds 0.0269927978515625\n",
      "Epoch 905: Train_loss 27309737984.0, Validation_loss 23213944832.0, Seconds 0.025507688522338867\n",
      "Epoch 906: Train_loss 27309185024.0, Validation_loss 23213332480.0, Seconds 0.03200054168701172\n",
      "Epoch 907: Train_loss 27309256704.0, Validation_loss 23215069184.0, Seconds 0.029005050659179688\n",
      "Epoch 908: Train_loss 27309068288.0, Validation_loss 23213406208.0, Seconds 0.031511545181274414\n",
      "Epoch 909: Train_loss 27308560384.0, Validation_loss 23212824576.0, Seconds 0.03199911117553711\n",
      "Epoch 910: Train_loss 27308548096.0, Validation_loss 23212480512.0, Seconds 0.029997825622558594\n",
      "Epoch 911: Train_loss 27308220416.0, Validation_loss 23213279232.0, Seconds 0.028007030487060547\n",
      "Epoch 912: Train_loss 27308013568.0, Validation_loss 23212881920.0, Seconds 0.027508974075317383\n",
      "Epoch 913: Train_loss 27307763712.0, Validation_loss 23212965888.0, Seconds 0.031999826431274414\n",
      "Epoch 914: Train_loss 27307491328.0, Validation_loss 23214014464.0, Seconds 0.03301644325256348\n",
      "Epoch 915: Train_loss 27307272192.0, Validation_loss 23213479936.0, Seconds 0.03358650207519531\n",
      "Epoch 916: Train_loss 27306907648.0, Validation_loss 23212904448.0, Seconds 0.03299307823181152\n",
      "Epoch 917: Train_loss 27306950656.0, Validation_loss 23212378112.0, Seconds 0.029940128326416016\n",
      "Epoch 918: Train_loss 27306457088.0, Validation_loss 23212451840.0, Seconds 0.0312502384185791\n",
      "Epoch 919: Train_loss 27306391552.0, Validation_loss 23213117440.0, Seconds 0.031990766525268555\n",
      "Epoch 920: Train_loss 27306246144.0, Validation_loss 23212838912.0, Seconds 0.031072139739990234\n",
      "Epoch 921: Train_loss 27305766912.0, Validation_loss 23213414400.0, Seconds 0.026422739028930664\n",
      "Epoch 922: Train_loss 27305467904.0, Validation_loss 23212048384.0, Seconds 0.027996540069580078\n",
      "Epoch 923: Train_loss 27305889792.0, Validation_loss 23212009472.0, Seconds 0.026000022888183594\n",
      "Epoch 924: Train_loss 27305259008.0, Validation_loss 23212810240.0, Seconds 0.03407573699951172\n",
      "Epoch 925: Train_loss 27304914944.0, Validation_loss 23211270144.0, Seconds 0.03144574165344238\n",
      "Epoch 926: Train_loss 27304894464.0, Validation_loss 23212693504.0, Seconds 0.030066728591918945\n",
      "Epoch 927: Train_loss 27304531968.0, Validation_loss 23211646976.0, Seconds 0.029959917068481445\n",
      "Epoch 928: Train_loss 27304523776.0, Validation_loss 23211161600.0, Seconds 0.030497312545776367\n",
      "Epoch 929: Train_loss 27304081408.0, Validation_loss 23210115072.0, Seconds 0.03200054168701172\n",
      "Epoch 930: Train_loss 27303546880.0, Validation_loss 23211673600.0, Seconds 0.029999732971191406\n",
      "Epoch 931: Train_loss 27303888896.0, Validation_loss 23208978432.0, Seconds 0.02750706672668457\n",
      "Epoch 932: Train_loss 27303221248.0, Validation_loss 23208290304.0, Seconds 0.03000164031982422\n",
      "Epoch 933: Train_loss 27303372800.0, Validation_loss 23207536640.0, Seconds 0.031000375747680664\n",
      "Epoch 934: Train_loss 27303004160.0, Validation_loss 23209150464.0, Seconds 0.02907705307006836\n",
      "Epoch 935: Train_loss 27302471680.0, Validation_loss 23209076736.0, Seconds 0.03244185447692871\n",
      "Epoch 936: Train_loss 27302641664.0, Validation_loss 23208943616.0, Seconds 0.029999971389770508\n",
      "Epoch 937: Train_loss 27302498304.0, Validation_loss 23208087552.0, Seconds 0.030022144317626953\n",
      "Epoch 938: Train_loss 27301869568.0, Validation_loss 23207661568.0, Seconds 0.029508590698242188\n",
      "Epoch 939: Train_loss 27301877760.0, Validation_loss 23207530496.0, Seconds 0.031003475189208984\n",
      "Epoch 940: Train_loss 27301550080.0, Validation_loss 23208589312.0, Seconds 0.03299736976623535\n",
      "Epoch 941: Train_loss 27301656576.0, Validation_loss 23207436288.0, Seconds 0.029091596603393555\n",
      "Epoch 942: Train_loss 27301064704.0, Validation_loss 23207895040.0, Seconds 0.0319981575012207\n",
      "Epoch 943: Train_loss 27300958208.0, Validation_loss 23207579648.0, Seconds 0.0260007381439209\n",
      "Epoch 944: Train_loss 27300978688.0, Validation_loss 23206998016.0, Seconds 0.028011322021484375\n",
      "Epoch 945: Train_loss 27300417536.0, Validation_loss 23208015872.0, Seconds 0.031500816345214844\n",
      "Epoch 946: Train_loss 27301013504.0, Validation_loss 23206230016.0, Seconds 0.03400731086730957\n",
      "Epoch 947: Train_loss 27299780608.0, Validation_loss 23208171520.0, Seconds 0.03099513053894043\n",
      "Epoch 948: Train_loss 27300481024.0, Validation_loss 23207753728.0, Seconds 0.02651524543762207\n",
      "Epoch 949: Train_loss 27299792896.0, Validation_loss 23208585216.0, Seconds 0.025992155075073242\n",
      "Epoch 950: Train_loss 27299940352.0, Validation_loss 23208052736.0, Seconds 0.029005765914916992\n",
      "Epoch 951: Train_loss 27299217408.0, Validation_loss 23208427520.0, Seconds 0.03050827980041504\n",
      "Epoch 952: Train_loss 27299696640.0, Validation_loss 23207249920.0, Seconds 0.036009788513183594\n",
      "Epoch 953: Train_loss 27299135488.0, Validation_loss 23207469056.0, Seconds 0.02899026870727539\n",
      "Epoch 954: Train_loss 27299082240.0, Validation_loss 23209213952.0, Seconds 0.030512571334838867\n",
      "Epoch 955: Train_loss 27299110912.0, Validation_loss 23207038976.0, Seconds 0.031001806259155273\n",
      "Epoch 956: Train_loss 27298166784.0, Validation_loss 23207256064.0, Seconds 0.032999277114868164\n",
      "Epoch 957: Train_loss 27299160064.0, Validation_loss 23206289408.0, Seconds 0.02900552749633789\n",
      "Epoch 958: Train_loss 27297720320.0, Validation_loss 23208476672.0, Seconds 0.028509140014648438\n",
      "Epoch 959: Train_loss 27298654208.0, Validation_loss 23206348800.0, Seconds 0.02801036834716797\n",
      "Epoch 960: Train_loss 27297740800.0, Validation_loss 23208554496.0, Seconds 0.02798938751220703\n",
      "Epoch 961: Train_loss 27298084864.0, Validation_loss 23206389760.0, Seconds 0.031604766845703125\n",
      "Epoch 962: Train_loss 27297071104.0, Validation_loss 23207221248.0, Seconds 0.03099799156188965\n",
      "Epoch 963: Train_loss 27298107392.0, Validation_loss 23205312512.0, Seconds 0.029993534088134766\n",
      "Epoch 964: Train_loss 27297021952.0, Validation_loss 23207268352.0, Seconds 0.02850651741027832\n",
      "Epoch 965: Train_loss 27297247232.0, Validation_loss 23206322176.0, Seconds 0.03300786018371582\n",
      "Epoch 966: Train_loss 27296854016.0, Validation_loss 23206455296.0, Seconds 0.028070449829101562\n",
      "Epoch 967: Train_loss 27296950272.0, Validation_loss 23206291456.0, Seconds 0.031929731369018555\n",
      "Epoch 968: Train_loss 27296188416.0, Validation_loss 23206514688.0, Seconds 0.03251028060913086\n",
      "Epoch 969: Train_loss 27296942080.0, Validation_loss 23205488640.0, Seconds 0.03400564193725586\n",
      "Epoch 970: Train_loss 27296028672.0, Validation_loss 23205791744.0, Seconds 0.029998302459716797\n",
      "Epoch 971: Train_loss 27296217088.0, Validation_loss 23204773888.0, Seconds 0.029508352279663086\n",
      "Epoch 972: Train_loss 27296018432.0, Validation_loss 23206547456.0, Seconds 0.031002044677734375\n",
      "Epoch 973: Train_loss 27295862784.0, Validation_loss 23205339136.0, Seconds 0.0319976806640625\n",
      "Epoch 974: Train_loss 27295266816.0, Validation_loss 23204837376.0, Seconds 0.03351187705993652\n",
      "Epoch 975: Train_loss 27295744000.0, Validation_loss 23204751360.0, Seconds 0.031000137329101562\n",
      "Epoch 976: Train_loss 27294910464.0, Validation_loss 23206281216.0, Seconds 0.030000686645507812\n",
      "Epoch 977: Train_loss 27295492096.0, Validation_loss 23204288512.0, Seconds 0.030514001846313477\n",
      "Epoch 978: Train_loss 27294914560.0, Validation_loss 23204755456.0, Seconds 0.030008554458618164\n",
      "Epoch 979: Train_loss 27294840832.0, Validation_loss 23205281792.0, Seconds 0.031995296478271484\n",
      "Epoch 980: Train_loss 27294615552.0, Validation_loss 23205554176.0, Seconds 0.026015043258666992\n",
      "Epoch 981: Train_loss 27294711808.0, Validation_loss 23204304896.0, Seconds 0.02550792694091797\n",
      "Epoch 982: Train_loss 27294027776.0, Validation_loss 23205890048.0, Seconds 0.030000925064086914\n",
      "Epoch 983: Train_loss 27294007296.0, Validation_loss 23203682304.0, Seconds 0.03300046920776367\n",
      "Epoch 984: Train_loss 27294076928.0, Validation_loss 23200651264.0, Seconds 0.030512332916259766\n",
      "Epoch 985: Train_loss 27292899328.0, Validation_loss 23199762432.0, Seconds 0.028001070022583008\n",
      "Epoch 986: Train_loss 27293011968.0, Validation_loss 23197990912.0, Seconds 0.0279998779296875\n",
      "Epoch 987: Train_loss 27290877952.0, Validation_loss 23196190720.0, Seconds 0.0260009765625\n",
      "Epoch 988: Train_loss 27290191872.0, Validation_loss 23188819968.0, Seconds 0.03350663185119629\n",
      "Epoch 989: Train_loss 27287701504.0, Validation_loss 23182305280.0, Seconds 0.031000375747680664\n",
      "Epoch 990: Train_loss 27285878784.0, Validation_loss 23178242048.0, Seconds 0.030025482177734375\n",
      "Epoch 991: Train_loss 27284500480.0, Validation_loss 23175055360.0, Seconds 0.028505563735961914\n",
      "Epoch 992: Train_loss 27282976768.0, Validation_loss 23171926016.0, Seconds 0.03099966049194336\n",
      "Epoch 993: Train_loss 27282305024.0, Validation_loss 23168339968.0, Seconds 0.02900862693786621\n",
      "Epoch 994: Train_loss 27281350656.0, Validation_loss 23167483904.0, Seconds 0.02949666976928711\n",
      "Epoch 995: Train_loss 27280752640.0, Validation_loss 23165757440.0, Seconds 0.031003475189208984\n",
      "Epoch 996: Train_loss 27279939584.0, Validation_loss 23165085696.0, Seconds 0.02799844741821289\n",
      "Epoch 997: Train_loss 27279276032.0, Validation_loss 23165210624.0, Seconds 0.029003381729125977\n",
      "Epoch 998: Train_loss 27278725120.0, Validation_loss 23164612608.0, Seconds 0.032511234283447266\n",
      "Epoch 999: Train_loss 27278383104.0, Validation_loss 23163824128.0, Seconds 0.027996540069580078\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        target = target.view(-1, 1)\n",
    "        output = net(data)\n",
    "        L = loss(output, target)\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    y_train_pred = net(X_train)\n",
    "    training_loss = loss(y_train_pred, y_train.view(-1, 1)).item()\n",
    "    y_test_pred = net(X_test)\n",
    "    test_loss = loss(y_test_pred, y_test.view(-1, 1)).item()\n",
    "    \n",
    "    train_losses.append(training_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Epoch {}: Train_loss {}, Validation_loss {}, Seconds {}\".format(epoch, training_loss, test_loss, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11261887190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHFCAYAAADcytJ5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMrklEQVR4nO3dd3xUVf7/8fedSTKphFBDpC8g0hEUURQUlKIsiAVZpFlRAdFFsbcVg66FdV1x9Yugi4Kylh+uDVCxAQIiAoKIGikCIkI6mSQz9/fHzNxkUiY9N4TX8/GY79y599w7n7nwXd6ec+69hmmapgAAAOogh90FAAAAlIagAgAA6iyCCgAAqLMIKgAAoM4iqAAAgDqLoAIAAOosggoAAKizCCoAAKDOIqgAAIA6i6AC1HOLFi2SYRjauHGj3aXUqsDv/uWXX+wuBUAVEFQAAECdRVABAAB1FkEFgCTpiy++0ODBgxUXF6fo6GideeaZevfdd4PaZGdna9asWWrXrp0iIyPVqFEj9e3bV0uWLLHa/Pzzz7riiiuUlJQkl8ul5s2ba/Dgwdq8eXOp3z1v3jwZhqEff/yx2LbZs2crIiJChw8fliStXLlSo0aNUsuWLRUZGakOHTro+uuvt7aH0rZtW02ePLnY+kGDBmnQoEFB69LT063fGhERoZNOOkkzZ85UVlZWULtly5apX79+io+PV3R0tNq3b6+rrrqqzFoAlE+Y3QUAsN+nn36q888/Xz169NCCBQvkcrn07LPPauTIkVqyZInGjh0rSbr11lv1n//8Rw8//LB69+6trKwsbdu2TX/88Yd1rBEjRsjj8eixxx5T69atdfjwYa1Zs0apqamlfv+VV16p2bNna9GiRXr44Yet9R6PR4sXL9bIkSPVpEkTSdJPP/2k/v3765prrlF8fLx++eUXPfnkkxowYIC2bt2q8PDwKp+P7OxsDRw4UPv27dNdd92lHj166LvvvtN9992nrVu3atWqVTIMQ2vXrtXYsWM1duxYPfDAA4qMjNTu3bv18ccfV7kGAH4mgHpt4cKFpiRzw4YNpbY544wzzGbNmpkZGRnWuvz8fLNbt25my5YtTa/Xa5qmaXbr1s0cPXp0qcc5fPiwKcmcN29ehescM2aM2bJlS9Pj8Vjr3nvvPVOS+c4775S4j9frNfPy8szdu3ebksz/9//+n7Ut8LtTUlKsdW3atDEnTZpU7DgDBw40Bw4caH1OTk42HQ5HsXP23//+15Rkvvfee6Zpmubjjz9uSjJTU1Mr/HsBlE+9Gfr57LPPNHLkSCUlJckwDL399tsV2j8nJ0eTJ09W9+7dFRYWptGjR5fY7tNPP1WfPn0UGRmp9u3b67nnnqt68YCNsrKy9NVXX+nSSy9VbGystd7pdGrChAnat2+fdu7cKUk6/fTT9f777+uOO+7Q6tWrdezYsaBjNWrUSH/605/097//XU8++aS++eYbeb3ectUxZcoU7du3T6tWrbLWLVy4UImJiRo+fLi17tChQ5o6dapatWqlsLAwhYeHq02bNpKkHTt2VPo8FPa///1P3bp1U69evZSfn2+9hg4dKsMwtHr1aknSaaedJkm6/PLL9frrr+vXX3+tlu8HUKDeBJWsrCz17NlTzzzzTKX293g8ioqK0owZMzRkyJAS26SkpGjEiBE6++yz9c033+iuu+7SjBkz9MYbb1SldMBWR48elWmaatGiRbFtSUlJkmQN7Tz99NOaPXu23n77bZ177rlq1KiRRo8erV27dkmSDMPQRx99pKFDh+qxxx7TqaeeqqZNm2rGjBnKyMgIWcfw4cPVokULLVy40Kpr+fLlmjhxopxOpyTJ6/Xqggsu0Jtvvqnbb79dH330kdavX69169ZJUrHgVFm//fabtmzZovDw8KBXXFycTNO05sOcc845evvtt5Wfn6+JEyeqZcuW6tatW9CcHQBVU2/mqAwfPjzov7qKys3N1T333KNXXnlFqamp6tatmx599FFrAl1MTIzmz58vSfryyy9LHE9/7rnn1Lp1a82bN0+SdMopp2jjxo16/PHHdckll1T3TwJqRUJCghwOhw4cOFBs2/79+yXJmh8SExOjBx98UA8++KB+++03q3dl5MiR+v777yVJbdq00YIFCyRJP/zwg15//XU98MADys3NDdkDGejBefrpp5WamqpXX31VbrdbU6ZMsdps27ZN3377rRYtWqRJkyZZ60uahFuSyMhIud3uYusPHz5s/cbA742KitKLL75Y4nEKtx01apRGjRolt9utdevWKTk5WX/5y1/Utm1b9e/fv1x1AShdvelRKcuUKVP05ZdfaunSpdqyZYsuu+wyDRs2zPovwfJYu3atLrjggqB1Q4cO1caNG5WXl1fdJQO1IiYmRv369dObb74Z1CPh9Xq1ePFitWzZUp06dSq2X/PmzTV58mSNGzdOO3fuVHZ2drE2nTp10j333KPu3btr06ZNZdYyZcoU5eTkaMmSJVq0aJH69++vzp07W9sNw5AkuVyuoP3+/e9/l+u3tm3bVlu2bAla98MPP1hDWwEXXXSRfvrpJzVu3Fh9+/Yt9mrbtm2xY7tcLg0cOFCPPvqoJOmbb74pV00AQqs3PSqh/PTTT1qyZIn27dtndWXPmjVLH3zwgRYuXKhHHnmkXMc5ePCgmjdvHrSuefPmys/P1+HDh0vsOgfqio8//rjEu7SOGDFCycnJOv/883Xuuedq1qxZioiI0LPPPqtt27ZpyZIlVkDo16+fLrroIvXo0UMJCQnasWOH/vOf/6h///6Kjo7Wli1bNG3aNF122WXq2LGjIiIi9PHHH2vLli264447yqyxc+fO6t+/v5KTk7V37149//zzxbb/6U9/0h133CHTNNWoUSO98847WrlyZbnOwYQJE3TllVfqxhtv1CWXXKLdu3frscceU9OmTYPazZw5U2+88YbOOecc3XLLLerRo4e8Xq/27NmjFStW6K9//av69eun++67T/v27dPgwYPVsmVLpaam6h//+IfCw8M1cODActUEILQTIqhs2rRJpmkW+69Ct9utxo0bV+hYgf/BDjBNs8T1QF0ze/bsEtenpKRo4MCB+vjjj3X//fdr8uTJ8nq96tmzp5YvX66LLrrIanveeedp+fLleuqpp5Sdna2TTjpJEydO1N133y1JSkxM1J/+9Cc9++yz2rt3rwzDUPv27fXEE09o+vTp5apzypQpuu666xQVFWVdFh0QHh6ud955RzfffLOuv/56hYWFaciQIVq1apVat25d5rH/8pe/aP/+/Xruuee0cOFCdevWTfPnz9eDDz4Y1C4mJkaff/655s6dq+eff14pKSmKiopS69atNWTIEKtHpV+/ftq4caNmz56t33//XQ0bNlTfvn318ccfq2vXruX6vQBCM8zAv7T1iGEYeuutt6wrd1577TWNHz9e3333nTUpLyA2NlaJiYlB6yZPnqzU1NRiVw6dc8456t27t/7xj39Y69566y1dfvnlys7Orpb7NwAAgAInRI9K79695fF4dOjQIZ199tmVPk7//v31zjvvBK1bsWKF+vbtS0gBAKAG1JugkpmZGTTzPyUlRZs3b1ajRo3UqVMnjR8/XhMnTtQTTzyh3r176/Dhw/r444/VvXt3jRgxQpK0fft25ebm6siRI8rIyLBu+d2rVy9J0tSpU/XMM8/o1ltv1bXXXqu1a9dqwYIFXIoIAEANqTdDP6tXr9a5555bbP2kSZO0aNEi5eXl6eGHH9bLL7+sX3/9VY0bN1b//v314IMPqnv37pJ8VwTs3r272DEKn6JPP/1Ut9xyi7777jslJSVp9uzZmjp1as39MAAATmD1JqgAAID654S5jwoAADj+EFQAAECddVxPpvV6vdq/f7/i4uK4jwkAAMcJ0zSVkZGhpKQkORyh+0yO66Cyf/9+tWrVyu4yAABAJezdu1ctW7YM2ea4DipxcXGSfD+0QYMGNlcDAADKIz09Xa1atbL+HQ/luA4qgeGeBg0aEFQAADjOlGfaBpNpAQBAnUVQAQAAdRZBBQAA1FnH9RwVAEDVeL1e5ebm2l0G6pnw8HA5nc5qORZBBQBOULm5uUpJSZHX67W7FNRDDRs2VGJiYpXvc0ZQAYATkGmaOnDggJxOp1q1alXmTbeA8jJNU9nZ2Tp06JAkqUWLFlU6HkEFAE5A+fn5ys7OVlJSkqKjo+0uB/VMVFSUJOnQoUNq1qxZlYaBiNAAcALyeDySpIiICJsrQX0VCMB5eXlVOg5BBQBOYDwnDTWluv5uEVQAAECdRVABAJzQBg0apJkzZ5a7/S+//CLDMLR58+YaqwkFCCoAgOOCYRghX5MnT67Ucd9880397W9/K3f7Vq1a6cCBA+rWrVulvq+8CEQ+XPVTij1/ZMtjmmrXJMbuUgAAkg4cOGAtv/baa7rvvvu0c+dOa13gSpOAvLw8hYeHl3ncRo0aVagOp9OpxMTECu2DyqNHpQQLvkjROX//RE+t/MHuUgAAfomJidYrPj5ehmFYn3NyctSwYUO9/vrrGjRokCIjI7V48WL98ccfGjdunFq2bKno6Gh1795dS5YsCTpu0aGftm3b6pFHHtFVV12luLg4tW7dWs8//7y1vWhPx+rVq2UYhj766CP17dtX0dHROvPMM4NClCQ9/PDDatasmeLi4nTNNdfojjvuUK9evSp9Ptxut2bMmKFmzZopMjJSAwYM0IYNG6ztR48e1fjx49W0aVNFRUWpY8eOWrhwoSTfzf6mTZumFi1aKDIyUm3btlVycnKla6lJBJUS9GvnS9cfbDuo1GxuLQ2g/jNNU9m5+ba8TNOstt8xe/ZszZgxQzt27NDQoUOVk5OjPn366H//+5+2bdum6667ThMmTNBXX30V8jhPPPGE+vbtq2+++UY33nijbrjhBn3//fch97n77rv1xBNPaOPGjQoLC9NVV11lbXvllVc0Z84cPfroo/r666/VunVrzZ8/v0q/9fbbb9cbb7yhl156SZs2bVKHDh00dOhQHTlyRJJ07733avv27Xr//fe1Y8cOzZ8/X02aNJEkPf3001q+fLlef/117dy5U4sXL1bbtm2rVE9NYeinBN1OildSfKT2p+Xo58NZOrU19xkAUL8dy/Ooy30f2vLd2x8aquiI6vnnaObMmRozZkzQulmzZlnL06dP1wcffKBly5apX79+pR5nxIgRuvHGGyX5ws9TTz2l1atXq3PnzqXuM2fOHA0cOFCSdMcdd+jCCy9UTk6OIiMj9c9//lNXX321pkyZIkm67777tGLFCmVmZlbqd2ZlZWn+/PlatGiRhg8fLkl64YUXtHLlSi1YsEC33Xab9uzZo969e6tv376SFBRE9uzZo44dO2rAgAEyDENt2rSpVB21gR6VUiTE+MJJ+rGq3agGAFB7Av8oB3g8Hs2ZM0c9evRQ48aNFRsbqxUrVmjPnj0hj9OjRw9rOTDEFLglfHn2Cdw2PrDPzp07dfrppwe1L/q5In766Sfl5eXprLPOstaFh4fr9NNP144dOyRJN9xwg5YuXapevXrp9ttv15o1a6y2kydP1ubNm3XyySdrxowZWrFiRaVrqWn0qJSiQaRvAlYaQQXACSAq3KntDw217burS0xM8AUQTzzxhJ566inNmzdP3bt3V0xMjGbOnFnmE6OLTsI1DKPMhzcW3idws7PC+xS9AVpVhrwC+5Z0zMC64cOHa/fu3Xr33Xe1atUqDR48WDfddJMef/xxnXrqqUpJSdH777+vVatW6fLLL9eQIUP03//+t9I11RR6VEoRH+X7C5eek29zJQBQ8wzDUHREmC2vmrw77ueff65Ro0bpyiuvVM+ePdW+fXvt2rWrxr6vNCeffLLWr18ftG7jxo2VPl6HDh0UERGhL774wlqXl5enjRs36pRTTrHWNW3aVJMnT9bixYs1b968oEnBDRo00NixY/XCCy/otdde0xtvvGHNb6lL6FEpRYMo36lh6AcAjl8dOnTQG2+8oTVr1ighIUFPPvmkDh48GPSPeW2YPn26rr32WvXt21dnnnmmXnvtNW3ZskXt27cvc9+iVw9JUpcuXXTDDTfotttuU6NGjdS6dWs99thjys7O1tVXXy3JNw+mT58+6tq1q9xut/73v/9Zv/upp55SixYt1KtXLzkcDi1btkyJiYlq2LBhtf7u6kBQKUVg6IegAgDHr3vvvVcpKSkaOnSooqOjdd1112n06NFKS0ur1TrGjx+vn3/+WbNmzVJOTo4uv/xyTZ48uVgvS0muuOKKYutSUlI0d+5ceb1eTZgwQRkZGerbt68+/PBDJSQkSPI9cPLOO+/UL7/8oqioKJ199tlaunSpJCk2NlaPPvqodu3aJafTqdNOO03vvfeeHI66N9BimNV5XVgtS09PV3x8vNLS0tSgQYNqPfbTH+3Skyt/0LjTWyl5TI+ydwCA40hOTo5SUlLUrl07RUZG2l3OCen8889XYmKi/vOf/9hdSo0I9XesIv9+06NSiugI3+SuLLfH5koAAMe77OxsPffccxo6dKicTqeWLFmiVatWaeXKlXaXVucRVEoR7vR1f3m8x22HEwCgjjAMQ++9954efvhhud1unXzyyXrjjTc0ZMgQu0ur8wgqpXA6fLPQ88u4HA0AgLJERUVp1apVdpdxXLJ11kx+fr7uuecetWvXTlFRUWrfvr0eeuihMq9Vrw3hTl9QoUcFAAD72Nqj8uijj+q5557TSy+9pK5du2rjxo2aMmWK4uPjdfPNN9tZmpz+mc95HoIKAAB2sTWorF27VqNGjdKFF14oyfccgiVLllTpJjjVJcxBjwoAAHazdehnwIAB+uijj/TDDz9Ikr799lt98cUXGjFiRInt3W630tPTg141hTkqAADYz9YeldmzZystLU2dO3eW0+m0Hh41bty4EtsnJyfrwQcfrJXamKMCAID9bO1Ree2117R48WK9+uqr2rRpk1566SU9/vjjeumll0psf+eddyotLc167d27t8ZqY44KAAD2szWo3Hbbbbrjjjt0xRVXqHv37powYYJuueUWJScnl9je5XKpQYMGQa+awhwVAKifBg0apJkzZ1qf27Ztq3nz5oXcxzAMvf3221X+7uo6zonE1qCSnZ1d7LkCTqezTlyeHOYMzFEhqABAXTBy5MhSb5C2du1aGYahTZs2Vfi4GzZs0HXXXVfV8oI88MAD6tWrV7H1Bw4c0PDhw6v1u4patGhRnXy4YGXZOkdl5MiRmjNnjlq3bq2uXbvqm2++0ZNPPqmrrrrKzrIkFUym9dSB0AQAkK6++mqNGTNGu3fvVps2bYK2vfjii+rVq5dOPfXUCh+3adOm1VVimRITE2vtu+oLW3tU/vnPf+rSSy/VjTfeqFNOOUWzZs3S9ddfr7/97W92liVJCvP39OQzRwUA6oSLLrpIzZo106JFi4LWZ2dn67XXXtPVV1+tP/74Q+PGjVPLli0VHR2t7t27a8mSJSGPW3ToZ9euXTrnnHMUGRmpLl26lPg8ntmzZ6tTp06Kjo5W+/btde+99yovL0+Sr0fjwQcf1LfffivDMGQYhlVz0aGfrVu36rzzzlNUVJQaN26s6667TpmZmdb2yZMna/To0Xr88cfVokULNW7cWDfddJP1XZWxZ88ejRo1SrGxsWrQoIEuv/xy/fbbb9b2b7/9Vueee67i4uLUoEED9enTx7ptyO7duzVy5EglJCQoJiZGXbt21XvvvVfpWsrD1h6VuLg4zZs3r8yxQTsUXJ5MUAFwAjBNKS/bnu8Oj5YMo8xmYWFhmjhxohYtWqT77rtPhn+fZcuWKTc3V+PHj1d2drb69Omj2bNnq0GDBnr33Xc1YcIEtW/fXv369SvzO7xer8aMGaMmTZpo3bp1Sk9PD5rPEhAXF6dFixYpKSlJW7du1bXXXqu4uDjdfvvtGjt2rLZt26YPPvjAum1+fHx8sWNkZ2dr2LBhOuOMM7RhwwYdOnRI11xzjaZNmxYUxj755BO1aNFCn3zyiX788UeNHTtWvXr10rXXXlvm7ynKNE2NHj1aMTEx+vTTT5Wfn68bb7xRY8eO1erVqyVJ48ePV+/evTV//nw5nU5t3rxZ4eHhkqSbbrpJubm5+uyzzxQTE6Pt27crNja2wnVUBM/6KQWXJwM4oeRlS48k2fPdd+2XImLK1fSqq67S3//+d61evVrnnnuuJN+wz5gxY5SQkKCEhATNmjXLaj99+nR98MEHWrZsWbmCyqpVq7Rjxw798ssvatmypSTpkUceKTav5J577rGW27Ztq7/+9a967bXXdPvttysqKkqxsbEKCwsLOdTzyiuv6NixY3r55ZcVE+P7/c8884xGjhypRx99VM2bN5ckJSQk6JlnnpHT6VTnzp114YUX6qOPPqpUUFm1apW2bNmilJQUtWrVSpL0n//8R127dtWGDRt02mmnac+ePbrtttvUuXNnSVLHjh2t/ffs2aNLLrlE3bt3lyS1b9++wjVUlK1DP3VZhPsPtdAf3PANAOqQzp0768wzz9SLL74oSfrpp5/0+eefW3MbA/fj6tGjhxo3bqzY2FitWLFCe/bsKdfxd+zYodatW1shRZL69+9frN1///tfDRgwQImJiYqNjdW9995b7u8o/F09e/a0QooknXXWWfJ6vdq5c6e1rmvXrnI6ndbnFi1a6NChQxX6rsLf2apVKyukSFKXLl3UsGFD7dixQ5J066236pprrtGQIUM0d+5c/fTTT1bbGTNm6OGHH9ZZZ52l+++/X1u2bKlUHRVBj0pJNvyfTn7/Dt0a1l9zPTPsrgYAal54tK9nw67vroCrr75a06ZN07/+9S8tXLhQbdq00eDBgyVJTzzxhJ566inNmzdP3bt3V0xMjGbOnKnc3NxyHds0i/eiG0WGpdatW6crrrhCDz74oIYOHar4+HgtXbpUTzzxRIV+h2maxY5d0ncGhl0Kb6vs1bGlfWfh9Q888ID+8pe/6N1339X777+v+++/X0uXLtXFF1+sa665RkOHDtW7776rFStWKDk5WU888YSmT59eqXrKgx6VkiT2kOHN00jnWkV5MstuDwDHO8PwDb/Y8SrH/JTCLr/8cjmdTr366qt66aWXNGXKFOsf2c8//1yjRo3SlVdeqZ49e6p9+/batWtXuY/dpUsX7dmzR/v3F4S2tWvXBrX58ssv1aZNG919993q27evOnbsqN27dwe1iYiIkMfjKfO7Nm/erKysrKBjOxwOderUqdw1V0Tg9xW+Yer27duVlpamU045xVrXqVMn3XLLLVqxYoXGjBmjhQsXWttatWqlqVOn6s0339Rf//pXvfDCCzVSawBBpSQtT1N+TAtFGnlqbe6zuxoAQCGxsbEaO3as7rrrLu3fv1+TJ0+2tnXo0EErV67UmjVrtGPHDl1//fU6ePBguY89ZMgQnXzyyZo4caK+/fZbff7557r77ruD2nTo0EF79uzR0qVL9dNPP+npp5/WW2+9FdSmbdu2SklJ0ebNm3X48GG53e5i3zV+/HhFRkZq0qRJ2rZtmz755BNNnz5dEyZMsOanVJbH49HmzZuDXtu3b9eQIUPUo0cPjR8/Xps2bdL69es1ceJEDRw4UH379tWxY8c0bdo0rV69Wrt379aXX36pDRs2WCFm5syZ+vDDD5WSkqJNmzbp448/Dgo4NYGgUhLDkDe6sSQp2kuPCgDUNVdffbWOHj2qIUOGqHXr1tb6e++9V6eeeqqGDh2qQYMGKTExUaNHjy73cR0Oh9566y253W6dfvrpuuaaazRnzpygNqNGjdItt9yiadOmqVevXlqzZo3uvffeoDaXXHKJhg0bpnPPPVdNmzYt8RLp6Ohoffjhhzpy5IhOO+00XXrppRo8eLCeeeaZip2MEmRmZqp3795BrxEjRliXRyckJOicc87RkCFD1L59e7322muSfDdd/eOPPzRx4kR16tRJl19+uYYPH249Z8/j8eimm27SKaecomHDhunkk0/Ws88+W+V6QzHMkgbkjhPp6emKj49XWlpatd9O371ghFx7v9TM/Gma9/CcsncAgONITk6OUlJS1K5dO0VGRtpdDuqhUH/HKvLvNz0qpYlsKEmKNbNKnFwFAABqHkGlNJG+m/M0UJa4lQoAAPYgqJTCiGooSYo3spTn4V4qAADYgaBSCiMqQZIUryzuTgsAgE0IKqVwuHx3CowycnneD4B6izl4qCnV9XeLoFIKw+m7E6BTHnpUANQ7gVuyl/eOrUBFZWf7HnJZ9M66FcUt9EvhcPpOTbg8ymeOCoB6JiwsTNHR0fr9998VHh4uh4P/bkX1ME1T2dnZOnTokBo2bBj0nKLKIKiUxuE7NU55RH8KgPrGMAy1aNFCKSkpxW7/DlSHhg0bhnx6dHkRVErj8HVVhckrhnAB1EcRERHq2LEjwz+oduHh4VXuSQkgqJTG36MSpnx5SSoA6imHw8GdaVGnMShZGocvCYYZXoZ+AACwCUGlNIWu+vFy1Q8AALYgqJTGUXDVDyM/AADYg6BSmqCrfkgqAADYgaBSGmsyrZeHEgIAYBOCSmmsoOLhFtMAANiEoFKawpNpySkAANiCoFKaQpNpxRwVAABsQVApjf8+Kk6DHhUAAOxCUClNoVvoc2daAADsQVApTaFb6JNTAACwB0GlNEGXJ5NUAACwA0GlNM5CN3wjpwAAYAuCSmmC7qNicy0AAJygCCqlsSbTcgt9AADsQlApTeBZP4Ypr9drczEAAJyYCCql8d9HRZLkybOvDgAATmAEldL4b6EvSV6vx8ZCAAA4cRFUSuMf+pFEjwoAADYhqJSmcFDx5ttXBwAAJzCCSmkcTnll+JbpUQEAwBYElRBMf1AxuZEKAAC2IKiEUBBUmEwLAIAdCCohWEM/XnpUAACwA0ElBNN/ehj6AQDAHgSVEAJDP9xHBQAAexBUQggEFfGsHwAAbEFQCYEeFQAA7GVrUGnbtq0Mwyj2uummm+wsy2IavqBiMEcFAABbhJXdpOZs2LBBHk9Bb8W2bdt0/vnn67LLLrOxqgJWj4rJ05MBALCDrUGladOmQZ/nzp2rP/3pTxo4cKBNFQWz5qh4CSoAANihzsxRyc3N1eLFi3XVVVfJMIyyd6gFXJ4MAIC9bO1RKeztt99WamqqJk+eXGobt9stt9ttfU5PT6/Rmqw709KjAgCALepMj8qCBQs0fPhwJSUlldomOTlZ8fHx1qtVq1Y1WpNp9exw1Q8AAHaoE0Fl9+7dWrVqla655pqQ7e68806lpaVZr71799ZoXQXP+qnRrwEAAKWoE0M/CxcuVLNmzXThhReGbOdyueRyuWqpqoI5KkymBQDAHrb3qHi9Xi1cuFCTJk1SWFidyE0Wnp4MAIC9bA8qq1at0p49e3TVVVfZXUoxgTkqDP0AAGAP27swLrjggjp8+a9/Mi09KgAA2ML2HpW6rGDohzkqAADYgaASgtfw3/DNW1d7fAAAqN8IKiEFhn7oUQEAwA4ElRAY+gEAwF4ElRCs+6jU2cm+AADUbwSVUAyu+gEAwE4ElRC83EIfAABbEVRC4s60AADYiaASgmkwRwUAADsRVEIIXPXDQwkBALAHQSWUwGRaEVQAALADQSUE6z4q3JkWAABbEFRCKJijQo8KAAB2IKiEFLjqhx4VAADsQFAJweRZPwAA2IqgEopBUAEAwE4ElRACz/ph6AcAAHsQVEKwJtNyeTIAALYgqJSDyQ3fAACwBUElBNM6PQz9AABgB4JKKIGhH3pUAACwBUElBJOrfgAAsBVBJaRAULG3CgAATlQElVCMwJ1pPTYXAgDAiYmgEgKTaQEAsBdBJQTmqAAAYC+CSki+oGJwZ1oAAGxBUAkhcGdakx4VAABsQVAJxWCOCgAAdiKohMQcFQAA7ERQCcWaTEuPCgAAdiCohGDSowIAgK0IKqEE5qgQVAAAsAVBJaRAUGHoBwAAOxBUQjCNwAI9KgAA2IGgEgqXJwMAYCuCSijMUQEAwFYElZC46gcAADsRVEIwDSbTAgBgJ4JKSNzwDQAAOxFUQvHfmdYQQz8AANiBoBKK9fRkelQAALADQSWUQI8Kk2kBALAFQSUE0396TO6jAgCALQgqofiHfuhRAQDAHgSVEAxr6IceFQAA7GB7UPn111915ZVXqnHjxoqOjlavXr309ddf212WpIL7qDCZFgAAe4TZ+eVHjx7VWWedpXPPPVfvv/++mjVrpp9++kkNGza0s6xCuDwZAAA72RpUHn30UbVq1UoLFy601rVt29a+gooyuOEbAAB2snXoZ/ny5erbt68uu+wyNWvWTL1799YLL7xQanu326309PSgV42ynp5MjwoAAHawNaj8/PPPmj9/vjp27KgPP/xQU6dO1YwZM/Tyyy+X2D45OVnx8fHWq1WrVjVbIJNpAQCwla1Bxev16tRTT9Ujjzyi3r176/rrr9e1116r+fPnl9j+zjvvVFpamvXau3dvzRbIZFoAAGxla1Bp0aKFunTpErTulFNO0Z49e0ps73K51KBBg6BXjeI+KgAA2MrWoHLWWWdp586dQet++OEHtWnTxqaKivJPpmWOCgAAtrA1qNxyyy1at26dHnnkEf3444969dVX9fzzz+umm26ysyyLEehR4Rb6AADYwtagctppp+mtt97SkiVL1K1bN/3tb3/TvHnzNH78eDvLsgRu+MblyQAA2MPW+6hI0kUXXaSLLrrI7jJKZPD0ZAAAbGX7LfTrMqtHhaEfAABsQVAJwbDuTEuPCgAAdiCohGJNpgUAAHYgqIRCjwoAALYiqIRQcHkyQQUAADsQVEIwxdOTAQCwE0ElBMNw+t656gcAAFsQVELxd6hwHxUAAOxBUAnF36PC0A8AAPYgqIQQuOiHoR8AAOxBUAkl0KPCVT8AANiCoBKK9awfelQAALADQSUUnvUDAICtCCohWE9PJqgAAGALgkooDv+dabk8GQAAWxBUQuEW+gAA2IqgEkLgWT+M/AAAYA+CSgiGAnNU6FEBAMAOBJVQrDkqdKkAAGAHgkooXJ4MAICtCCohFFyezNAPAAB2qFRQ2bt3r/bt22d9Xr9+vWbOnKnnn3++2gqrE6yrfgAAgB0qFVT+8pe/6JNPPpEkHTx4UOeff77Wr1+vu+66Sw899FC1FminwFU/3EcFAAB7VCqobNu2Taeffrok6fXXX1e3bt20Zs0avfrqq1q0aFF11mcrw8HQDwAAdqpUUMnLy5PL5ZIkrVq1Sn/+858lSZ07d9aBAweqrzrbBe6jwmRaAADsUKmg0rVrVz333HP6/PPPtXLlSg0bNkyStH//fjVu3LhaC7SVNUeFoAIAgB0qFVQeffRR/fvf/9agQYM0btw49ezZU5K0fPlya0ioPmDoBwAAe4VVZqdBgwbp8OHDSk9PV0JCgrX+uuuuU3R0dLUVZzfDcPreba4DAIATVaV6VI4dOya3222FlN27d2vevHnauXOnmjVrVq0F2ipwHxWu+gEAwBaVCiqjRo3Syy+/LElKTU1Vv3799MQTT2j06NGaP39+tRZoJ4P7qAAAYKtKBZVNmzbp7LPPliT997//VfPmzbV79269/PLLevrpp6u1QFtZQYUeFQAA7FCpoJKdna24uDhJ0ooVKzRmzBg5HA6dccYZ2r17d7UWaKeCybRc9QMAgB0qFVQ6dOigt99+W3v37tWHH36oCy64QJJ06NAhNWjQoFoLtJPBQwkBALBVpYLKfffdp1mzZqlt27Y6/fTT1b9/f0m+3pXevXtXa4F2CjyU0MFkWgAAbFGpy5MvvfRSDRgwQAcOHLDuoSJJgwcP1sUXX1xtxdnNcAQuT6ZHBQAAO1QqqEhSYmKiEhMTtW/fPhmGoZNOOqle3ezNhzkqAADYqVJDP16vVw899JDi4+PVpk0btW7dWg0bNtTf/vY3eb31Z5jEcHALfQAA7FSpHpW7775bCxYs0Ny5c3XWWWfJNE19+eWXeuCBB5STk6M5c+ZUd532YDItAAC2qlRQeemll/R///d/1lOTJalnz5466aSTdOONN9aboBLoUXHw9GQAAGxRqaGfI0eOqHPnzsXWd+7cWUeOHKlyUXWFw+ChhAAA2KlSQaVnz5565plniq1/5pln1KNHjyoXVWcYXPUDAICdKjX089hjj+nCCy/UqlWr1L9/fxmGoTVr1mjv3r167733qrtG2xgGV/0AAGCnSvWoDBw4UD/88IMuvvhipaam6siRIxozZoy+++47LVy4sLprtI//FvoOggoAALao9H1UkpKSik2a/fbbb/XSSy/pxRdfrHJhdYHDP/TDVT8AANijUj0qJwyDHhUAAOxka1B54IEHZBhG0CsxMdHOkoI4uOEbAAC2qvTQT3Xp2rWrVq1aZX12Op0hWtcyK6hweTIAAHaoUFAZM2ZMyO2pqakVLyAsrE71ohTm9N+Z1iFTXq8ph39yLQAAqB0VCirx8fFlbp84cWKFCti1a5eSkpLkcrnUr18/PfLII2rfvn2FjlFTYiIjrOX0nDw1jI4I0RoAAFS3CgWV6r70uF+/fnr55ZfVqVMn/fbbb3r44Yd15pln6rvvvlPjxo2LtXe73XK73dbn9PT0aq2nqDD/MJRDXh3JyiWoAABQy2ydTDt8+HBdcskl6t69u4YMGaJ3331Xku9ZQiVJTk5WfHy89WrVqlXNFljoqp+j2bk1+10AAKCYOnV5ckxMjLp3765du3aVuP3OO+9UWlqa9dq7d2/NFmQUXPVzJCuvZr8LAAAUY/tVP4W53W7t2LFDZ599donbXS6XXC5XLVZUqEclix4VAABqm609KrNmzdKnn36qlJQUffXVV7r00kuVnp6uSZMm2VlWgUI9Kgz9AABQ+2ztUdm3b5/GjRunw4cPq2nTpjrjjDO0bt06tWnTxs6yChQKKlnufJuLAQDgxGNrUFm6dKmdX1+2QpNpMwgqAADUujo1mbbOoUcFAABbEVRCKXRn2iy3x+ZiAAA48RBUysFg6AcAAFsQVEJh6AcAAFsRVEIpNJmWoAIAQO0jqIRizVHxKiOHoAIAQG0jqIRiDf1IqdzwDQCAWkdQCcnw/1+vsnI9ymT4BwCAWkVQCaVQj4okHUrPsa8WAABOQASVUAJzVAxTkvRbutvOagAAOOEQVEJxOCVJTnnllEeHMuhRAQCgNhFUQolqJDldkqQk47AO0aMCAECtIqiE4nBICW0lSW2MQ/qNOSoAANQqgkpZGrWTJLU2Dum3DHpUAACoTQSVssQ0kSQ1VCY9KgAA1DKCSlnCYyRJUYZbh+lRAQCgVhFUyhIRLUmKUY5+zySoAABQmwgqZQn0qMitjJx85eR5bC4IAIATB0GlLP4elViHrzflML0qAADUGoJKWcJ9QaVhWJ4k6XfmqQAAUGsIKmWJ8A39NHD6np58OJOnKAMAUFsIKmUJDwz9+AIKPSoAANQegkpZ/HNUog3mqAAAUNsIKmUJXPVj+gIKPSoAANQegkpZXLGSpEhvtiR6VAAAqE0ElbLENJMkufJSFaZ8elQAAKhFBJWyRDeSDKcMmWqkDHpUAACoRQSVsjicUkxTSVJTI5UeFQAAahFBpTxifcM/TY1UZeV6dCyX2+gDAFAbCCrlEdtckpQUli6JK38AAKgtBJXy8AeV1uEZkqQj2dydFgCA2kBQKQ//0E+LMF9QOUpQAQCgVhBUysPfo9LckSZJSiWoAABQKwgq5eHvUWmsVElSanaejcUAAHDiIKiUh79HpaH3qCTpKEEFAIBaQVApD39QaZB/RBJDPwAA1BaCSnn4h35cnixFyk2PCgAAtYSgUh6uOCksSpLUxEijRwUAgFpCUCkPw7B6VZoplcuTAQCoJQSV8oppIklqbKTraBZDPwAA1AaCSnlF+4JKIyODoR8AAGoJQaW8Aj0qSldWrkfufB5MCABATSOolFd0Y0lSguG7jX76sXw7qwEA4IRAUCkvf1Bp7syUJGXkME8FAICaRlApL//QT1OHv0clhx4VAABqGkGlvPyTaRv7gwo9KgAA1Lw6E1SSk5NlGIZmzpxpdykl8/eoNDTTJUkZ9KgAAFDj6kRQ2bBhg55//nn16NHD7lJKF91IkhTvDyrpx+hRAQCgptkeVDIzMzV+/Hi98MILSkhIsLuc0vmHflxmjiLlpkcFAIBaYHtQuemmm3ThhRdqyJAhZbZ1u91KT08PetUaV5zkjJDku5cKc1QAAKh5YXZ++dKlS7Vp0yZt2LChXO2Tk5P14IMP1nBVpTAMKaqRlHlQDY0srvoBAKAW2NajsnfvXt18881avHixIiMjy7XPnXfeqbS0NOu1d+/eGq6yiKiGkqR4I1Pp9KgAAFDjbOtR+frrr3Xo0CH16dPHWufxePTZZ5/pmWeekdvtltPpDNrH5XLJ5XLVdqkFIhtKkuKVxRwVAABqgW1BZfDgwdq6dWvQuilTpqhz586aPXt2sZBSJ1g9KllK4aofAABqnG1BJS4uTt26dQtaFxMTo8aNGxdbX2fQowIAQK2y/aqf40qhHpUMNz0qAADUNFuv+ilq9erVdpcQWpTvPi/xyuLpyQAA1AJ6VCoiMPRjZCkjJ0+madpbDwAA9RxBpSICQz/KlNeUjuV57K0HAIB6jqBSEf4elYZGliQeTAgAQE0jqFSEv0eloSNbEkEFAICaRlCpiEKXJ0vieT8AANQwgkpF+HtUYpUlQ15luulRAQCgJhFUKsLfo+KQqTgdY+gHAIAaRlCpiPBIyRkhSYrVMWUSVAAAqFEElYqKiJUkxRg5PEEZAIAaRlCpKFecJClO2cxRAQCghhFUKsrVQJIUazBHBQCAmkZQqSiXf+hHOVyeDABADSOoVJR/6CfWOMbQDwAANYygUlHWHBWGfgAAqGkElYryB5UYggoAADWOoFJR/suTfZNpmaMCAEBNIqhUlP+qnzgxRwUAgJpGUKmowNCPkcPQDwAANYygUlH+y5NjdUzZuR55vKbNBQEAUH8RVCqq0OXJknjeDwAANYigUlH+oNLAH1Qy3EyoBQCgphBUKirCfx8VI0eSmKcCAEANIqhUVGDoR/4eFYIKAAA1hqBSUdazfrIliXupAABQgwgqFeW/4Vu48hWmfKVmE1QAAKgpBJWK8gcVyfcE5aPZuTYWAwBA/UZQqaiwCMkZIckXVP7IIqgAAFBTCCqV4e9ViTFydCSToAIAQE0hqFSGNaE2R0cY+gEAoMYQVCrD6lE5psOZbpuLAQCg/iKoVEZEQY/K/tRjNhcDAED9RVCpjIgYSb6gcijDrdx8r80FAQBQPxFUKsM/RyXe6ZZpSgfS6FUBAKAmEFQqwz/00yLKI0n6leEfAABqBEGlMvxBpXmk7660vx4lqAAAUBMIKpXhH/ppEu4PKvSoAABQIwgqleGfTJsQ5ruHCj0qAADUDIJKZUTESZLi/UEl5XCWndUAAFBvEVQqw9+jEu/w3ext16FMmaZpZ0UAANRLBJXKcBU868dhSGnH8vR7BneoBQCguhFUKsM/9OPIzVSbxr7elV2HMu2sCACAeomgUhn+oR/lZqlDM1/vyq7fMmwsCACA+omgUhn+oR/lZqpTc9/yjgMEFQAAqhtBpTICPSruTPVqlSBJ+nrPURsLAgCgfiKoVIZ/jorystSndbwk6cdDmUrNzrWxKAAA6h9bg8r8+fPVo0cPNWjQQA0aNFD//v31/vvv21lS+QR6VCQ1Cs9T+ya+z9/sSbWpIAAA6idbg0rLli01d+5cbdy4URs3btR5552nUaNG6bvvvrOzrLKFR0mG/9TlZqlvW9/wzxc/HraxKAAA6h9bg8rIkSM1YsQIderUSZ06ddKcOXMUGxurdevW2VlW2QyjYPjHnanzOjeXJH2w7SA3fgMAoBrVmTkqHo9HS5cuVVZWlvr3719iG7fbrfT09KCXbaxLlDM1sFNTRYU79WvqMW371caaAACoZ2wPKlu3blVsbKxcLpemTp2qt956S126dCmxbXJysuLj461Xq1atarnaQgpdohwV4dR5nZtJkpZs2GNfTQAA1DO2B5WTTz5Zmzdv1rp163TDDTdo0qRJ2r59e4lt77zzTqWlpVmvvXv31nK1hRS6RFmSJvRvI0l6c9M+Hcni6h8AAKqD7UElIiJCHTp0UN++fZWcnKyePXvqH//4R4ltXS6XdYVQ4GUbl/+73b6hnn7tGqnbSQ2Uk+fV3z/83r66AACoR2wPKkWZpim3+zh4wF9UQ9/7sVRJkmEYuu+irpKkJev3atlGG3t7AACoJ2wNKnfddZc+//xz/fLLL9q6davuvvturV69WuPHj7ezrPKJbOh7z0m1Vp3erpGuPbudJOm2/27RnW9u1eHM4yB0AQBQR4XZ+eW//fabJkyYoAMHDig+Pl49evTQBx98oPPPP9/OssqnSI9KwJ3DT5HDMPTvz37WkvV79MamfRrcuZkGn9JcZ3dsouYNImu9VAAAjle2BpUFCxbY+fVVU0KPiiQ5HIbuHHGKBnZqqkc/3Klv96bq/W0H9f62g5KkJrEudUlqoLaNo5UYH6nEBpFKjI9Uk1iXGkaHq2FUhCLC6tyIHAAAtrA1qBzXSulRCTizQxP9vw5NtHVfmlZuP6iPvj+kHQfSdTjTrc9++F2fhTh0rCtM8VHhinWFKTLCqahwh6LCnYoMd/reI/zv4Q5FhvnWu/zLrnCHXGH+beFOucJ878HLvjZOh1HdZwUAgGpFUKmsKN9t83Us9FOTu7eMV/eW8br1gpN1LNej7w+ma8eBDP2amq0DaTk6mJajg+k5OpKVq7RjeTJNKdOdr0x3fo3/hHCnYYUaV1hB2Al8jnE5FR0RVvAe4VRUkc/RLv974fUuX5AyDIIQAKBqCCqVFeO7wZsyfyv3LlERTvVunaDerRNK3O7xmko/lqej2blKPZanbLdHOXkeHfO/3IHlXK+O5fm2ufM9ysnz+pd978HLXrnzvXLneZST71Gep+AW/3keU3mefNXEfF/DkKLDSw4ysZFhinOFKdblW451hSkuMkyxrnD/Z2ehZd+L3h8AODERVCorLtH3XoGgUhanw1BCTIQSYiKq7ZhFebymFW6KvhcNOzl5HmW5PcrOzVdWrkfZbv97bn7B+hK2S5JpSlm5HmXlevR7NdQdHeG0gk1coYAT4yr8ObzUEBTjX+cKc9DTAwDHEYJKZcX6HkSo3EzJnSG54uytp5ycDkPREWGKrqEs5PWaysn3lBpkMt35yvK/Z7jzlZlT6HNOvjXslZnj256b75UkZed6lJ3r0aGMqnX/hDkMRUc4FeMKs8JP8LBVkSEt/3tgjlBgjo81Xyg8eD4QIQgAqhdBpbJcsb6707rTpYzfjpugUtMcVhAKk+Sq8vHc/tDjCy55vmV3XkGoySkScgqHnSKfJSnfayo9J1/pOdU/B8gwZE1YDnc6FOF0KNxpKNzp8L3CHIoo/NnpUESYUWi5+D4RYUU+Ox0KDyvyObBPWJHP/v3DHIbCHA45HL6g6jAMhTkMOR0GwQpAnUdQqYrY5v6gckBq0sHuauolV5hTrjCnGlVxOMzrNZWVm6/sXI8y3fnKdnv8n/OV6S4Ytspy5/vW+7dnuX37HMv1zfHJyfPqWG7B3KBjeR55vL55P6Yp/xCatzp+eq0wDMlp+EKL02H4lp2+d0fgs6PIK7DNITkdDjmNQgHI6Xsv3M5hSA7Dt17Wsu/dKOGzYQTvE2hjyBeEi+/jWzbkX1dKG0MqtL3wd6jQdkMOR/BxA98dtI8j8Dn4u602jsKfC45tGMHf4Zt6VcLvdYT4bsOQUWh/Q6WfR6A+IKhURVyi9McuKeOg3ZWgDA6HobjIcMVFhqt5NR87z1MwcTkwwTk331Sex6s8j1e5Hq9v4nJ+kc+B7flFPnu8yitz/4J9cvODPxc9Zr7XLLV205TyTTNkGxyf/LmwWOArLRSWGN5KDZYlhcqixys5dAZCYaC+wp/lD10F2wP7+JZVwj6FP8ufzQL7BVZZ+weWrQxX8H0qqZ2CA59R5PhB+wVq8H9p8eOUXFvgQ6g21nKRWop+R0nrC9oXnLPgP6/gP7PAf3QU/rNOahhZ6kUgtYGgUhXWhFqCyoksMAwTV0dvOmyapjxeXxjx+petV6HPXq/8n73yeFViG4//GPleU96SjmGayvf41nm9prym5DVNmWbh5eD3wm1864rv4zV9v8OUSj+u/7d6vcH7BLYF7VOojVT8e7yF2ljHLaFNoF5rn0K/raTfXLB/yft4Cx236D4V/3OX/3eb8i0BlfPnnkkEleNWIKjQo4I6zDB8QzJhTrsrQVWYQSGp5ACkYoGocMAqOQBZx1WhcFYsJPmP4y2hBpUcAIOOaxYE5kCACgRP+dsUrA/+LCssFuxT+BgqtI+CtvnPm/9Yhc9jwbaS9w00KG174WMrsE85jh1oU3h70RoLr1fh7y2lbdHfX7SeoscMFeo9pYT1Ds1iZSeCSlXEtfC9p++3tw4A9Z5hGHIWHt8AThA8VKYqEtr63o/8bGsZAADUVwSVqmjsv9Lnjx8V1LcIAACqBUGlKhLaSYbTd9O3arxDLQAA8CGoVEVYhJTQxrd8eJe9tQAAUA8RVKrKGv4hqAAAUN0IKlXVuKPv/fcf7K0DAIB6iKBSVS16+t5//dreOgAAqIcIKlXVsq/v/cBmKb9qT/YFAADBCCpV1ai9FN1Y8uRKB7faXQ0AAPUKQaWqDENqebpvefcae2sBAKCeIahUhz+d53vfsdzeOgAAqGcIKtWhyyjJcEj7NkhHd9tdDQAA9QZBpTrENZfaDvAtr/2XvbUAAFCPEFSqy9l/9b1vXCDtXW9vLQAA1BNhdhdQb7QfJJ0yUtrxjvTSSKnrxVLzrlJMUykiRjK9ktfjew+8JEmGb0Ju0WXDKPQ5sM4hOSMkZ5jkCJec4b7PjrDiy9b2QssOZ62eEgAAqoqgUp0u/rfkzpB+Xi19u8TuaoozHIVCS5g/9JS0XDT0hPkevuhw+oJTYNkRXhCaCrcNvBfbHhb8/YVDVbHtzkLLgeP4txuO4N8U5pLCIn1tAAD1Cv/LXp0iYqQJb0spn0m/fCH98aN07KiUm+X/R94R/JIkmf4307dslvJZpq9HxpsvefIkb57vvfBy0XVFmV7J4/a96iPD6QssgeASFiE5Xb7QZS0XCj8OZ4igVCRIlRTIgl7O4M/OMrZb68KLtwkERaunDQBOXASV6mYYUvuBvpedTH+w8eT6A0x+oeU8f+DJLbSc599ewrI3XzI9wcNXXk+hY3mCj1t4v8LBypvvqyOohkC7vCLbSjtmCQHM+s0eKS/L9zreGU7JFStFxPnfYwp6uYJCVCAAhReEHWfR8BNeSoAKDw5HJQUqq/es8PFCtAn0zDkjCpYJXACqgKBSXxmG7x+l+j4c4vX4Hl2Qn1P83ZPrW/a4fSEn312kB6poqAoVlgLb/NsDvVvWyxN8zJK2e0Psb81Z8jM9Uk6a73W8c4T7erkKB5hiPUylfDb8PZGOIu/WUGRgvaPQcuFQVnioM1zFeswCx3A4iywHApgjxLoQ+1vbS9rfSXgDKqCe/yuGes/hlCKifa/jmdfrCyeBnq7cbN98p9wMyZ3pGz4M6pUqIfRYQclTqG3hUJRXSqgq9PLkF9RhHavQZ7Pw56Lv/toDw5nWb8uTckP0hJ2QjOJBxwpZlQk/JYUnR3A4UpGJ+tayvx6jUG0h2xlltCvvPipnu8rUUEK7avt9FWmnUtqVwZoeYBSaLlBkubRtQesLHSvU8QK/x1pfpGfWFSdFNyq77hpCUAHqAodDksP3Pw7hUVJkvKQWdldVOYEhx0APlie3YJjRk+vr4fJ6Q/Q4FVlvegsCUtDVc4F1Hn/Q8waHrKLDjEHzu4oELyuAeYLDmPV9nuB6rO2F68oP3r9oYAti+oMjAQ7Hga5jpMsW2vb1BBUA1cvhlBxRvsB1IvMWDVMVDT8lhKcKBSpPQSA0Pb6aApP0rWWp2KT9Yu1UznaVOXZJ7VTOdhX43mr7fdXRrgzWhRSB8F142Vtw3KLbStzHDLGt8PrCxywSvD15tv//MkEFAGpC4V4yAJXGnWkBAECdRVABAAB1FkEFAADUWQQVAABQZxFUAABAnUVQAQAAdRZBBQAA1FkEFQAAUGcRVAAAQJ1FUAEAAHUWQQUAANRZBBUAAFBnEVQAAECdRVABAAB1VpjdBVSFaZqSpPT0dJsrAQAA5RX4dzvw73gox3VQycjIkCS1atXK5koAAEBFZWRkKD4+PmQbwyxPnKmjvF6v9u/fr7i4OBmGUa3HTk9PV6tWrbR37141aNCgWo+NApzn2sF5rj2c69rBea4dNXWeTdNURkaGkpKS5HCEnoVyXPeoOBwOtWzZska/o0GDBvw/QS3gPNcOznPt4VzXDs5z7aiJ81xWT0oAk2kBAECdRVABAAB1FkGlFC6XS/fff79cLpfdpdRrnOfawXmuPZzr2sF5rh114Twf15NpAQBA/UaPCgAAqLMIKgAAoM4iqAAAgDqLoAIAAOosgkoJnn32WbVr106RkZHq06ePPv/8c7tLOq4kJyfrtNNOU1xcnJo1a6bRo0dr586dQW1M09QDDzygpKQkRUVFadCgQfruu++C2rjdbk2fPl1NmjRRTEyM/vznP2vfvn21+VOOK8nJyTIMQzNnzrTWcZ6rx6+//qorr7xSjRs3VnR0tHr16qWvv/7a2s55rrr8/Hzdc889ateunaKiotS+fXs99NBD8nq9VhvOc+V89tlnGjlypJKSkmQYht5+++2g7dV1Xo8ePaoJEyYoPj5e8fHxmjBhglJTU6v+A0wEWbp0qRkeHm6+8MIL5vbt282bb77ZjImJMXfv3m13aceNoUOHmgsXLjS3bdtmbt682bzwwgvN1q1bm5mZmVabuXPnmnFxceYbb7xhbt261Rw7dqzZokULMz093WozdepU86STTjJXrlxpbtq0yTz33HPNnj17mvn5+Xb8rDpt/fr1Ztu2bc0ePXqYN998s7We81x1R44cMdu0aWNOnjzZ/Oqrr8yUlBRz1apV5o8//mi14TxX3cMPP2w2btzY/N///mempKSYy5YtM2NjY8158+ZZbTjPlfPee++Zd999t/nGG2+Yksy33noraHt1nddhw4aZ3bp1M9esWWOuWbPG7Natm3nRRRdVuX6CShGnn366OXXq1KB1nTt3Nu+44w6bKjr+HTp0yJRkfvrpp6ZpmqbX6zUTExPNuXPnWm1ycnLM+Ph487nnnjNN0zRTU1PN8PBwc+nSpVabX3/91XQ4HOYHH3xQuz+gjsvIyDA7duxorly50hw4cKAVVDjP1WP27NnmgAEDSt3Oea4eF154oXnVVVcFrRszZox55ZVXmqbJea4uRYNKdZ3X7du3m5LMdevWWW3Wrl1rSjK///77KtXM0E8hubm5+vrrr3XBBRcErb/gggu0Zs0am6o6/qWlpUmSGjVqJElKSUnRwYMHg86zy+XSwIEDrfP89ddfKy8vL6hNUlKSunXrxp9FETfddJMuvPBCDRkyJGg957l6LF++XH379tVll12mZs2aqXfv3nrhhRes7Zzn6jFgwAB99NFH+uGHHyRJ3377rb744guNGDFCEue5plTXeV27dq3i4+PVr18/q80ZZ5yh+Pj4Kp/74/qhhNXt8OHD8ng8at68edD65s2b6+DBgzZVdXwzTVO33nqrBgwYoG7dukmSdS5LOs+7d++22kRERCghIaFYG/4sCixdulSbNm3Shg0bim3jPFePn3/+WfPnz9ett96qu+66S+vXr9eMGTPkcrk0ceJEznM1mT17ttLS0tS5c2c5nU55PB7NmTNH48aNk8Tf55pSXef14MGDatasWbHjN2vWrMrnnqBSAsMwgj6bpllsHcpn2rRp2rJli7744oti2ypznvmzKLB3717dfPPNWrFihSIjI0ttx3muGq/Xq759++qRRx6RJPXu3Vvfffed5s+fr4kTJ1rtOM9V89prr2nx4sV69dVX1bVrV23evFkzZ85UUlKSJk2aZLXjPNeM6jivJbWvjnPP0E8hTZo0kdPpLJb+Dh06VCxtomzTp0/X8uXL9cknn6hly5bW+sTEREkKeZ4TExOVm5uro0ePltrmRPf111/r0KFD6tOnj8LCwhQWFqZPP/1UTz/9tMLCwqzzxHmumhYtWqhLly5B60455RTt2bNHEn+fq8ttt92mO+64Q1dccYW6d++uCRMm6JZbblFycrIkznNNqa7zmpiYqN9++63Y8X///fcqn3uCSiERERHq06ePVq5cGbR+5cqVOvPMM22q6vhjmqamTZumN998Ux9//LHatWsXtL1du3ZKTEwMOs+5ubn69NNPrfPcp08fhYeHB7U5cOCAtm3bxp+F3+DBg7V161Zt3rzZevXt21fjx4/X5s2b1b59e85zNTjrrLOKXV7/ww8/qE2bNpL4+1xdsrOz5XAE/5PkdDqty5M5zzWjus5r//79lZaWpvXr11ttvvrqK6WlpVX93FdpKm49FLg8ecGCBeb27dvNmTNnmjExMeYvv/xid2nHjRtuuMGMj483V69ebR44cMB6ZWdnW23mzp1rxsfHm2+++aa5detWc9y4cSVeDteyZUtz1apV5qZNm8zzzjvvhL/MsCyFr/oxTc5zdVi/fr0ZFhZmzpkzx9y1a5f5yiuvmNHR0ebixYutNpznqps0aZJ50kknWZcnv/nmm2aTJk3M22+/3WrDea6cjIwM85tvvjG/+eYbU5L55JNPmt988411243qOq/Dhg0ze/ToYa5du9Zcu3at2b17dy5Prin/+te/zDZt2pgRERHmqaeeal1Wi/KRVOJr4cKFVhuv12vef//9ZmJioulyucxzzjnH3Lp1a9Bxjh07Zk6bNs1s1KiRGRUVZV500UXmnj17avnXHF+KBhXOc/V45513zG7dupkul8vs3Lmz+fzzzwdt5zxXXXp6unnzzTebrVu3NiMjI8327dubd999t+l2u602nOfK+eSTT0r83+RJkyaZpll95/WPP/4wx48fb8bFxZlxcXHm+PHjzaNHj1a5fsM0TbNqfTIAAAA1gzkqAACgziKoAACAOougAgAA6iyCCgAAqLMIKgAAoM4iqAAAgDqLoAIAAOosggqAesUwDL399tt2lwGgmhBUAFSbyZMnyzCMYq9hw4bZXRqA41SY3QUAqF+GDRumhQsXBq1zuVw2VQPgeEePCoBq5XK5lJiYGPRKSEiQ5BuWmT9/voYPH66oqCi1a9dOy5YtC9p/69atOu+88xQVFaXGjRvruuuuU2ZmZlCbF198UV27dpXL5VKLFi00bdq0oO2HDx/WxRdfrOjoaHXs2FHLly+v2R8NoMYQVADUqnvvvVeXXHKJvv32W1155ZUaN26cduzYIUnKzs7WsGHDlJCQoA0bNmjZsmVatWpVUBCZP3++brrpJl133XXaunWrli9frg4dOgR9x4MPPqjLL79cW7Zs0YgRIzR+/HgdOXKkVn8ngGpS5ccaAoDfpEmTTKfTacbExAS9HnroIdM0fU/Wnjp1atA+/fr1M2+44QbTNE3z+eefNxMSEszMzExr+7vvvms6HA7z4MGDpmmaZlJSknn33XeXWoMk85577rE+Z2ZmmoZhmO+//361/U4AtYc5KgCq1bnnnqv58+cHrWvUqJG13L9//6Bt/fv31+bNmyVJO3bsUM+ePRUTE2NtP+uss+T1erVz504ZhqH9+/dr8ODBIWvo0aOHtRwTE6O4uDgdOnSosj8JgI0IKgCqVUxMTLGhmLIYhiFJMk3TWi6pTVRUVLmOFx4eXmxfr9dboZoA1A3MUQFQq9atW1fsc+fOnSVJXbp00ebNm5WVlWVt//LLL+VwONSpUyfFxcWpbdu2+uijj2q1ZgD2oUcFQLVyu906ePBg0LqwsDA1adJEkrRs2TL17dtXAwYM0CuvvKL169drwYIFkqTx48fr/vvv16RJk/TAAw/o999/1/Tp0zVhwgQ1b95ckvTAAw9o6tSpatasmYYPH66MjAx9+eWXmj59eu3+UAC1gqACoFp98MEHatGiRdC6k08+Wd9//70k3xU5S5cu1Y033qjExES98sor6tKliyQpOjpaH374oW6++Waddtppio6O1iWXXKInn3zSOtakSZOUk5Ojp556SrNmzVKTJk106aWX1t4PBFCrDNM0TbuLAHBiMAxDb731lkaPHm13KQCOE8xRAQAAdRZBBQAA1FnMUQFQaxhpBlBR9KgAAIA6i6ACAADqLIIKAACoswgqAACgziKoAACAOougAgAA6iyCCgAAqLMIKgAAoM4iqAAAgDrr/wNIeL4UBsrrQQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(test_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss values\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = net(X_train)\n",
    "y_test_pred = net(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = y_train_pred.detach().numpy()\n",
    "y_test_pred =y_test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE: 1.05e+05\n",
      "train MSE: 2.73e+10\n",
      "train R2: 0.445\n"
     ]
    }
   ],
   "source": [
    "print('train MAE: {0:.2e}'.format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print('train MSE: {0:.2e}'.format(mean_squared_error(y_train, y_train_pred)))\n",
    "print('train R2: {0:.3f}'.format(r2_score(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 1.02e+05\n",
      "test MSE: 2.32e+10\n",
      "test R2: 0.501\n"
     ]
    }
   ],
   "source": [
    "print('test MAE: {0:.2e}'.format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print('test MSE: {0:.2e}'.format(mean_squared_error(y_test, y_test_pred)))\n",
    "print('test R2: {0:.3f}'.format(r2_score(y_test, y_test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
